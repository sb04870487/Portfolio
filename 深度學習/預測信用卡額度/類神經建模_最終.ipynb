{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import boston_housing\n",
    "from keras.datasets import reuters\n",
    "import numpy as np\n",
    "import os\n",
    "from keras.models import Sequential\n",
    "import tensorflow as tf\n",
    "from keras import models,Model\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "from keras import losses\n",
    "from keras import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import cross_validate\n",
    "from utils import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import *\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.wrappers.scikit_learn import KerasClassifier \n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten\n",
    "from keras.layers import Input, LSTM, Embedding, Dense\n",
    "from keras.models import Model, Sequential\n",
    "import keras\n",
    "from keras.layers import Conv2D, MaxPooling2D, Input\n",
    "import tensorboard\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras.datasets import imdb\n",
    "from keras.preprocessing import sequence\n",
    "from keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1680 entries, 0 to 1686\n",
      "Data columns (total 8 columns):\n",
      "age                1680 non-null float64\n",
      "serveTime          1680 non-null float64\n",
      "credLimit          1680 non-null int64\n",
      "Loan               1680 non-null float64\n",
      "SalPerY            1680 non-null int64\n",
      "holdCard           1680 non-null int64\n",
      "Career             1680 non-null int64\n",
      "credLimit_group    1680 non-null int32\n",
      "dtypes: float64(3), int32(1), int64(4)\n",
      "memory usage: 111.6 KB\n"
     ]
    }
   ],
   "source": [
    "#開檔\n",
    "df = pd.read_excel(r'C:\\Users\\Big data\\Desktop\\class\\funcardproject\\斷詞與和卡額度_20群.xls',encoding='utf-16')\n",
    "df = df.loc[:, [\"age\",\"serveTime\",\"credLimit\",\"Loan\",\"SalPerY\",\"holdCard\",\"Career\",\"credLimit_group\"]] \n",
    "#若某raw有NAN則整RAW刪除\n",
    "df =df.dropna(\n",
    "    axis=0,     # 0: 对行进行操作; 1: 对列进行操作\n",
    "    how='any'   # 'any': 只要存在 NaN 就 drop 掉; 'all': 必须全部是 NaN 才 drop \n",
    "    ) \n",
    "#把分群的Y轉成int\n",
    "df['credLimit_group'] = df['credLimit_group'].astype('int')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1176, 6)\n",
      "(504, 6)\n",
      "(1176, 1)\n",
      "(504, 1)\n",
      "(1176, 6)\n",
      "(504, 6)\n",
      "(1176, 20)\n",
      "(504, 20)\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data, train_targets, test_targets = train_test_split(df.loc[:, [\"age\",\"serveTime\",\"Loan\",\"SalPerY\",\"holdCard\",\"Career\"]] , df.loc[:, [\"credLimit_group\"]] , test_size=0.3, random_state=4)\n",
    "print(train_data.shape)\n",
    "print(test_data.shape)\n",
    "print(train_targets.shape)\n",
    "print(test_targets.shape)\n",
    "#轉array\n",
    "train_data = np.array(train_data).astype(float)\n",
    "test_data = np.array(test_data).astype(float)\n",
    "train_targets = np.array(train_targets).astype(int)\n",
    "test_targets = np.array(test_targets).astype(int)\n",
    "#把Y弄成onehot\n",
    "def to_one_hot(labels, dimension=20):\n",
    "    results = np.zeros((len(labels),dimension))\n",
    "    for i,label in enumerate(labels):\n",
    "        results[i,label]=1.\n",
    "    return results\n",
    "train_targets = to_one_hot(train_targets)\n",
    "test_targets = to_one_hot(test_targets)\n",
    "\n",
    "print(train_data.shape)\n",
    "print(test_data.shape)\n",
    "print(train_targets.shape)\n",
    "print(test_targets.shape)\n",
    "\n",
    "#正規化\n",
    "#因為relu,所以這個比較好\n",
    "train_data_max = train_data.max(axis=0)\n",
    "train_data_min = train_data.min(axis=0)\n",
    "train_data_range = train_data_max-train_data_min\n",
    "train_data-=train_data_min\n",
    "train_data/=train_data_range\n",
    "\n",
    "test_data_max = test_data.max(axis=0)\n",
    "test_data_min = test_data.min(axis=0)\n",
    "test_data_range = test_data_max-test_data_min\n",
    "test_data-=test_data_min\n",
    "test_data/=test_data_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_30\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_34 (InputLayer)        (None, 6)                 0         \n",
      "_________________________________________________________________\n",
      "dense_338 (Dense)            (None, 10)                70        \n",
      "_________________________________________________________________\n",
      "dropout_32 (Dropout)         (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_339 (Dense)            (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dropout_33 (Dropout)         (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_340 (Dense)            (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dropout_34 (Dropout)         (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_341 (Dense)            (None, 20)                220       \n",
      "=================================================================\n",
      "Total params: 510\n",
      "Trainable params: 510\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1176 samples, validate on 504 samples\n",
      "Epoch 1/1000\n",
      "1176/1176 [==============================] - 0s 299us/step - loss: 3.1241 - accuracy: 0.0026 - val_loss: 2.9862 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 2.8647 - accuracy: 0.0434 - val_loss: 2.7285 - val_accuracy: 0.1806\n",
      "Epoch 3/1000\n",
      "1176/1176 [==============================] - 0s 40us/step - loss: 2.6270 - accuracy: 0.1641 - val_loss: 2.5040 - val_accuracy: 0.1746\n",
      "Epoch 4/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 2.4462 - accuracy: 0.1820 - val_loss: 2.3236 - val_accuracy: 0.1746\n",
      "Epoch 5/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 2.2986 - accuracy: 0.2032 - val_loss: 2.1886 - val_accuracy: 0.1865\n",
      "Epoch 6/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 2.1913 - accuracy: 0.2177 - val_loss: 2.0976 - val_accuracy: 0.1865\n",
      "Epoch 7/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 2.1247 - accuracy: 0.2270 - val_loss: 2.0417 - val_accuracy: 0.2103\n",
      "Epoch 8/1000\n",
      "1176/1176 [==============================] - 0s 44us/step - loss: 2.0899 - accuracy: 0.2364 - val_loss: 2.0105 - val_accuracy: 0.2798\n",
      "Epoch 9/1000\n",
      "1176/1176 [==============================] - 0s 40us/step - loss: 2.0759 - accuracy: 0.2636 - val_loss: 1.9931 - val_accuracy: 0.2798\n",
      "Epoch 10/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 2.0729 - accuracy: 0.2551 - val_loss: 1.9819 - val_accuracy: 0.2798\n",
      "Epoch 11/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 2.0549 - accuracy: 0.2619 - val_loss: 1.9742 - val_accuracy: 0.2798\n",
      "Epoch 12/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 2.0510 - accuracy: 0.2526 - val_loss: 1.9685 - val_accuracy: 0.2798\n",
      "Epoch 13/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 2.0526 - accuracy: 0.2543 - val_loss: 1.9641 - val_accuracy: 0.2798\n",
      "Epoch 14/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 2.0465 - accuracy: 0.2500 - val_loss: 1.9616 - val_accuracy: 0.2798\n",
      "Epoch 15/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 2.0473 - accuracy: 0.2432 - val_loss: 1.9592 - val_accuracy: 0.2798\n",
      "Epoch 16/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 2.0406 - accuracy: 0.2568 - val_loss: 1.9574 - val_accuracy: 0.2798\n",
      "Epoch 17/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 2.0442 - accuracy: 0.2517 - val_loss: 1.9558 - val_accuracy: 0.2798\n",
      "Epoch 18/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 2.0299 - accuracy: 0.2577 - val_loss: 1.9537 - val_accuracy: 0.2798\n",
      "Epoch 19/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 2.0365 - accuracy: 0.2534 - val_loss: 1.9515 - val_accuracy: 0.2798\n",
      "Epoch 20/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 2.0331 - accuracy: 0.2474 - val_loss: 1.9488 - val_accuracy: 0.2798\n",
      "Epoch 21/1000\n",
      "1176/1176 [==============================] - 0s 42us/step - loss: 2.0344 - accuracy: 0.2509 - val_loss: 1.9468 - val_accuracy: 0.2798\n",
      "Epoch 22/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 2.0227 - accuracy: 0.2551 - val_loss: 1.9446 - val_accuracy: 0.2798\n",
      "Epoch 23/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 2.0198 - accuracy: 0.2696 - val_loss: 1.9422 - val_accuracy: 0.2798\n",
      "Epoch 24/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 2.0156 - accuracy: 0.2611 - val_loss: 1.9404 - val_accuracy: 0.2798\n",
      "Epoch 25/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 2.0159 - accuracy: 0.2509 - val_loss: 1.9387 - val_accuracy: 0.2798\n",
      "Epoch 26/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 2.0236 - accuracy: 0.2662 - val_loss: 1.9372 - val_accuracy: 0.2798\n",
      "Epoch 27/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 2.0190 - accuracy: 0.2474 - val_loss: 1.9360 - val_accuracy: 0.2798\n",
      "Epoch 28/1000\n",
      "1176/1176 [==============================] - 0s 41us/step - loss: 2.0127 - accuracy: 0.2619 - val_loss: 1.9344 - val_accuracy: 0.2798\n",
      "Epoch 29/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 2.0114 - accuracy: 0.2551 - val_loss: 1.9326 - val_accuracy: 0.2798\n",
      "Epoch 30/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 2.0108 - accuracy: 0.2543 - val_loss: 1.9303 - val_accuracy: 0.2798\n",
      "Epoch 31/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 2.0016 - accuracy: 0.2560 - val_loss: 1.9285 - val_accuracy: 0.2798\n",
      "Epoch 32/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 2.0040 - accuracy: 0.2585 - val_loss: 1.9271 - val_accuracy: 0.2798\n",
      "Epoch 33/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 2.0037 - accuracy: 0.2730 - val_loss: 1.9249 - val_accuracy: 0.2798\n",
      "Epoch 34/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.9964 - accuracy: 0.2628 - val_loss: 1.9231 - val_accuracy: 0.2798\n",
      "Epoch 35/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 2.0061 - accuracy: 0.2585 - val_loss: 1.9212 - val_accuracy: 0.2798\n",
      "Epoch 36/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.9894 - accuracy: 0.2721 - val_loss: 1.9185 - val_accuracy: 0.2857\n",
      "Epoch 37/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.9934 - accuracy: 0.2730 - val_loss: 1.9166 - val_accuracy: 0.2817\n",
      "Epoch 38/1000\n",
      "1176/1176 [==============================] - 0s 40us/step - loss: 1.9967 - accuracy: 0.2713 - val_loss: 1.9147 - val_accuracy: 0.2817\n",
      "Epoch 39/1000\n",
      "1176/1176 [==============================] - 0s 40us/step - loss: 2.0020 - accuracy: 0.2628 - val_loss: 1.9131 - val_accuracy: 0.2877\n",
      "Epoch 40/1000\n",
      "1176/1176 [==============================] - 0s 40us/step - loss: 1.9882 - accuracy: 0.2687 - val_loss: 1.9106 - val_accuracy: 0.2877\n",
      "Epoch 41/1000\n",
      "1176/1176 [==============================] - 0s 41us/step - loss: 1.9844 - accuracy: 0.2662 - val_loss: 1.9080 - val_accuracy: 0.2778\n",
      "Epoch 42/1000\n",
      "1176/1176 [==============================] - 0s 46us/step - loss: 1.9866 - accuracy: 0.2577 - val_loss: 1.9051 - val_accuracy: 0.2778\n",
      "Epoch 43/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.9798 - accuracy: 0.2704 - val_loss: 1.9011 - val_accuracy: 0.2817\n",
      "Epoch 44/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.9825 - accuracy: 0.2560 - val_loss: 1.8989 - val_accuracy: 0.2817\n",
      "Epoch 45/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.9684 - accuracy: 0.2747 - val_loss: 1.8953 - val_accuracy: 0.2798\n",
      "Epoch 46/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1176/1176 [==============================] - 0s 40us/step - loss: 1.9676 - accuracy: 0.2721 - val_loss: 1.8923 - val_accuracy: 0.2817\n",
      "Epoch 47/1000\n",
      "1176/1176 [==============================] - 0s 40us/step - loss: 1.9780 - accuracy: 0.2679 - val_loss: 1.8880 - val_accuracy: 0.2817\n",
      "Epoch 48/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.9688 - accuracy: 0.2704 - val_loss: 1.8841 - val_accuracy: 0.2897\n",
      "Epoch 49/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.9628 - accuracy: 0.2798 - val_loss: 1.8810 - val_accuracy: 0.2877\n",
      "Epoch 50/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.9677 - accuracy: 0.2619 - val_loss: 1.8765 - val_accuracy: 0.2917\n",
      "Epoch 51/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.9515 - accuracy: 0.2636 - val_loss: 1.8703 - val_accuracy: 0.2897\n",
      "Epoch 52/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.9524 - accuracy: 0.2772 - val_loss: 1.8640 - val_accuracy: 0.2976\n",
      "Epoch 53/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.9527 - accuracy: 0.2772 - val_loss: 1.8587 - val_accuracy: 0.3214\n",
      "Epoch 54/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.9423 - accuracy: 0.2908 - val_loss: 1.8542 - val_accuracy: 0.3333\n",
      "Epoch 55/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.9305 - accuracy: 0.2772 - val_loss: 1.8473 - val_accuracy: 0.3373\n",
      "Epoch 56/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.9262 - accuracy: 0.2908 - val_loss: 1.8411 - val_accuracy: 0.3452\n",
      "Epoch 57/1000\n",
      "1176/1176 [==============================] - 0s 42us/step - loss: 1.9250 - accuracy: 0.3070 - val_loss: 1.8363 - val_accuracy: 0.3433\n",
      "Epoch 58/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.9187 - accuracy: 0.2985 - val_loss: 1.8303 - val_accuracy: 0.3512\n",
      "Epoch 59/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.9167 - accuracy: 0.3087 - val_loss: 1.8259 - val_accuracy: 0.3532\n",
      "Epoch 60/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.9079 - accuracy: 0.3002 - val_loss: 1.8236 - val_accuracy: 0.3472\n",
      "Epoch 61/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.9015 - accuracy: 0.2934 - val_loss: 1.8191 - val_accuracy: 0.3472\n",
      "Epoch 62/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.8943 - accuracy: 0.2985 - val_loss: 1.8145 - val_accuracy: 0.3552\n",
      "Epoch 63/1000\n",
      "1176/1176 [==============================] - 0s 50us/step - loss: 1.8942 - accuracy: 0.3070 - val_loss: 1.8035 - val_accuracy: 0.3591\n",
      "Epoch 64/1000\n",
      "1176/1176 [==============================] - 0s 47us/step - loss: 1.8850 - accuracy: 0.3291 - val_loss: 1.8040 - val_accuracy: 0.3552\n",
      "Epoch 65/1000\n",
      "1176/1176 [==============================] - 0s 41us/step - loss: 1.8772 - accuracy: 0.3095 - val_loss: 1.8024 - val_accuracy: 0.3512\n",
      "Epoch 66/1000\n",
      "1176/1176 [==============================] - 0s 41us/step - loss: 1.8736 - accuracy: 0.3087 - val_loss: 1.7976 - val_accuracy: 0.3512\n",
      "Epoch 67/1000\n",
      "1176/1176 [==============================] - 0s 41us/step - loss: 1.8865 - accuracy: 0.3019 - val_loss: 1.8041 - val_accuracy: 0.3413\n",
      "Epoch 68/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.8698 - accuracy: 0.3197 - val_loss: 1.8055 - val_accuracy: 0.3393\n",
      "Epoch 69/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.8616 - accuracy: 0.3172 - val_loss: 1.7978 - val_accuracy: 0.3413\n",
      "Epoch 70/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.8715 - accuracy: 0.3044 - val_loss: 1.8036 - val_accuracy: 0.3353\n",
      "Epoch 71/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.8622 - accuracy: 0.3053 - val_loss: 1.7960 - val_accuracy: 0.3413\n",
      "Epoch 72/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.8636 - accuracy: 0.3095 - val_loss: 1.7974 - val_accuracy: 0.3393\n",
      "Epoch 73/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.8405 - accuracy: 0.3265 - val_loss: 1.7924 - val_accuracy: 0.3373\n",
      "Epoch 74/1000\n",
      "1176/1176 [==============================] - 0s 40us/step - loss: 1.8507 - accuracy: 0.3359 - val_loss: 1.7881 - val_accuracy: 0.3452\n",
      "Epoch 75/1000\n",
      "1176/1176 [==============================] - 0s 41us/step - loss: 1.8583 - accuracy: 0.3155 - val_loss: 1.7976 - val_accuracy: 0.3373\n",
      "Epoch 76/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.8481 - accuracy: 0.3231 - val_loss: 1.7855 - val_accuracy: 0.3413\n",
      "Epoch 77/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.8467 - accuracy: 0.3214 - val_loss: 1.7887 - val_accuracy: 0.3393\n",
      "Epoch 78/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.8340 - accuracy: 0.3401 - val_loss: 1.7902 - val_accuracy: 0.3373\n",
      "Epoch 79/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.8488 - accuracy: 0.3061 - val_loss: 1.7883 - val_accuracy: 0.3373\n",
      "Epoch 80/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.8426 - accuracy: 0.3308 - val_loss: 1.7892 - val_accuracy: 0.3373\n",
      "Epoch 81/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.8478 - accuracy: 0.3172 - val_loss: 1.7892 - val_accuracy: 0.3353\n",
      "Epoch 82/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.8229 - accuracy: 0.3333 - val_loss: 1.7796 - val_accuracy: 0.3353\n",
      "Epoch 83/1000\n",
      "1176/1176 [==============================] - 0s 42us/step - loss: 1.8410 - accuracy: 0.3223 - val_loss: 1.7846 - val_accuracy: 0.3413\n",
      "Epoch 84/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.8472 - accuracy: 0.3257 - val_loss: 1.7862 - val_accuracy: 0.3313\n",
      "Epoch 85/1000\n",
      "1176/1176 [==============================] - 0s 40us/step - loss: 1.8171 - accuracy: 0.3180 - val_loss: 1.7938 - val_accuracy: 0.3333\n",
      "Epoch 86/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.8322 - accuracy: 0.3316 - val_loss: 1.7905 - val_accuracy: 0.3313\n",
      "Epoch 87/1000\n",
      "1176/1176 [==============================] - 0s 40us/step - loss: 1.8355 - accuracy: 0.3070 - val_loss: 1.7874 - val_accuracy: 0.3313\n",
      "Epoch 88/1000\n",
      "1176/1176 [==============================] - 0s 40us/step - loss: 1.8234 - accuracy: 0.3223 - val_loss: 1.7885 - val_accuracy: 0.3274\n",
      "Epoch 89/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.8332 - accuracy: 0.3240 - val_loss: 1.7810 - val_accuracy: 0.3313\n",
      "Epoch 90/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.8306 - accuracy: 0.3350 - val_loss: 1.7750 - val_accuracy: 0.3333\n",
      "Epoch 91/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.8266 - accuracy: 0.3104 - val_loss: 1.7808 - val_accuracy: 0.3313\n",
      "Epoch 92/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.7998 - accuracy: 0.3291 - val_loss: 1.7781 - val_accuracy: 0.3313\n",
      "Epoch 93/1000\n",
      "1176/1176 [==============================] - 0s 41us/step - loss: 1.8112 - accuracy: 0.3376 - val_loss: 1.7719 - val_accuracy: 0.3393\n",
      "Epoch 94/1000\n",
      "1176/1176 [==============================] - 0s 41us/step - loss: 1.8320 - accuracy: 0.3231 - val_loss: 1.7754 - val_accuracy: 0.3353\n",
      "Epoch 95/1000\n",
      "1176/1176 [==============================] - 0s 40us/step - loss: 1.8166 - accuracy: 0.3376 - val_loss: 1.7784 - val_accuracy: 0.3313\n",
      "Epoch 96/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.8277 - accuracy: 0.3367 - val_loss: 1.7815 - val_accuracy: 0.3274\n",
      "Epoch 97/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.8173 - accuracy: 0.3138 - val_loss: 1.7782 - val_accuracy: 0.3294\n",
      "Epoch 98/1000\n",
      "1176/1176 [==============================] - 0s 40us/step - loss: 1.8188 - accuracy: 0.3240 - val_loss: 1.7741 - val_accuracy: 0.3274\n",
      "Epoch 99/1000\n",
      "1176/1176 [==============================] - 0s 51us/step - loss: 1.7973 - accuracy: 0.3240 - val_loss: 1.7770 - val_accuracy: 0.3294\n",
      "Epoch 100/1000\n",
      "1176/1176 [==============================] - 0s 43us/step - loss: 1.8071 - accuracy: 0.3231 - val_loss: 1.7773 - val_accuracy: 0.3274\n",
      "Epoch 101/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.8141 - accuracy: 0.3299 - val_loss: 1.7704 - val_accuracy: 0.3294\n",
      "Epoch 102/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.8186 - accuracy: 0.3350 - val_loss: 1.7701 - val_accuracy: 0.3294\n",
      "Epoch 103/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.7871 - accuracy: 0.3376 - val_loss: 1.7678 - val_accuracy: 0.3294\n",
      "Epoch 104/1000\n",
      "1176/1176 [==============================] - 0s 43us/step - loss: 1.8067 - accuracy: 0.3257 - val_loss: 1.7708 - val_accuracy: 0.3274\n",
      "Epoch 105/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.8050 - accuracy: 0.3214 - val_loss: 1.7663 - val_accuracy: 0.3294\n",
      "Epoch 106/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.8153 - accuracy: 0.3299 - val_loss: 1.7640 - val_accuracy: 0.3333\n",
      "Epoch 107/1000\n",
      "1176/1176 [==============================] - 0s 40us/step - loss: 1.8038 - accuracy: 0.3223 - val_loss: 1.7658 - val_accuracy: 0.3313\n",
      "Epoch 108/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.7963 - accuracy: 0.3189 - val_loss: 1.7757 - val_accuracy: 0.3333\n",
      "Epoch 109/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.8005 - accuracy: 0.3410 - val_loss: 1.7763 - val_accuracy: 0.3333\n",
      "Epoch 110/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.8011 - accuracy: 0.3359 - val_loss: 1.7613 - val_accuracy: 0.3333\n",
      "Epoch 111/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.8051 - accuracy: 0.3257 - val_loss: 1.7650 - val_accuracy: 0.3313\n",
      "Epoch 112/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.7879 - accuracy: 0.3274 - val_loss: 1.7603 - val_accuracy: 0.3353\n",
      "Epoch 113/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.7823 - accuracy: 0.3299 - val_loss: 1.7653 - val_accuracy: 0.3313\n",
      "Epoch 114/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.7764 - accuracy: 0.3444 - val_loss: 1.7596 - val_accuracy: 0.3353\n",
      "Epoch 115/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.7956 - accuracy: 0.3359 - val_loss: 1.7598 - val_accuracy: 0.3333\n",
      "Epoch 116/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.7965 - accuracy: 0.3333 - val_loss: 1.7650 - val_accuracy: 0.3313\n",
      "Epoch 117/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.7947 - accuracy: 0.3274 - val_loss: 1.7605 - val_accuracy: 0.3413\n",
      "Epoch 118/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.7946 - accuracy: 0.3359 - val_loss: 1.7620 - val_accuracy: 0.3393\n",
      "Epoch 119/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.7869 - accuracy: 0.3274 - val_loss: 1.7624 - val_accuracy: 0.3373\n",
      "Epoch 120/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.7964 - accuracy: 0.3435 - val_loss: 1.7577 - val_accuracy: 0.3413\n",
      "Epoch 121/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.7780 - accuracy: 0.3367 - val_loss: 1.7547 - val_accuracy: 0.3413\n",
      "Epoch 122/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.8006 - accuracy: 0.3274 - val_loss: 1.7554 - val_accuracy: 0.3452\n",
      "Epoch 123/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.7764 - accuracy: 0.3325 - val_loss: 1.7591 - val_accuracy: 0.3452\n",
      "Epoch 124/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.7832 - accuracy: 0.3163 - val_loss: 1.7612 - val_accuracy: 0.3433\n",
      "Epoch 125/1000\n",
      "1176/1176 [==============================] - 0s 42us/step - loss: 1.7804 - accuracy: 0.3554 - val_loss: 1.7595 - val_accuracy: 0.3373\n",
      "Epoch 126/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.7694 - accuracy: 0.3461 - val_loss: 1.7561 - val_accuracy: 0.3393\n",
      "Epoch 127/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.7939 - accuracy: 0.3282 - val_loss: 1.7614 - val_accuracy: 0.3373\n",
      "Epoch 128/1000\n",
      "1176/1176 [==============================] - 0s 40us/step - loss: 1.7802 - accuracy: 0.3350 - val_loss: 1.7595 - val_accuracy: 0.3413\n",
      "Epoch 129/1000\n",
      "1176/1176 [==============================] - 0s 42us/step - loss: 1.7733 - accuracy: 0.3350 - val_loss: 1.7578 - val_accuracy: 0.3433\n",
      "Epoch 130/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.7780 - accuracy: 0.3308 - val_loss: 1.7554 - val_accuracy: 0.3452\n",
      "Epoch 131/1000\n",
      "1176/1176 [==============================] - 0s 40us/step - loss: 1.7826 - accuracy: 0.3418 - val_loss: 1.7507 - val_accuracy: 0.3413\n",
      "Epoch 132/1000\n",
      "1176/1176 [==============================] - 0s 40us/step - loss: 1.7785 - accuracy: 0.3342 - val_loss: 1.7563 - val_accuracy: 0.3353\n",
      "Epoch 133/1000\n",
      "1176/1176 [==============================] - 0s 40us/step - loss: 1.7810 - accuracy: 0.3410 - val_loss: 1.7565 - val_accuracy: 0.3353\n",
      "Epoch 134/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.7716 - accuracy: 0.3359 - val_loss: 1.7558 - val_accuracy: 0.3433\n",
      "Epoch 135/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.7842 - accuracy: 0.3495 - val_loss: 1.7555 - val_accuracy: 0.3413\n",
      "Epoch 136/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.7759 - accuracy: 0.3435 - val_loss: 1.7500 - val_accuracy: 0.3472\n",
      "Epoch 137/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.7729 - accuracy: 0.3206 - val_loss: 1.7570 - val_accuracy: 0.3433\n",
      "Epoch 138/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.7869 - accuracy: 0.3282 - val_loss: 1.7498 - val_accuracy: 0.3452\n",
      "Epoch 139/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.7620 - accuracy: 0.3452 - val_loss: 1.7533 - val_accuracy: 0.3393\n",
      "Epoch 140/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.7708 - accuracy: 0.3452 - val_loss: 1.7536 - val_accuracy: 0.3413\n",
      "Epoch 141/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.7771 - accuracy: 0.3384 - val_loss: 1.7580 - val_accuracy: 0.3373\n",
      "Epoch 142/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.7743 - accuracy: 0.3461 - val_loss: 1.7567 - val_accuracy: 0.3413\n",
      "Epoch 143/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.7636 - accuracy: 0.3384 - val_loss: 1.7507 - val_accuracy: 0.3452\n",
      "Epoch 144/1000\n",
      "1176/1176 [==============================] - 0s 40us/step - loss: 1.7523 - accuracy: 0.3478 - val_loss: 1.7454 - val_accuracy: 0.3433\n",
      "Epoch 145/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.7644 - accuracy: 0.3316 - val_loss: 1.7565 - val_accuracy: 0.3433\n",
      "Epoch 146/1000\n",
      "1176/1176 [==============================] - 0s 45us/step - loss: 1.7661 - accuracy: 0.3308 - val_loss: 1.7524 - val_accuracy: 0.3433\n",
      "Epoch 147/1000\n",
      "1176/1176 [==============================] - 0s 40us/step - loss: 1.7753 - accuracy: 0.3401 - val_loss: 1.7541 - val_accuracy: 0.3452\n",
      "Epoch 148/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.7691 - accuracy: 0.3461 - val_loss: 1.7517 - val_accuracy: 0.3452\n",
      "Epoch 149/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.7611 - accuracy: 0.3427 - val_loss: 1.7539 - val_accuracy: 0.3413\n",
      "Epoch 150/1000\n",
      "1176/1176 [==============================] - 0s 42us/step - loss: 1.7620 - accuracy: 0.3418 - val_loss: 1.7536 - val_accuracy: 0.3393\n",
      "Epoch 151/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.7629 - accuracy: 0.3427 - val_loss: 1.7471 - val_accuracy: 0.3393\n",
      "Epoch 152/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.7648 - accuracy: 0.3359 - val_loss: 1.7452 - val_accuracy: 0.3433\n",
      "Epoch 153/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.7724 - accuracy: 0.3401 - val_loss: 1.7514 - val_accuracy: 0.3333\n",
      "Epoch 154/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.7646 - accuracy: 0.3435 - val_loss: 1.7478 - val_accuracy: 0.3353\n",
      "Epoch 155/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.7707 - accuracy: 0.3410 - val_loss: 1.7489 - val_accuracy: 0.3373\n",
      "Epoch 156/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.7743 - accuracy: 0.3367 - val_loss: 1.7507 - val_accuracy: 0.3373\n",
      "Epoch 157/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.7735 - accuracy: 0.3240 - val_loss: 1.7497 - val_accuracy: 0.3333\n",
      "Epoch 158/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.7739 - accuracy: 0.3469 - val_loss: 1.7483 - val_accuracy: 0.3393\n",
      "Epoch 159/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.7485 - accuracy: 0.3529 - val_loss: 1.7448 - val_accuracy: 0.3373\n",
      "Epoch 160/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.7676 - accuracy: 0.3376 - val_loss: 1.7483 - val_accuracy: 0.3393\n",
      "Epoch 161/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.7658 - accuracy: 0.3435 - val_loss: 1.7511 - val_accuracy: 0.3333\n",
      "Epoch 162/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.7585 - accuracy: 0.3554 - val_loss: 1.7471 - val_accuracy: 0.3333\n",
      "Epoch 163/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.7746 - accuracy: 0.3350 - val_loss: 1.7494 - val_accuracy: 0.3333\n",
      "Epoch 164/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.7609 - accuracy: 0.3418 - val_loss: 1.7456 - val_accuracy: 0.3373\n",
      "Epoch 165/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.7608 - accuracy: 0.3486 - val_loss: 1.7421 - val_accuracy: 0.3472\n",
      "Epoch 166/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.7658 - accuracy: 0.3350 - val_loss: 1.7466 - val_accuracy: 0.3492\n",
      "Epoch 167/1000\n",
      "1176/1176 [==============================] - 0s 42us/step - loss: 1.7604 - accuracy: 0.3384 - val_loss: 1.7490 - val_accuracy: 0.3353\n",
      "Epoch 168/1000\n",
      "1176/1176 [==============================] - 0s 40us/step - loss: 1.7524 - accuracy: 0.3282 - val_loss: 1.7508 - val_accuracy: 0.3373\n",
      "Epoch 169/1000\n",
      "1176/1176 [==============================] - 0s 42us/step - loss: 1.7654 - accuracy: 0.3427 - val_loss: 1.7444 - val_accuracy: 0.3512\n",
      "Epoch 170/1000\n",
      "1176/1176 [==============================] - 0s 48us/step - loss: 1.7458 - accuracy: 0.3418 - val_loss: 1.7410 - val_accuracy: 0.3532\n",
      "Epoch 171/1000\n",
      "1176/1176 [==============================] - 0s 48us/step - loss: 1.7489 - accuracy: 0.3520 - val_loss: 1.7406 - val_accuracy: 0.3512\n",
      "Epoch 172/1000\n",
      "1176/1176 [==============================] - 0s 42us/step - loss: 1.7483 - accuracy: 0.3452 - val_loss: 1.7398 - val_accuracy: 0.3532\n",
      "Epoch 173/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.7494 - accuracy: 0.3461 - val_loss: 1.7460 - val_accuracy: 0.3433\n",
      "Epoch 174/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.7485 - accuracy: 0.3529 - val_loss: 1.7436 - val_accuracy: 0.3393\n",
      "Epoch 175/1000\n",
      "1176/1176 [==============================] - 0s 42us/step - loss: 1.7502 - accuracy: 0.3478 - val_loss: 1.7426 - val_accuracy: 0.3433\n",
      "Epoch 176/1000\n",
      "1176/1176 [==============================] - 0s 46us/step - loss: 1.7595 - accuracy: 0.3401 - val_loss: 1.7464 - val_accuracy: 0.3353\n",
      "Epoch 177/1000\n",
      "1176/1176 [==============================] - 0s 45us/step - loss: 1.7577 - accuracy: 0.3478 - val_loss: 1.7463 - val_accuracy: 0.3373\n",
      "Epoch 178/1000\n",
      "1176/1176 [==============================] - 0s 42us/step - loss: 1.7560 - accuracy: 0.3469 - val_loss: 1.7437 - val_accuracy: 0.3433\n",
      "Epoch 179/1000\n",
      "1176/1176 [==============================] - 0s 40us/step - loss: 1.7550 - accuracy: 0.3503 - val_loss: 1.7426 - val_accuracy: 0.3433\n",
      "Epoch 180/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.7647 - accuracy: 0.3291 - val_loss: 1.7413 - val_accuracy: 0.3492\n",
      "Epoch 181/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.7428 - accuracy: 0.3444 - val_loss: 1.7459 - val_accuracy: 0.3333\n",
      "Epoch 182/1000\n",
      "1176/1176 [==============================] - 0s 44us/step - loss: 1.7535 - accuracy: 0.3333 - val_loss: 1.7413 - val_accuracy: 0.3353\n",
      "Epoch 183/1000\n",
      "1176/1176 [==============================] - 0s 46us/step - loss: 1.7536 - accuracy: 0.3478 - val_loss: 1.7400 - val_accuracy: 0.3413\n",
      "Epoch 184/1000\n",
      "1176/1176 [==============================] - 0s 43us/step - loss: 1.7376 - accuracy: 0.3648 - val_loss: 1.7366 - val_accuracy: 0.3433\n",
      "Epoch 185/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.7511 - accuracy: 0.3384 - val_loss: 1.7441 - val_accuracy: 0.3333\n",
      "Epoch 186/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.7520 - accuracy: 0.3495 - val_loss: 1.7390 - val_accuracy: 0.3452\n",
      "Epoch 187/1000\n",
      "1176/1176 [==============================] - 0s 45us/step - loss: 1.7386 - accuracy: 0.3410 - val_loss: 1.7395 - val_accuracy: 0.3433\n",
      "Epoch 188/1000\n",
      "1176/1176 [==============================] - 0s 40us/step - loss: 1.7474 - accuracy: 0.3631 - val_loss: 1.7394 - val_accuracy: 0.3452\n",
      "Epoch 189/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.7533 - accuracy: 0.3546 - val_loss: 1.7419 - val_accuracy: 0.3413\n",
      "Epoch 190/1000\n",
      "1176/1176 [==============================] - 0s 40us/step - loss: 1.7495 - accuracy: 0.3580 - val_loss: 1.7466 - val_accuracy: 0.3313\n",
      "Epoch 191/1000\n",
      "1176/1176 [==============================] - 0s 48us/step - loss: 1.7430 - accuracy: 0.3495 - val_loss: 1.7489 - val_accuracy: 0.3313\n",
      "Epoch 192/1000\n",
      "1176/1176 [==============================] - 0s 51us/step - loss: 1.7533 - accuracy: 0.3580 - val_loss: 1.7437 - val_accuracy: 0.3373\n",
      "Epoch 193/1000\n",
      "1176/1176 [==============================] - 0s 48us/step - loss: 1.7416 - accuracy: 0.3478 - val_loss: 1.7394 - val_accuracy: 0.3472\n",
      "Epoch 194/1000\n",
      "1176/1176 [==============================] - 0s 43us/step - loss: 1.7479 - accuracy: 0.3342 - val_loss: 1.7423 - val_accuracy: 0.3373\n",
      "Epoch 195/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.7501 - accuracy: 0.3563 - val_loss: 1.7385 - val_accuracy: 0.3452\n",
      "Epoch 196/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.7423 - accuracy: 0.3495 - val_loss: 1.7442 - val_accuracy: 0.3373\n",
      "Epoch 197/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.7447 - accuracy: 0.3461 - val_loss: 1.7439 - val_accuracy: 0.3373\n",
      "Epoch 198/1000\n",
      "1176/1176 [==============================] - 0s 43us/step - loss: 1.7420 - accuracy: 0.3546 - val_loss: 1.7425 - val_accuracy: 0.3373\n",
      "Epoch 199/1000\n",
      "1176/1176 [==============================] - 0s 47us/step - loss: 1.7515 - accuracy: 0.3546 - val_loss: 1.7404 - val_accuracy: 0.3393\n",
      "Epoch 200/1000\n",
      "1176/1176 [==============================] - 0s 45us/step - loss: 1.7509 - accuracy: 0.3486 - val_loss: 1.7357 - val_accuracy: 0.3433\n",
      "Epoch 201/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.7549 - accuracy: 0.3495 - val_loss: 1.7391 - val_accuracy: 0.3433\n",
      "Epoch 202/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.7594 - accuracy: 0.3452 - val_loss: 1.7400 - val_accuracy: 0.3433\n",
      "Epoch 203/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.7326 - accuracy: 0.3571 - val_loss: 1.7338 - val_accuracy: 0.3413\n",
      "Epoch 204/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.7468 - accuracy: 0.3393 - val_loss: 1.7382 - val_accuracy: 0.3433\n",
      "Epoch 205/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.7383 - accuracy: 0.3639 - val_loss: 1.7368 - val_accuracy: 0.3433\n",
      "Epoch 206/1000\n",
      "1176/1176 [==============================] - 0s 45us/step - loss: 1.7525 - accuracy: 0.3410 - val_loss: 1.7437 - val_accuracy: 0.3294\n",
      "Epoch 207/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.7305 - accuracy: 0.3622 - val_loss: 1.7382 - val_accuracy: 0.3313\n",
      "Epoch 208/1000\n",
      "1176/1176 [==============================] - 0s 45us/step - loss: 1.7392 - accuracy: 0.3495 - val_loss: 1.7389 - val_accuracy: 0.3353\n",
      "Epoch 209/1000\n",
      "1176/1176 [==============================] - 0s 44us/step - loss: 1.7349 - accuracy: 0.3444 - val_loss: 1.7372 - val_accuracy: 0.3393\n",
      "Epoch 210/1000\n",
      "1176/1176 [==============================] - 0s 47us/step - loss: 1.7287 - accuracy: 0.3427 - val_loss: 1.7372 - val_accuracy: 0.3373\n",
      "Epoch 211/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1176/1176 [==============================] - 0s 40us/step - loss: 1.7268 - accuracy: 0.3563 - val_loss: 1.7296 - val_accuracy: 0.3492\n",
      "Epoch 212/1000\n",
      "1176/1176 [==============================] - 0s 40us/step - loss: 1.7431 - accuracy: 0.3316 - val_loss: 1.7309 - val_accuracy: 0.3413\n",
      "Epoch 213/1000\n",
      "1176/1176 [==============================] - 0s 40us/step - loss: 1.7466 - accuracy: 0.3469 - val_loss: 1.7353 - val_accuracy: 0.3452\n",
      "Epoch 214/1000\n",
      "1176/1176 [==============================] - 0s 40us/step - loss: 1.7488 - accuracy: 0.3469 - val_loss: 1.7384 - val_accuracy: 0.3353\n",
      "Epoch 215/1000\n",
      "1176/1176 [==============================] - 0s 41us/step - loss: 1.7354 - accuracy: 0.3478 - val_loss: 1.7389 - val_accuracy: 0.3353\n",
      "Epoch 216/1000\n",
      "1176/1176 [==============================] - 0s 41us/step - loss: 1.7285 - accuracy: 0.3597 - val_loss: 1.7412 - val_accuracy: 0.3353\n",
      "Epoch 217/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.7257 - accuracy: 0.3512 - val_loss: 1.7396 - val_accuracy: 0.3294\n",
      "Epoch 218/1000\n",
      "1176/1176 [==============================] - 0s 40us/step - loss: 1.7476 - accuracy: 0.3554 - val_loss: 1.7362 - val_accuracy: 0.3353\n",
      "Epoch 219/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.7284 - accuracy: 0.3418 - val_loss: 1.7404 - val_accuracy: 0.3294\n",
      "Epoch 220/1000\n",
      "1176/1176 [==============================] - 0s 41us/step - loss: 1.7367 - accuracy: 0.3512 - val_loss: 1.7361 - val_accuracy: 0.3353\n",
      "Epoch 221/1000\n",
      "1176/1176 [==============================] - 0s 47us/step - loss: 1.7413 - accuracy: 0.3554 - val_loss: 1.7328 - val_accuracy: 0.3393\n",
      "Epoch 222/1000\n",
      "1176/1176 [==============================] - 0s 47us/step - loss: 1.7341 - accuracy: 0.3418 - val_loss: 1.7354 - val_accuracy: 0.3373\n",
      "Epoch 223/1000\n",
      "1176/1176 [==============================] - 0s 55us/step - loss: 1.7362 - accuracy: 0.3639 - val_loss: 1.7382 - val_accuracy: 0.3333\n",
      "Epoch 224/1000\n",
      "1176/1176 [==============================] - 0s 48us/step - loss: 1.7432 - accuracy: 0.3401 - val_loss: 1.7361 - val_accuracy: 0.3393\n",
      "Epoch 225/1000\n",
      "1176/1176 [==============================] - 0s 43us/step - loss: 1.7450 - accuracy: 0.3478 - val_loss: 1.7412 - val_accuracy: 0.3274\n",
      "Epoch 226/1000\n",
      "1176/1176 [==============================] - 0s 53us/step - loss: 1.7453 - accuracy: 0.3325 - val_loss: 1.7363 - val_accuracy: 0.3353\n",
      "Epoch 227/1000\n",
      "1176/1176 [==============================] - 0s 45us/step - loss: 1.7347 - accuracy: 0.3410 - val_loss: 1.7385 - val_accuracy: 0.3353\n",
      "Epoch 228/1000\n",
      "1176/1176 [==============================] - 0s 40us/step - loss: 1.7337 - accuracy: 0.3554 - val_loss: 1.7356 - val_accuracy: 0.3433\n",
      "Epoch 229/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.7362 - accuracy: 0.3435 - val_loss: 1.7310 - val_accuracy: 0.3472\n",
      "Epoch 230/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.7382 - accuracy: 0.3410 - val_loss: 1.7321 - val_accuracy: 0.3433\n",
      "Epoch 231/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.7276 - accuracy: 0.3486 - val_loss: 1.7380 - val_accuracy: 0.3353\n",
      "Epoch 232/1000\n",
      "1176/1176 [==============================] - 0s 40us/step - loss: 1.7252 - accuracy: 0.3435 - val_loss: 1.7338 - val_accuracy: 0.3413\n",
      "Epoch 233/1000\n",
      "1176/1176 [==============================] - 0s 42us/step - loss: 1.7318 - accuracy: 0.3376 - val_loss: 1.7368 - val_accuracy: 0.3373\n",
      "Epoch 234/1000\n",
      "1176/1176 [==============================] - 0s 47us/step - loss: 1.7341 - accuracy: 0.3554 - val_loss: 1.7397 - val_accuracy: 0.3353\n",
      "Epoch 235/1000\n",
      "1176/1176 [==============================] - 0s 43us/step - loss: 1.7266 - accuracy: 0.3469 - val_loss: 1.7284 - val_accuracy: 0.3433\n",
      "Epoch 236/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.7369 - accuracy: 0.3495 - val_loss: 1.7290 - val_accuracy: 0.3452\n",
      "Epoch 237/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.7251 - accuracy: 0.3554 - val_loss: 1.7385 - val_accuracy: 0.3373\n",
      "Epoch 238/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.7319 - accuracy: 0.3512 - val_loss: 1.7321 - val_accuracy: 0.3413\n",
      "Epoch 239/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.7169 - accuracy: 0.3631 - val_loss: 1.7360 - val_accuracy: 0.3393\n",
      "Epoch 240/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.7338 - accuracy: 0.3401 - val_loss: 1.7326 - val_accuracy: 0.3472\n",
      "Epoch 241/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.7215 - accuracy: 0.3614 - val_loss: 1.7337 - val_accuracy: 0.3472\n",
      "Epoch 242/1000\n",
      "1176/1176 [==============================] - 0s 41us/step - loss: 1.7380 - accuracy: 0.3410 - val_loss: 1.7307 - val_accuracy: 0.3472\n",
      "Epoch 243/1000\n",
      "1176/1176 [==============================] - 0s 43us/step - loss: 1.7257 - accuracy: 0.3427 - val_loss: 1.7360 - val_accuracy: 0.3353\n",
      "Epoch 244/1000\n",
      "1176/1176 [==============================] - 0s 50us/step - loss: 1.7282 - accuracy: 0.3495 - val_loss: 1.7317 - val_accuracy: 0.3452\n",
      "Epoch 245/1000\n",
      "1176/1176 [==============================] - 0s 54us/step - loss: 1.7174 - accuracy: 0.3529 - val_loss: 1.7379 - val_accuracy: 0.3373\n",
      "Epoch 246/1000\n",
      "1176/1176 [==============================] - 0s 46us/step - loss: 1.7270 - accuracy: 0.3444 - val_loss: 1.7289 - val_accuracy: 0.3472\n",
      "Epoch 247/1000\n",
      "1176/1176 [==============================] - 0s 40us/step - loss: 1.7082 - accuracy: 0.3495 - val_loss: 1.7329 - val_accuracy: 0.3452\n",
      "Epoch 248/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.7320 - accuracy: 0.3546 - val_loss: 1.7281 - val_accuracy: 0.3492\n",
      "Epoch 249/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.7305 - accuracy: 0.3342 - val_loss: 1.7287 - val_accuracy: 0.3433\n",
      "Epoch 250/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.7175 - accuracy: 0.3410 - val_loss: 1.7293 - val_accuracy: 0.3452\n",
      "Epoch 251/1000\n",
      "1176/1176 [==============================] - 0s 36us/step - loss: 1.7189 - accuracy: 0.3554 - val_loss: 1.7279 - val_accuracy: 0.3472\n",
      "Epoch 252/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.7242 - accuracy: 0.3546 - val_loss: 1.7268 - val_accuracy: 0.3472\n",
      "Epoch 253/1000\n",
      "1176/1176 [==============================] - 0s 47us/step - loss: 1.7185 - accuracy: 0.3639 - val_loss: 1.7329 - val_accuracy: 0.3393\n",
      "Epoch 254/1000\n",
      "1176/1176 [==============================] - 0s 41us/step - loss: 1.7150 - accuracy: 0.3563 - val_loss: 1.7280 - val_accuracy: 0.3433\n",
      "Epoch 255/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.7212 - accuracy: 0.3495 - val_loss: 1.7279 - val_accuracy: 0.3413\n",
      "Epoch 256/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.7253 - accuracy: 0.3435 - val_loss: 1.7278 - val_accuracy: 0.3413\n",
      "Epoch 257/1000\n",
      "1176/1176 [==============================] - 0s 44us/step - loss: 1.7032 - accuracy: 0.3699 - val_loss: 1.7244 - val_accuracy: 0.3472\n",
      "Epoch 258/1000\n",
      "1176/1176 [==============================] - 0s 48us/step - loss: 1.7120 - accuracy: 0.3571 - val_loss: 1.7268 - val_accuracy: 0.3472\n",
      "Epoch 259/1000\n",
      "1176/1176 [==============================] - 0s 45us/step - loss: 1.7198 - accuracy: 0.3486 - val_loss: 1.7258 - val_accuracy: 0.3452\n",
      "Epoch 260/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.7090 - accuracy: 0.3486 - val_loss: 1.7268 - val_accuracy: 0.3492\n",
      "Epoch 261/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.7204 - accuracy: 0.3486 - val_loss: 1.7240 - val_accuracy: 0.3452\n",
      "Epoch 262/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.7201 - accuracy: 0.3495 - val_loss: 1.7273 - val_accuracy: 0.3492\n",
      "Epoch 263/1000\n",
      "1176/1176 [==============================] - 0s 44us/step - loss: 1.7220 - accuracy: 0.3410 - val_loss: 1.7285 - val_accuracy: 0.3472\n",
      "Epoch 264/1000\n",
      "1176/1176 [==============================] - 0s 43us/step - loss: 1.7106 - accuracy: 0.3554 - val_loss: 1.7276 - val_accuracy: 0.3452\n",
      "Epoch 265/1000\n",
      "1176/1176 [==============================] - 0s 50us/step - loss: 1.7322 - accuracy: 0.3597 - val_loss: 1.7317 - val_accuracy: 0.3452\n",
      "Epoch 266/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.7211 - accuracy: 0.3520 - val_loss: 1.7220 - val_accuracy: 0.3452\n",
      "Epoch 267/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.7218 - accuracy: 0.3699 - val_loss: 1.7209 - val_accuracy: 0.3452\n",
      "Epoch 268/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.7041 - accuracy: 0.3648 - val_loss: 1.7201 - val_accuracy: 0.3472\n",
      "Epoch 269/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.7220 - accuracy: 0.3656 - val_loss: 1.7245 - val_accuracy: 0.3492\n",
      "Epoch 270/1000\n",
      "1176/1176 [==============================] - 0s 36us/step - loss: 1.7037 - accuracy: 0.3546 - val_loss: 1.7201 - val_accuracy: 0.3452\n",
      "Epoch 271/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.7168 - accuracy: 0.3418 - val_loss: 1.7202 - val_accuracy: 0.3452\n",
      "Epoch 272/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.7244 - accuracy: 0.3563 - val_loss: 1.7269 - val_accuracy: 0.3393\n",
      "Epoch 273/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.7064 - accuracy: 0.3520 - val_loss: 1.7199 - val_accuracy: 0.3393\n",
      "Epoch 274/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.7093 - accuracy: 0.3537 - val_loss: 1.7185 - val_accuracy: 0.3433\n",
      "Epoch 275/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.7205 - accuracy: 0.3554 - val_loss: 1.7224 - val_accuracy: 0.3433\n",
      "Epoch 276/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.7095 - accuracy: 0.3546 - val_loss: 1.7255 - val_accuracy: 0.3393\n",
      "Epoch 277/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6982 - accuracy: 0.3580 - val_loss: 1.7198 - val_accuracy: 0.3373\n",
      "Epoch 278/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.7069 - accuracy: 0.3639 - val_loss: 1.7221 - val_accuracy: 0.3452\n",
      "Epoch 279/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.7192 - accuracy: 0.3648 - val_loss: 1.7203 - val_accuracy: 0.3433\n",
      "Epoch 280/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.7148 - accuracy: 0.3461 - val_loss: 1.7189 - val_accuracy: 0.3472\n",
      "Epoch 281/1000\n",
      "1176/1176 [==============================] - 0s 40us/step - loss: 1.7082 - accuracy: 0.3486 - val_loss: 1.7210 - val_accuracy: 0.3452\n",
      "Epoch 282/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.7181 - accuracy: 0.3537 - val_loss: 1.7186 - val_accuracy: 0.3433\n",
      "Epoch 283/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.6962 - accuracy: 0.3750 - val_loss: 1.7169 - val_accuracy: 0.3452\n",
      "Epoch 284/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.7028 - accuracy: 0.3512 - val_loss: 1.7222 - val_accuracy: 0.3452\n",
      "Epoch 285/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.7023 - accuracy: 0.3452 - val_loss: 1.7163 - val_accuracy: 0.3472\n",
      "Epoch 286/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.7112 - accuracy: 0.3427 - val_loss: 1.7203 - val_accuracy: 0.3433\n",
      "Epoch 287/1000\n",
      "1176/1176 [==============================] - 0s 42us/step - loss: 1.7071 - accuracy: 0.3622 - val_loss: 1.7165 - val_accuracy: 0.3452\n",
      "Epoch 288/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.7133 - accuracy: 0.3529 - val_loss: 1.7129 - val_accuracy: 0.3532\n",
      "Epoch 289/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6966 - accuracy: 0.3478 - val_loss: 1.7159 - val_accuracy: 0.3472\n",
      "Epoch 290/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.7031 - accuracy: 0.3546 - val_loss: 1.7140 - val_accuracy: 0.3532\n",
      "Epoch 291/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.7012 - accuracy: 0.3486 - val_loss: 1.7194 - val_accuracy: 0.3413\n",
      "Epoch 292/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6989 - accuracy: 0.3469 - val_loss: 1.7147 - val_accuracy: 0.3433\n",
      "Epoch 293/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.7022 - accuracy: 0.3580 - val_loss: 1.7124 - val_accuracy: 0.3433\n",
      "Epoch 294/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6965 - accuracy: 0.3478 - val_loss: 1.7090 - val_accuracy: 0.3532\n",
      "Epoch 295/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6939 - accuracy: 0.3682 - val_loss: 1.7112 - val_accuracy: 0.3512\n",
      "Epoch 296/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6925 - accuracy: 0.3537 - val_loss: 1.7106 - val_accuracy: 0.3512\n",
      "Epoch 297/1000\n",
      "1176/1176 [==============================] - 0s 41us/step - loss: 1.7121 - accuracy: 0.3316 - val_loss: 1.7122 - val_accuracy: 0.3492\n",
      "Epoch 298/1000\n",
      "1176/1176 [==============================] - 0s 41us/step - loss: 1.6865 - accuracy: 0.3529 - val_loss: 1.7117 - val_accuracy: 0.3452\n",
      "Epoch 299/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.6914 - accuracy: 0.3631 - val_loss: 1.7075 - val_accuracy: 0.3532\n",
      "Epoch 300/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.7058 - accuracy: 0.3724 - val_loss: 1.7070 - val_accuracy: 0.3552\n",
      "Epoch 301/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.6992 - accuracy: 0.3444 - val_loss: 1.7056 - val_accuracy: 0.3472\n",
      "Epoch 302/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.6994 - accuracy: 0.3554 - val_loss: 1.7129 - val_accuracy: 0.3512\n",
      "Epoch 303/1000\n",
      "1176/1176 [==============================] - 0s 41us/step - loss: 1.6957 - accuracy: 0.3546 - val_loss: 1.7096 - val_accuracy: 0.3472\n",
      "Epoch 304/1000\n",
      "1176/1176 [==============================] - 0s 41us/step - loss: 1.6911 - accuracy: 0.3520 - val_loss: 1.7035 - val_accuracy: 0.3532\n",
      "Epoch 305/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.7002 - accuracy: 0.3546 - val_loss: 1.7011 - val_accuracy: 0.3591\n",
      "Epoch 306/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.6918 - accuracy: 0.3580 - val_loss: 1.7006 - val_accuracy: 0.3571\n",
      "Epoch 307/1000\n",
      "1176/1176 [==============================] - 0s 42us/step - loss: 1.6810 - accuracy: 0.3580 - val_loss: 1.6988 - val_accuracy: 0.3552\n",
      "Epoch 308/1000\n",
      "1176/1176 [==============================] - 0s 45us/step - loss: 1.6889 - accuracy: 0.3563 - val_loss: 1.7003 - val_accuracy: 0.3532\n",
      "Epoch 309/1000\n",
      "1176/1176 [==============================] - 0s 41us/step - loss: 1.6875 - accuracy: 0.3537 - val_loss: 1.6988 - val_accuracy: 0.3552\n",
      "Epoch 310/1000\n",
      "1176/1176 [==============================] - 0s 40us/step - loss: 1.6843 - accuracy: 0.3835 - val_loss: 1.6974 - val_accuracy: 0.3611\n",
      "Epoch 311/1000\n",
      "1176/1176 [==============================] - 0s 42us/step - loss: 1.6898 - accuracy: 0.3673 - val_loss: 1.7026 - val_accuracy: 0.3532\n",
      "Epoch 312/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.6897 - accuracy: 0.3554 - val_loss: 1.6981 - val_accuracy: 0.3532\n",
      "Epoch 313/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.6861 - accuracy: 0.3631 - val_loss: 1.7004 - val_accuracy: 0.3552\n",
      "Epoch 314/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6894 - accuracy: 0.3529 - val_loss: 1.6941 - val_accuracy: 0.3671\n",
      "Epoch 315/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6850 - accuracy: 0.3478 - val_loss: 1.7095 - val_accuracy: 0.3492\n",
      "Epoch 316/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.6870 - accuracy: 0.3810 - val_loss: 1.6953 - val_accuracy: 0.3571\n",
      "Epoch 317/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6847 - accuracy: 0.3563 - val_loss: 1.6919 - val_accuracy: 0.3631\n",
      "Epoch 318/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6936 - accuracy: 0.3537 - val_loss: 1.6911 - val_accuracy: 0.3651\n",
      "Epoch 319/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6839 - accuracy: 0.3622 - val_loss: 1.6921 - val_accuracy: 0.3611\n",
      "Epoch 320/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6732 - accuracy: 0.3707 - val_loss: 1.6898 - val_accuracy: 0.3591\n",
      "Epoch 321/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.7006 - accuracy: 0.3597 - val_loss: 1.6982 - val_accuracy: 0.3492\n",
      "Epoch 322/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6688 - accuracy: 0.3665 - val_loss: 1.6930 - val_accuracy: 0.3512\n",
      "Epoch 323/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6627 - accuracy: 0.3614 - val_loss: 1.6896 - val_accuracy: 0.3631\n",
      "Epoch 324/1000\n",
      "1176/1176 [==============================] - 0s 36us/step - loss: 1.6803 - accuracy: 0.3503 - val_loss: 1.6887 - val_accuracy: 0.3611\n",
      "Epoch 325/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6746 - accuracy: 0.3444 - val_loss: 1.6910 - val_accuracy: 0.3552\n",
      "Epoch 326/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.6803 - accuracy: 0.3588 - val_loss: 1.6903 - val_accuracy: 0.3571\n",
      "Epoch 327/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6701 - accuracy: 0.3605 - val_loss: 1.6898 - val_accuracy: 0.3532\n",
      "Epoch 328/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.6739 - accuracy: 0.3554 - val_loss: 1.6863 - val_accuracy: 0.3591\n",
      "Epoch 329/1000\n",
      "1176/1176 [==============================] - 0s 42us/step - loss: 1.6817 - accuracy: 0.3520 - val_loss: 1.6853 - val_accuracy: 0.3591\n",
      "Epoch 330/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6790 - accuracy: 0.3631 - val_loss: 1.6807 - val_accuracy: 0.3671\n",
      "Epoch 331/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6764 - accuracy: 0.3673 - val_loss: 1.6802 - val_accuracy: 0.3651\n",
      "Epoch 332/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6889 - accuracy: 0.3622 - val_loss: 1.6802 - val_accuracy: 0.3631\n",
      "Epoch 333/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6818 - accuracy: 0.3563 - val_loss: 1.6795 - val_accuracy: 0.3631\n",
      "Epoch 334/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6797 - accuracy: 0.3648 - val_loss: 1.6827 - val_accuracy: 0.3591\n",
      "Epoch 335/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6748 - accuracy: 0.3495 - val_loss: 1.6841 - val_accuracy: 0.3472\n",
      "Epoch 336/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.6789 - accuracy: 0.3546 - val_loss: 1.6848 - val_accuracy: 0.3452\n",
      "Epoch 337/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.6775 - accuracy: 0.3588 - val_loss: 1.6788 - val_accuracy: 0.3611\n",
      "Epoch 338/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6787 - accuracy: 0.3461 - val_loss: 1.6764 - val_accuracy: 0.3611\n",
      "Epoch 339/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6777 - accuracy: 0.3716 - val_loss: 1.6770 - val_accuracy: 0.3651\n",
      "Epoch 340/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.6722 - accuracy: 0.3614 - val_loss: 1.6793 - val_accuracy: 0.3492\n",
      "Epoch 341/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.6525 - accuracy: 0.3622 - val_loss: 1.6776 - val_accuracy: 0.3571\n",
      "Epoch 342/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6741 - accuracy: 0.3750 - val_loss: 1.6790 - val_accuracy: 0.3591\n",
      "Epoch 343/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6881 - accuracy: 0.3605 - val_loss: 1.6830 - val_accuracy: 0.3552\n",
      "Epoch 344/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6740 - accuracy: 0.3546 - val_loss: 1.6821 - val_accuracy: 0.3591\n",
      "Epoch 345/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.6659 - accuracy: 0.3741 - val_loss: 1.6812 - val_accuracy: 0.3532\n",
      "Epoch 346/1000\n",
      "1176/1176 [==============================] - 0s 40us/step - loss: 1.6697 - accuracy: 0.3656 - val_loss: 1.6763 - val_accuracy: 0.3651\n",
      "Epoch 347/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6589 - accuracy: 0.3699 - val_loss: 1.6766 - val_accuracy: 0.3512\n",
      "Epoch 348/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6660 - accuracy: 0.3580 - val_loss: 1.6775 - val_accuracy: 0.3631\n",
      "Epoch 349/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.6678 - accuracy: 0.3444 - val_loss: 1.6757 - val_accuracy: 0.3651\n",
      "Epoch 350/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6617 - accuracy: 0.3682 - val_loss: 1.6749 - val_accuracy: 0.3552\n",
      "Epoch 351/1000\n",
      "1176/1176 [==============================] - 0s 42us/step - loss: 1.6735 - accuracy: 0.3597 - val_loss: 1.6751 - val_accuracy: 0.3571\n",
      "Epoch 352/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.6779 - accuracy: 0.3580 - val_loss: 1.6729 - val_accuracy: 0.3651\n",
      "Epoch 353/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6603 - accuracy: 0.3588 - val_loss: 1.6703 - val_accuracy: 0.3671\n",
      "Epoch 354/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6639 - accuracy: 0.3724 - val_loss: 1.6740 - val_accuracy: 0.3591\n",
      "Epoch 355/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.6631 - accuracy: 0.3639 - val_loss: 1.6728 - val_accuracy: 0.3611\n",
      "Epoch 356/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.6570 - accuracy: 0.3588 - val_loss: 1.6759 - val_accuracy: 0.3571\n",
      "Epoch 357/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.6561 - accuracy: 0.3605 - val_loss: 1.6702 - val_accuracy: 0.3571\n",
      "Epoch 358/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6723 - accuracy: 0.3537 - val_loss: 1.6687 - val_accuracy: 0.3651\n",
      "Epoch 359/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6575 - accuracy: 0.3707 - val_loss: 1.6732 - val_accuracy: 0.3512\n",
      "Epoch 360/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6492 - accuracy: 0.3537 - val_loss: 1.6752 - val_accuracy: 0.3532\n",
      "Epoch 361/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6542 - accuracy: 0.3750 - val_loss: 1.6751 - val_accuracy: 0.3413\n",
      "Epoch 362/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6591 - accuracy: 0.3622 - val_loss: 1.6712 - val_accuracy: 0.3591\n",
      "Epoch 363/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6644 - accuracy: 0.3639 - val_loss: 1.6689 - val_accuracy: 0.3591\n",
      "Epoch 364/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6764 - accuracy: 0.3665 - val_loss: 1.6750 - val_accuracy: 0.3413\n",
      "Epoch 365/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6816 - accuracy: 0.3682 - val_loss: 1.6688 - val_accuracy: 0.3671\n",
      "Epoch 366/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.6542 - accuracy: 0.3648 - val_loss: 1.6673 - val_accuracy: 0.3690\n",
      "Epoch 367/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.6600 - accuracy: 0.3639 - val_loss: 1.6690 - val_accuracy: 0.3671\n",
      "Epoch 368/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.6673 - accuracy: 0.3716 - val_loss: 1.6692 - val_accuracy: 0.3690\n",
      "Epoch 369/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6566 - accuracy: 0.3546 - val_loss: 1.6698 - val_accuracy: 0.3690\n",
      "Epoch 370/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.6557 - accuracy: 0.3631 - val_loss: 1.6687 - val_accuracy: 0.3710\n",
      "Epoch 371/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.6463 - accuracy: 0.3759 - val_loss: 1.6710 - val_accuracy: 0.3710\n",
      "Epoch 372/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6636 - accuracy: 0.3707 - val_loss: 1.6692 - val_accuracy: 0.3690\n",
      "Epoch 373/1000\n",
      "1176/1176 [==============================] - 0s 43us/step - loss: 1.6657 - accuracy: 0.3571 - val_loss: 1.6699 - val_accuracy: 0.3651\n",
      "Epoch 374/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6521 - accuracy: 0.3673 - val_loss: 1.6697 - val_accuracy: 0.3690\n",
      "Epoch 375/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6572 - accuracy: 0.3469 - val_loss: 1.6680 - val_accuracy: 0.3730\n",
      "Epoch 376/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6448 - accuracy: 0.3673 - val_loss: 1.6646 - val_accuracy: 0.3690\n",
      "Epoch 377/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.6660 - accuracy: 0.3707 - val_loss: 1.6709 - val_accuracy: 0.3651\n",
      "Epoch 378/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6518 - accuracy: 0.3665 - val_loss: 1.6706 - val_accuracy: 0.3651\n",
      "Epoch 379/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6634 - accuracy: 0.3682 - val_loss: 1.6739 - val_accuracy: 0.3651\n",
      "Epoch 380/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6576 - accuracy: 0.3597 - val_loss: 1.6713 - val_accuracy: 0.3671\n",
      "Epoch 381/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6502 - accuracy: 0.3733 - val_loss: 1.6703 - val_accuracy: 0.3651\n",
      "Epoch 382/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6575 - accuracy: 0.3597 - val_loss: 1.6695 - val_accuracy: 0.3552\n",
      "Epoch 383/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6536 - accuracy: 0.3690 - val_loss: 1.6686 - val_accuracy: 0.3611\n",
      "Epoch 384/1000\n",
      "1176/1176 [==============================] - 0s 40us/step - loss: 1.6525 - accuracy: 0.3733 - val_loss: 1.6699 - val_accuracy: 0.3611\n",
      "Epoch 385/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.6543 - accuracy: 0.3699 - val_loss: 1.6702 - val_accuracy: 0.3571\n",
      "Epoch 386/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.6516 - accuracy: 0.3597 - val_loss: 1.6699 - val_accuracy: 0.3651\n",
      "Epoch 387/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6537 - accuracy: 0.3656 - val_loss: 1.6698 - val_accuracy: 0.3671\n",
      "Epoch 388/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6660 - accuracy: 0.3656 - val_loss: 1.6703 - val_accuracy: 0.3591\n",
      "Epoch 389/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6599 - accuracy: 0.3605 - val_loss: 1.6723 - val_accuracy: 0.3730\n",
      "Epoch 390/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.6559 - accuracy: 0.3861 - val_loss: 1.6723 - val_accuracy: 0.3611\n",
      "Epoch 391/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6546 - accuracy: 0.3665 - val_loss: 1.6695 - val_accuracy: 0.3690\n",
      "Epoch 392/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.6458 - accuracy: 0.3707 - val_loss: 1.6633 - val_accuracy: 0.3730\n",
      "Epoch 393/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.6433 - accuracy: 0.3741 - val_loss: 1.6677 - val_accuracy: 0.3611\n",
      "Epoch 394/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6542 - accuracy: 0.3605 - val_loss: 1.6695 - val_accuracy: 0.3532\n",
      "Epoch 395/1000\n",
      "1176/1176 [==============================] - 0s 44us/step - loss: 1.6482 - accuracy: 0.3546 - val_loss: 1.6700 - val_accuracy: 0.3591\n",
      "Epoch 396/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6468 - accuracy: 0.3648 - val_loss: 1.6735 - val_accuracy: 0.3512\n",
      "Epoch 397/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.6571 - accuracy: 0.3648 - val_loss: 1.6665 - val_accuracy: 0.3690\n",
      "Epoch 398/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.6596 - accuracy: 0.3597 - val_loss: 1.6683 - val_accuracy: 0.3671\n",
      "Epoch 399/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6751 - accuracy: 0.3563 - val_loss: 1.6719 - val_accuracy: 0.3611\n",
      "Epoch 400/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6499 - accuracy: 0.3716 - val_loss: 1.6704 - val_accuracy: 0.3591\n",
      "Epoch 401/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6450 - accuracy: 0.3733 - val_loss: 1.6680 - val_accuracy: 0.3671\n",
      "Epoch 402/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6660 - accuracy: 0.3648 - val_loss: 1.6667 - val_accuracy: 0.3611\n",
      "Epoch 403/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6503 - accuracy: 0.3554 - val_loss: 1.6674 - val_accuracy: 0.3512\n",
      "Epoch 404/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6578 - accuracy: 0.3529 - val_loss: 1.6682 - val_accuracy: 0.3611\n",
      "Epoch 405/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.6524 - accuracy: 0.3733 - val_loss: 1.6705 - val_accuracy: 0.3472\n",
      "Epoch 406/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6392 - accuracy: 0.3699 - val_loss: 1.6667 - val_accuracy: 0.3651\n",
      "Epoch 407/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6587 - accuracy: 0.3614 - val_loss: 1.6674 - val_accuracy: 0.3651\n",
      "Epoch 408/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6569 - accuracy: 0.3597 - val_loss: 1.6667 - val_accuracy: 0.3631\n",
      "Epoch 409/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6494 - accuracy: 0.3724 - val_loss: 1.6656 - val_accuracy: 0.3571\n",
      "Epoch 410/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.6395 - accuracy: 0.3716 - val_loss: 1.6680 - val_accuracy: 0.3512\n",
      "Epoch 411/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6347 - accuracy: 0.3878 - val_loss: 1.6696 - val_accuracy: 0.3591\n",
      "Epoch 412/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.6553 - accuracy: 0.3835 - val_loss: 1.6672 - val_accuracy: 0.3631\n",
      "Epoch 413/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.6592 - accuracy: 0.3614 - val_loss: 1.6671 - val_accuracy: 0.3571\n",
      "Epoch 414/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.6378 - accuracy: 0.3673 - val_loss: 1.6669 - val_accuracy: 0.3591\n",
      "Epoch 415/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.6479 - accuracy: 0.3614 - val_loss: 1.6640 - val_accuracy: 0.3671\n",
      "Epoch 416/1000\n",
      "1176/1176 [==============================] - 0s 43us/step - loss: 1.6464 - accuracy: 0.3750 - val_loss: 1.6644 - val_accuracy: 0.3690\n",
      "Epoch 417/1000\n",
      "1176/1176 [==============================] - 0s 44us/step - loss: 1.6486 - accuracy: 0.3682 - val_loss: 1.6623 - val_accuracy: 0.3611\n",
      "Epoch 418/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.6530 - accuracy: 0.3750 - val_loss: 1.6632 - val_accuracy: 0.3671\n",
      "Epoch 419/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6491 - accuracy: 0.3614 - val_loss: 1.6639 - val_accuracy: 0.3631\n",
      "Epoch 420/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6521 - accuracy: 0.3656 - val_loss: 1.6658 - val_accuracy: 0.3591\n",
      "Epoch 421/1000\n",
      "1176/1176 [==============================] - 0s 40us/step - loss: 1.6482 - accuracy: 0.3665 - val_loss: 1.6665 - val_accuracy: 0.3671\n",
      "Epoch 422/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.6403 - accuracy: 0.3707 - val_loss: 1.6650 - val_accuracy: 0.3631\n",
      "Epoch 423/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.6523 - accuracy: 0.3665 - val_loss: 1.6626 - val_accuracy: 0.3671\n",
      "Epoch 424/1000\n",
      "1176/1176 [==============================] - 0s 41us/step - loss: 1.6504 - accuracy: 0.3563 - val_loss: 1.6632 - val_accuracy: 0.3651\n",
      "Epoch 425/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.6474 - accuracy: 0.3673 - val_loss: 1.6649 - val_accuracy: 0.3591\n",
      "Epoch 426/1000\n",
      "1176/1176 [==============================] - 0s 40us/step - loss: 1.6498 - accuracy: 0.3827 - val_loss: 1.6664 - val_accuracy: 0.3671\n",
      "Epoch 427/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.6502 - accuracy: 0.3639 - val_loss: 1.6640 - val_accuracy: 0.3611\n",
      "Epoch 428/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6552 - accuracy: 0.3682 - val_loss: 1.6662 - val_accuracy: 0.3591\n",
      "Epoch 429/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.6686 - accuracy: 0.3639 - val_loss: 1.6638 - val_accuracy: 0.3571\n",
      "Epoch 430/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.6320 - accuracy: 0.3852 - val_loss: 1.6661 - val_accuracy: 0.3591\n",
      "Epoch 431/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.6473 - accuracy: 0.3673 - val_loss: 1.6636 - val_accuracy: 0.3552\n",
      "Epoch 432/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.6531 - accuracy: 0.3648 - val_loss: 1.6618 - val_accuracy: 0.3591\n",
      "Epoch 433/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.6579 - accuracy: 0.3759 - val_loss: 1.6613 - val_accuracy: 0.3611\n",
      "Epoch 434/1000\n",
      "1176/1176 [==============================] - 0s 45us/step - loss: 1.6467 - accuracy: 0.3784 - val_loss: 1.6615 - val_accuracy: 0.3591\n",
      "Epoch 435/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.6590 - accuracy: 0.3546 - val_loss: 1.6639 - val_accuracy: 0.3571\n",
      "Epoch 436/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6440 - accuracy: 0.3707 - val_loss: 1.6619 - val_accuracy: 0.3591\n",
      "Epoch 437/1000\n",
      "1176/1176 [==============================] - 0s 42us/step - loss: 1.6523 - accuracy: 0.3741 - val_loss: 1.6617 - val_accuracy: 0.3671\n",
      "Epoch 438/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6513 - accuracy: 0.3656 - val_loss: 1.6618 - val_accuracy: 0.3631\n",
      "Epoch 439/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6545 - accuracy: 0.3724 - val_loss: 1.6670 - val_accuracy: 0.3690\n",
      "Epoch 440/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6463 - accuracy: 0.3639 - val_loss: 1.6699 - val_accuracy: 0.3631\n",
      "Epoch 441/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.6398 - accuracy: 0.3665 - val_loss: 1.6663 - val_accuracy: 0.3591\n",
      "Epoch 442/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6548 - accuracy: 0.3571 - val_loss: 1.6632 - val_accuracy: 0.3690\n",
      "Epoch 443/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.6438 - accuracy: 0.3741 - val_loss: 1.6686 - val_accuracy: 0.3671\n",
      "Epoch 444/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6538 - accuracy: 0.3656 - val_loss: 1.6644 - val_accuracy: 0.3611\n",
      "Epoch 445/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6352 - accuracy: 0.3682 - val_loss: 1.6626 - val_accuracy: 0.3690\n",
      "Epoch 446/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6481 - accuracy: 0.3741 - val_loss: 1.6631 - val_accuracy: 0.3671\n",
      "Epoch 447/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6605 - accuracy: 0.3614 - val_loss: 1.6639 - val_accuracy: 0.3651\n",
      "Epoch 448/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6502 - accuracy: 0.3554 - val_loss: 1.6659 - val_accuracy: 0.3611\n",
      "Epoch 449/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6411 - accuracy: 0.3673 - val_loss: 1.6645 - val_accuracy: 0.3671\n",
      "Epoch 450/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6523 - accuracy: 0.3750 - val_loss: 1.6608 - val_accuracy: 0.3651\n",
      "Epoch 451/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6481 - accuracy: 0.3673 - val_loss: 1.6610 - val_accuracy: 0.3651\n",
      "Epoch 452/1000\n",
      "1176/1176 [==============================] - 0s 52us/step - loss: 1.6521 - accuracy: 0.3707 - val_loss: 1.6640 - val_accuracy: 0.3690\n",
      "Epoch 453/1000\n",
      "1176/1176 [==============================] - 0s 42us/step - loss: 1.6477 - accuracy: 0.3571 - val_loss: 1.6584 - val_accuracy: 0.3571\n",
      "Epoch 454/1000\n",
      "1176/1176 [==============================] - 0s 41us/step - loss: 1.6495 - accuracy: 0.3690 - val_loss: 1.6627 - val_accuracy: 0.3651\n",
      "Epoch 455/1000\n",
      "1176/1176 [==============================] - 0s 40us/step - loss: 1.6460 - accuracy: 0.3682 - val_loss: 1.6686 - val_accuracy: 0.3591\n",
      "Epoch 456/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.6422 - accuracy: 0.3614 - val_loss: 1.6659 - val_accuracy: 0.3651\n",
      "Epoch 457/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.6449 - accuracy: 0.3597 - val_loss: 1.6658 - val_accuracy: 0.3552\n",
      "Epoch 458/1000\n",
      "1176/1176 [==============================] - 0s 43us/step - loss: 1.6491 - accuracy: 0.3759 - val_loss: 1.6650 - val_accuracy: 0.3571\n",
      "Epoch 459/1000\n",
      "1176/1176 [==============================] - 0s 40us/step - loss: 1.6414 - accuracy: 0.3716 - val_loss: 1.6661 - val_accuracy: 0.3631\n",
      "Epoch 460/1000\n",
      "1176/1176 [==============================] - 0s 40us/step - loss: 1.6467 - accuracy: 0.3801 - val_loss: 1.6623 - val_accuracy: 0.3611\n",
      "Epoch 461/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.6412 - accuracy: 0.3614 - val_loss: 1.6635 - val_accuracy: 0.3611\n",
      "Epoch 462/1000\n",
      "1176/1176 [==============================] - 0s 45us/step - loss: 1.6417 - accuracy: 0.3656 - val_loss: 1.6644 - val_accuracy: 0.3611\n",
      "Epoch 463/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.6534 - accuracy: 0.3631 - val_loss: 1.6637 - val_accuracy: 0.3651\n",
      "Epoch 464/1000\n",
      "1176/1176 [==============================] - 0s 41us/step - loss: 1.6400 - accuracy: 0.3631 - val_loss: 1.6661 - val_accuracy: 0.3631\n",
      "Epoch 465/1000\n",
      "1176/1176 [==============================] - 0s 40us/step - loss: 1.6416 - accuracy: 0.3699 - val_loss: 1.6667 - val_accuracy: 0.3631\n",
      "Epoch 466/1000\n",
      "1176/1176 [==============================] - 0s 42us/step - loss: 1.6456 - accuracy: 0.3571 - val_loss: 1.6682 - val_accuracy: 0.3591\n",
      "Epoch 467/1000\n",
      "1176/1176 [==============================] - 0s 40us/step - loss: 1.6313 - accuracy: 0.3844 - val_loss: 1.6663 - val_accuracy: 0.3591\n",
      "Epoch 468/1000\n",
      "1176/1176 [==============================] - 0s 40us/step - loss: 1.6287 - accuracy: 0.3724 - val_loss: 1.6711 - val_accuracy: 0.3671\n",
      "Epoch 469/1000\n",
      "1176/1176 [==============================] - 0s 40us/step - loss: 1.6392 - accuracy: 0.3716 - val_loss: 1.6664 - val_accuracy: 0.3631\n",
      "Epoch 470/1000\n",
      "1176/1176 [==============================] - 0s 40us/step - loss: 1.6305 - accuracy: 0.3665 - val_loss: 1.6674 - val_accuracy: 0.3631\n",
      "Epoch 471/1000\n",
      "1176/1176 [==============================] - 0s 40us/step - loss: 1.6347 - accuracy: 0.3665 - val_loss: 1.6686 - val_accuracy: 0.3571\n",
      "Epoch 472/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.6536 - accuracy: 0.3895 - val_loss: 1.6686 - val_accuracy: 0.3571\n",
      "Epoch 473/1000\n",
      "1176/1176 [==============================] - 0s 40us/step - loss: 1.6553 - accuracy: 0.3690 - val_loss: 1.6648 - val_accuracy: 0.3591\n",
      "Epoch 474/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.6497 - accuracy: 0.3631 - val_loss: 1.6659 - val_accuracy: 0.3532\n",
      "Epoch 475/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6369 - accuracy: 0.3673 - val_loss: 1.6692 - val_accuracy: 0.3591\n",
      "Epoch 476/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.6376 - accuracy: 0.3639 - val_loss: 1.6675 - val_accuracy: 0.3591\n",
      "Epoch 477/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.6370 - accuracy: 0.3750 - val_loss: 1.6683 - val_accuracy: 0.3710\n",
      "Epoch 478/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.6524 - accuracy: 0.3724 - val_loss: 1.6633 - val_accuracy: 0.3631\n",
      "Epoch 479/1000\n",
      "1176/1176 [==============================] - 0s 45us/step - loss: 1.6422 - accuracy: 0.3759 - val_loss: 1.6649 - val_accuracy: 0.3591\n",
      "Epoch 480/1000\n",
      "1176/1176 [==============================] - 0s 40us/step - loss: 1.6364 - accuracy: 0.3665 - val_loss: 1.6642 - val_accuracy: 0.3631\n",
      "Epoch 481/1000\n",
      "1176/1176 [==============================] - 0s 40us/step - loss: 1.6351 - accuracy: 0.3682 - val_loss: 1.6671 - val_accuracy: 0.3571\n",
      "Epoch 482/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.6455 - accuracy: 0.3495 - val_loss: 1.6687 - val_accuracy: 0.3591\n",
      "Epoch 483/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6366 - accuracy: 0.3767 - val_loss: 1.6701 - val_accuracy: 0.3651\n",
      "Epoch 484/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.6411 - accuracy: 0.3869 - val_loss: 1.6628 - val_accuracy: 0.3611\n",
      "Epoch 485/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.6461 - accuracy: 0.3716 - val_loss: 1.6678 - val_accuracy: 0.3651\n",
      "Epoch 486/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1176/1176 [==============================] - 0s 40us/step - loss: 1.6450 - accuracy: 0.3682 - val_loss: 1.6644 - val_accuracy: 0.3611\n",
      "Epoch 487/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.6455 - accuracy: 0.3750 - val_loss: 1.6677 - val_accuracy: 0.3631\n",
      "Epoch 488/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6333 - accuracy: 0.3665 - val_loss: 1.6691 - val_accuracy: 0.3591\n",
      "Epoch 489/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6371 - accuracy: 0.3801 - val_loss: 1.6652 - val_accuracy: 0.3651\n",
      "Epoch 490/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.6398 - accuracy: 0.3784 - val_loss: 1.6657 - val_accuracy: 0.3710\n",
      "Epoch 491/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.6404 - accuracy: 0.3699 - val_loss: 1.6684 - val_accuracy: 0.3611\n",
      "Epoch 492/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.6465 - accuracy: 0.3546 - val_loss: 1.6677 - val_accuracy: 0.3611\n",
      "Epoch 493/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6443 - accuracy: 0.3716 - val_loss: 1.6711 - val_accuracy: 0.3611\n",
      "Epoch 494/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6450 - accuracy: 0.3665 - val_loss: 1.6692 - val_accuracy: 0.3591\n",
      "Epoch 495/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.6430 - accuracy: 0.3690 - val_loss: 1.6677 - val_accuracy: 0.3611\n",
      "Epoch 496/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.6504 - accuracy: 0.3631 - val_loss: 1.6667 - val_accuracy: 0.3611\n",
      "Epoch 497/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6442 - accuracy: 0.3707 - val_loss: 1.6686 - val_accuracy: 0.3631\n",
      "Epoch 498/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6328 - accuracy: 0.3750 - val_loss: 1.6674 - val_accuracy: 0.3591\n",
      "Epoch 499/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.6460 - accuracy: 0.3673 - val_loss: 1.6755 - val_accuracy: 0.3631\n",
      "Epoch 500/1000\n",
      "1176/1176 [==============================] - 0s 44us/step - loss: 1.6532 - accuracy: 0.3580 - val_loss: 1.6696 - val_accuracy: 0.3591\n",
      "Epoch 501/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6348 - accuracy: 0.3665 - val_loss: 1.6720 - val_accuracy: 0.3611\n",
      "Epoch 502/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.6310 - accuracy: 0.3827 - val_loss: 1.6677 - val_accuracy: 0.3512\n",
      "Epoch 503/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.6294 - accuracy: 0.3767 - val_loss: 1.6692 - val_accuracy: 0.3532\n",
      "Epoch 504/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.6608 - accuracy: 0.3810 - val_loss: 1.6677 - val_accuracy: 0.3532\n",
      "Epoch 505/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.6359 - accuracy: 0.3631 - val_loss: 1.6672 - val_accuracy: 0.3611\n",
      "Epoch 506/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.6266 - accuracy: 0.3852 - val_loss: 1.6654 - val_accuracy: 0.3611\n",
      "Epoch 507/1000\n",
      "1176/1176 [==============================] - 0s 40us/step - loss: 1.6394 - accuracy: 0.3776 - val_loss: 1.6655 - val_accuracy: 0.3571\n",
      "Epoch 508/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6329 - accuracy: 0.3767 - val_loss: 1.6650 - val_accuracy: 0.3671\n",
      "Epoch 509/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.6436 - accuracy: 0.3784 - val_loss: 1.6646 - val_accuracy: 0.3611\n",
      "Epoch 510/1000\n",
      "1176/1176 [==============================] - 0s 40us/step - loss: 1.6300 - accuracy: 0.3741 - val_loss: 1.6679 - val_accuracy: 0.3651\n",
      "Epoch 511/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.6279 - accuracy: 0.3750 - val_loss: 1.6661 - val_accuracy: 0.3631\n",
      "Epoch 512/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.6335 - accuracy: 0.3648 - val_loss: 1.6705 - val_accuracy: 0.3631\n",
      "Epoch 513/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.6308 - accuracy: 0.3605 - val_loss: 1.6646 - val_accuracy: 0.3671\n",
      "Epoch 514/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.6435 - accuracy: 0.3699 - val_loss: 1.6679 - val_accuracy: 0.3631\n",
      "Epoch 515/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6331 - accuracy: 0.3741 - val_loss: 1.6681 - val_accuracy: 0.3651\n",
      "Epoch 516/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.6513 - accuracy: 0.3614 - val_loss: 1.6686 - val_accuracy: 0.3532\n",
      "Epoch 517/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.6342 - accuracy: 0.3707 - val_loss: 1.6727 - val_accuracy: 0.3591\n",
      "Epoch 518/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.6503 - accuracy: 0.3639 - val_loss: 1.6691 - val_accuracy: 0.3631\n",
      "Epoch 519/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.6473 - accuracy: 0.3563 - val_loss: 1.6662 - val_accuracy: 0.3671\n",
      "Epoch 520/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6407 - accuracy: 0.3835 - val_loss: 1.6700 - val_accuracy: 0.3571\n",
      "Epoch 521/1000\n",
      "1176/1176 [==============================] - 0s 44us/step - loss: 1.6417 - accuracy: 0.3716 - val_loss: 1.6672 - val_accuracy: 0.3611\n",
      "Epoch 522/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.6490 - accuracy: 0.3733 - val_loss: 1.6689 - val_accuracy: 0.3591\n",
      "Epoch 523/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6324 - accuracy: 0.3767 - val_loss: 1.6704 - val_accuracy: 0.3611\n",
      "Epoch 524/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.6433 - accuracy: 0.3690 - val_loss: 1.6681 - val_accuracy: 0.3591\n",
      "Epoch 525/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.6371 - accuracy: 0.3682 - val_loss: 1.6666 - val_accuracy: 0.3552\n",
      "Epoch 526/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6388 - accuracy: 0.3699 - val_loss: 1.6673 - val_accuracy: 0.3532\n",
      "Epoch 527/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.6326 - accuracy: 0.3707 - val_loss: 1.6679 - val_accuracy: 0.3571\n",
      "Epoch 528/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6197 - accuracy: 0.3707 - val_loss: 1.6673 - val_accuracy: 0.3651\n",
      "Epoch 529/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.6419 - accuracy: 0.3886 - val_loss: 1.6707 - val_accuracy: 0.3591\n",
      "Epoch 530/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6335 - accuracy: 0.3682 - val_loss: 1.6713 - val_accuracy: 0.3591\n",
      "Epoch 531/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6452 - accuracy: 0.3597 - val_loss: 1.6661 - val_accuracy: 0.3631\n",
      "Epoch 532/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6366 - accuracy: 0.3776 - val_loss: 1.6659 - val_accuracy: 0.3651\n",
      "Epoch 533/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6350 - accuracy: 0.3690 - val_loss: 1.6651 - val_accuracy: 0.3671\n",
      "Epoch 534/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6427 - accuracy: 0.3690 - val_loss: 1.6677 - val_accuracy: 0.3611\n",
      "Epoch 535/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6148 - accuracy: 0.3818 - val_loss: 1.6775 - val_accuracy: 0.3611\n",
      "Epoch 536/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.6316 - accuracy: 0.3750 - val_loss: 1.6650 - val_accuracy: 0.3591\n",
      "Epoch 537/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.6249 - accuracy: 0.3750 - val_loss: 1.6682 - val_accuracy: 0.3571\n",
      "Epoch 538/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6434 - accuracy: 0.3750 - val_loss: 1.6662 - val_accuracy: 0.3611\n",
      "Epoch 539/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.6308 - accuracy: 0.3784 - val_loss: 1.6702 - val_accuracy: 0.3611\n",
      "Epoch 540/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.6452 - accuracy: 0.3597 - val_loss: 1.6659 - val_accuracy: 0.3651\n",
      "Epoch 541/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6541 - accuracy: 0.3707 - val_loss: 1.6713 - val_accuracy: 0.3631\n",
      "Epoch 542/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.6363 - accuracy: 0.3554 - val_loss: 1.6704 - val_accuracy: 0.3591\n",
      "Epoch 543/1000\n",
      "1176/1176 [==============================] - 0s 43us/step - loss: 1.6401 - accuracy: 0.3707 - val_loss: 1.6672 - val_accuracy: 0.3532\n",
      "Epoch 544/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.6395 - accuracy: 0.3622 - val_loss: 1.6729 - val_accuracy: 0.3571\n",
      "Epoch 545/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.6331 - accuracy: 0.3759 - val_loss: 1.6664 - val_accuracy: 0.3651\n",
      "Epoch 546/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.6394 - accuracy: 0.3639 - val_loss: 1.6697 - val_accuracy: 0.3571\n",
      "Epoch 547/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.6328 - accuracy: 0.3776 - val_loss: 1.6640 - val_accuracy: 0.3571\n",
      "Epoch 548/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.6222 - accuracy: 0.3759 - val_loss: 1.6664 - val_accuracy: 0.3591\n",
      "Epoch 549/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.6208 - accuracy: 0.3733 - val_loss: 1.6650 - val_accuracy: 0.3631\n",
      "Epoch 550/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6390 - accuracy: 0.3707 - val_loss: 1.6693 - val_accuracy: 0.3631\n",
      "Epoch 551/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6411 - accuracy: 0.3827 - val_loss: 1.6686 - val_accuracy: 0.3591\n",
      "Epoch 552/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.6359 - accuracy: 0.3648 - val_loss: 1.6671 - val_accuracy: 0.3631\n",
      "Epoch 553/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6317 - accuracy: 0.3852 - val_loss: 1.6678 - val_accuracy: 0.3611\n",
      "Epoch 554/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6363 - accuracy: 0.3665 - val_loss: 1.6684 - val_accuracy: 0.3552\n",
      "Epoch 555/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6271 - accuracy: 0.3639 - val_loss: 1.6695 - val_accuracy: 0.3591\n",
      "Epoch 556/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6314 - accuracy: 0.3759 - val_loss: 1.6699 - val_accuracy: 0.3571\n",
      "Epoch 557/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.6300 - accuracy: 0.3699 - val_loss: 1.6709 - val_accuracy: 0.3611\n",
      "Epoch 558/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6296 - accuracy: 0.3835 - val_loss: 1.6723 - val_accuracy: 0.3571\n",
      "Epoch 559/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.6328 - accuracy: 0.3741 - val_loss: 1.6655 - val_accuracy: 0.3671\n",
      "Epoch 560/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.6466 - accuracy: 0.3673 - val_loss: 1.6644 - val_accuracy: 0.3651\n",
      "Epoch 561/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.6203 - accuracy: 0.3759 - val_loss: 1.6665 - val_accuracy: 0.3671\n",
      "Epoch 562/1000\n",
      "1176/1176 [==============================] - 0s 69us/step - loss: 1.6260 - accuracy: 0.3605 - val_loss: 1.6692 - val_accuracy: 0.3631\n",
      "Epoch 563/1000\n",
      "1176/1176 [==============================] - 0s 48us/step - loss: 1.6426 - accuracy: 0.3597 - val_loss: 1.6711 - val_accuracy: 0.3611\n",
      "Epoch 564/1000\n",
      "1176/1176 [==============================] - 0s 41us/step - loss: 1.6279 - accuracy: 0.3699 - val_loss: 1.6663 - val_accuracy: 0.3671\n",
      "Epoch 565/1000\n",
      "1176/1176 [==============================] - 0s 40us/step - loss: 1.6312 - accuracy: 0.3580 - val_loss: 1.6718 - val_accuracy: 0.3591\n",
      "Epoch 566/1000\n",
      "1176/1176 [==============================] - 0s 40us/step - loss: 1.6330 - accuracy: 0.3716 - val_loss: 1.6741 - val_accuracy: 0.3552\n",
      "Epoch 567/1000\n",
      "1176/1176 [==============================] - 0s 41us/step - loss: 1.6391 - accuracy: 0.3818 - val_loss: 1.6693 - val_accuracy: 0.3611\n",
      "Epoch 568/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.6378 - accuracy: 0.3733 - val_loss: 1.6709 - val_accuracy: 0.3611\n",
      "Epoch 569/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.6331 - accuracy: 0.3614 - val_loss: 1.6710 - val_accuracy: 0.3671\n",
      "Epoch 570/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6214 - accuracy: 0.3810 - val_loss: 1.6677 - val_accuracy: 0.3690\n",
      "Epoch 571/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6199 - accuracy: 0.3810 - val_loss: 1.6710 - val_accuracy: 0.3631\n",
      "Epoch 572/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.6373 - accuracy: 0.3716 - val_loss: 1.6677 - val_accuracy: 0.3690\n",
      "Epoch 573/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.6328 - accuracy: 0.3563 - val_loss: 1.6667 - val_accuracy: 0.3690\n",
      "Epoch 574/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6324 - accuracy: 0.3776 - val_loss: 1.6709 - val_accuracy: 0.3651\n",
      "Epoch 575/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6354 - accuracy: 0.3699 - val_loss: 1.6660 - val_accuracy: 0.3631\n",
      "Epoch 576/1000\n",
      "1176/1176 [==============================] - 0s 42us/step - loss: 1.6161 - accuracy: 0.3759 - val_loss: 1.6746 - val_accuracy: 0.3591\n",
      "Epoch 577/1000\n",
      "1176/1176 [==============================] - 0s 42us/step - loss: 1.6288 - accuracy: 0.3844 - val_loss: 1.6721 - val_accuracy: 0.3651\n",
      "Epoch 578/1000\n",
      "1176/1176 [==============================] - 0s 45us/step - loss: 1.6317 - accuracy: 0.3801 - val_loss: 1.6720 - val_accuracy: 0.3611\n",
      "Epoch 579/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.6315 - accuracy: 0.3546 - val_loss: 1.6671 - val_accuracy: 0.3651\n",
      "Epoch 580/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.6250 - accuracy: 0.3827 - val_loss: 1.6667 - val_accuracy: 0.3631\n",
      "Epoch 581/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.6453 - accuracy: 0.3597 - val_loss: 1.6688 - val_accuracy: 0.3631\n",
      "Epoch 582/1000\n",
      "1176/1176 [==============================] - 0s 42us/step - loss: 1.6295 - accuracy: 0.3733 - val_loss: 1.6650 - val_accuracy: 0.3671\n",
      "Epoch 583/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.6343 - accuracy: 0.3597 - val_loss: 1.6746 - val_accuracy: 0.3710\n",
      "Epoch 584/1000\n",
      "1176/1176 [==============================] - 0s 46us/step - loss: 1.6269 - accuracy: 0.3852 - val_loss: 1.6702 - val_accuracy: 0.3710\n",
      "Epoch 585/1000\n",
      "1176/1176 [==============================] - 0s 42us/step - loss: 1.6376 - accuracy: 0.3741 - val_loss: 1.6736 - val_accuracy: 0.3671\n",
      "Epoch 586/1000\n",
      "1176/1176 [==============================] - 0s 42us/step - loss: 1.6429 - accuracy: 0.3699 - val_loss: 1.6687 - val_accuracy: 0.3611\n",
      "Epoch 587/1000\n",
      "1176/1176 [==============================] - 0s 41us/step - loss: 1.6209 - accuracy: 0.3648 - val_loss: 1.6761 - val_accuracy: 0.3611\n",
      "Epoch 588/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.6294 - accuracy: 0.3690 - val_loss: 1.6732 - val_accuracy: 0.3611\n",
      "Epoch 589/1000\n",
      "1176/1176 [==============================] - 0s 40us/step - loss: 1.6276 - accuracy: 0.3673 - val_loss: 1.6681 - val_accuracy: 0.3671\n",
      "Epoch 590/1000\n",
      "1176/1176 [==============================] - 0s 42us/step - loss: 1.6304 - accuracy: 0.3750 - val_loss: 1.6684 - val_accuracy: 0.3651\n",
      "Epoch 591/1000\n",
      "1176/1176 [==============================] - 0s 40us/step - loss: 1.6431 - accuracy: 0.3750 - val_loss: 1.6708 - val_accuracy: 0.3690\n",
      "Epoch 592/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6276 - accuracy: 0.3903 - val_loss: 1.6652 - val_accuracy: 0.3671\n",
      "Epoch 593/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6367 - accuracy: 0.3614 - val_loss: 1.6720 - val_accuracy: 0.3631\n",
      "Epoch 594/1000\n",
      "1176/1176 [==============================] - 0s 40us/step - loss: 1.6237 - accuracy: 0.3750 - val_loss: 1.6713 - val_accuracy: 0.3571\n",
      "Epoch 595/1000\n",
      "1176/1176 [==============================] - 0s 40us/step - loss: 1.6444 - accuracy: 0.3648 - val_loss: 1.6703 - val_accuracy: 0.3631\n",
      "Epoch 596/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6210 - accuracy: 0.3801 - val_loss: 1.6774 - val_accuracy: 0.3591\n",
      "Epoch 597/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.6184 - accuracy: 0.3895 - val_loss: 1.6683 - val_accuracy: 0.3671\n",
      "Epoch 598/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6537 - accuracy: 0.3759 - val_loss: 1.6682 - val_accuracy: 0.3532\n",
      "Epoch 599/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6487 - accuracy: 0.3776 - val_loss: 1.6730 - val_accuracy: 0.3532\n",
      "Epoch 600/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.6404 - accuracy: 0.3793 - val_loss: 1.6758 - val_accuracy: 0.3671\n",
      "Epoch 601/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.6271 - accuracy: 0.3699 - val_loss: 1.6680 - val_accuracy: 0.3591\n",
      "Epoch 602/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.6320 - accuracy: 0.3733 - val_loss: 1.6694 - val_accuracy: 0.3611\n",
      "Epoch 603/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.6255 - accuracy: 0.3716 - val_loss: 1.6720 - val_accuracy: 0.3571\n",
      "Epoch 604/1000\n",
      "1176/1176 [==============================] - 0s 40us/step - loss: 1.6295 - accuracy: 0.3784 - val_loss: 1.6725 - val_accuracy: 0.3591\n",
      "Epoch 605/1000\n",
      "1176/1176 [==============================] - 0s 45us/step - loss: 1.6376 - accuracy: 0.3716 - val_loss: 1.6709 - val_accuracy: 0.3611\n",
      "Epoch 606/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6308 - accuracy: 0.3707 - val_loss: 1.6755 - val_accuracy: 0.3591\n",
      "Epoch 607/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6342 - accuracy: 0.3741 - val_loss: 1.6713 - val_accuracy: 0.3631\n",
      "Epoch 608/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.6452 - accuracy: 0.3699 - val_loss: 1.6742 - val_accuracy: 0.3611\n",
      "Epoch 609/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.6265 - accuracy: 0.3690 - val_loss: 1.6712 - val_accuracy: 0.3690\n",
      "Epoch 610/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6336 - accuracy: 0.3759 - val_loss: 1.6673 - val_accuracy: 0.3651\n",
      "Epoch 611/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6240 - accuracy: 0.3716 - val_loss: 1.6760 - val_accuracy: 0.3631\n",
      "Epoch 612/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6228 - accuracy: 0.3759 - val_loss: 1.6774 - val_accuracy: 0.3651\n",
      "Epoch 613/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.6292 - accuracy: 0.3699 - val_loss: 1.6764 - val_accuracy: 0.3651\n",
      "Epoch 614/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.6223 - accuracy: 0.3682 - val_loss: 1.6711 - val_accuracy: 0.3651\n",
      "Epoch 615/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.6199 - accuracy: 0.3784 - val_loss: 1.6758 - val_accuracy: 0.3651\n",
      "Epoch 616/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6387 - accuracy: 0.3741 - val_loss: 1.6649 - val_accuracy: 0.3611\n",
      "Epoch 617/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.6356 - accuracy: 0.3827 - val_loss: 1.6698 - val_accuracy: 0.3651\n",
      "Epoch 618/1000\n",
      "1176/1176 [==============================] - 0s 42us/step - loss: 1.6254 - accuracy: 0.3673 - val_loss: 1.6699 - val_accuracy: 0.3651\n",
      "Epoch 619/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.6352 - accuracy: 0.3605 - val_loss: 1.6755 - val_accuracy: 0.3690\n",
      "Epoch 620/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.6183 - accuracy: 0.3724 - val_loss: 1.6701 - val_accuracy: 0.3631\n",
      "Epoch 621/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.6177 - accuracy: 0.3903 - val_loss: 1.6733 - val_accuracy: 0.3611\n",
      "Epoch 622/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.6397 - accuracy: 0.3665 - val_loss: 1.6718 - val_accuracy: 0.3651\n",
      "Epoch 623/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.6336 - accuracy: 0.3793 - val_loss: 1.6793 - val_accuracy: 0.3651\n",
      "Epoch 624/1000\n",
      "1176/1176 [==============================] - 0s 40us/step - loss: 1.6338 - accuracy: 0.3733 - val_loss: 1.6703 - val_accuracy: 0.3532\n",
      "Epoch 625/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.6256 - accuracy: 0.3639 - val_loss: 1.6734 - val_accuracy: 0.3690\n",
      "Epoch 626/1000\n",
      "1176/1176 [==============================] - 0s 45us/step - loss: 1.6292 - accuracy: 0.3741 - val_loss: 1.6790 - val_accuracy: 0.3651\n",
      "Epoch 627/1000\n",
      "1176/1176 [==============================] - 0s 41us/step - loss: 1.6293 - accuracy: 0.3793 - val_loss: 1.6772 - val_accuracy: 0.3651\n",
      "Epoch 628/1000\n",
      "1176/1176 [==============================] - 0s 42us/step - loss: 1.6216 - accuracy: 0.3759 - val_loss: 1.6766 - val_accuracy: 0.3631\n",
      "Epoch 629/1000\n",
      "1176/1176 [==============================] - 0s 42us/step - loss: 1.6389 - accuracy: 0.3827 - val_loss: 1.6738 - val_accuracy: 0.3651\n",
      "Epoch 630/1000\n",
      "1176/1176 [==============================] - 0s 41us/step - loss: 1.6327 - accuracy: 0.3750 - val_loss: 1.6718 - val_accuracy: 0.3611\n",
      "Epoch 631/1000\n",
      "1176/1176 [==============================] - 0s 40us/step - loss: 1.6283 - accuracy: 0.3844 - val_loss: 1.6758 - val_accuracy: 0.3730\n",
      "Epoch 632/1000\n",
      "1176/1176 [==============================] - 0s 42us/step - loss: 1.6298 - accuracy: 0.3733 - val_loss: 1.6707 - val_accuracy: 0.3671\n",
      "Epoch 633/1000\n",
      "1176/1176 [==============================] - 0s 41us/step - loss: 1.6373 - accuracy: 0.3741 - val_loss: 1.6684 - val_accuracy: 0.3651\n",
      "Epoch 634/1000\n",
      "1176/1176 [==============================] - 0s 41us/step - loss: 1.6447 - accuracy: 0.3793 - val_loss: 1.6731 - val_accuracy: 0.3690\n",
      "Epoch 635/1000\n",
      "1176/1176 [==============================] - 0s 41us/step - loss: 1.6248 - accuracy: 0.3741 - val_loss: 1.6810 - val_accuracy: 0.3651\n",
      "Epoch 636/1000\n",
      "1176/1176 [==============================] - 0s 40us/step - loss: 1.6325 - accuracy: 0.3810 - val_loss: 1.6707 - val_accuracy: 0.3631\n",
      "Epoch 637/1000\n",
      "1176/1176 [==============================] - 0s 42us/step - loss: 1.6285 - accuracy: 0.3699 - val_loss: 1.6687 - val_accuracy: 0.3710\n",
      "Epoch 638/1000\n",
      "1176/1176 [==============================] - 0s 42us/step - loss: 1.6274 - accuracy: 0.3673 - val_loss: 1.6806 - val_accuracy: 0.3710\n",
      "Epoch 639/1000\n",
      "1176/1176 [==============================] - 0s 40us/step - loss: 1.6316 - accuracy: 0.3733 - val_loss: 1.6690 - val_accuracy: 0.3611\n",
      "Epoch 640/1000\n",
      "1176/1176 [==============================] - 0s 42us/step - loss: 1.6286 - accuracy: 0.3759 - val_loss: 1.6724 - val_accuracy: 0.3710\n",
      "Epoch 641/1000\n",
      "1176/1176 [==============================] - 0s 45us/step - loss: 1.6241 - accuracy: 0.3733 - val_loss: 1.6730 - val_accuracy: 0.3651\n",
      "Epoch 642/1000\n",
      "1176/1176 [==============================] - 0s 42us/step - loss: 1.6283 - accuracy: 0.3793 - val_loss: 1.6769 - val_accuracy: 0.3631\n",
      "Epoch 643/1000\n",
      "1176/1176 [==============================] - 0s 41us/step - loss: 1.6360 - accuracy: 0.3605 - val_loss: 1.6745 - val_accuracy: 0.3611\n",
      "Epoch 644/1000\n",
      "1176/1176 [==============================] - 0s 41us/step - loss: 1.6184 - accuracy: 0.3835 - val_loss: 1.6797 - val_accuracy: 0.3690\n",
      "Epoch 645/1000\n",
      "1176/1176 [==============================] - 0s 40us/step - loss: 1.6305 - accuracy: 0.3793 - val_loss: 1.6736 - val_accuracy: 0.3631\n",
      "Epoch 646/1000\n",
      "1176/1176 [==============================] - 0s 47us/step - loss: 1.6156 - accuracy: 0.3861 - val_loss: 1.6778 - val_accuracy: 0.3710\n",
      "Epoch 647/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.6236 - accuracy: 0.3827 - val_loss: 1.6769 - val_accuracy: 0.3690\n",
      "Epoch 648/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.6346 - accuracy: 0.3776 - val_loss: 1.6776 - val_accuracy: 0.3671\n",
      "Epoch 649/1000\n",
      "1176/1176 [==============================] - 0s 40us/step - loss: 1.6516 - accuracy: 0.3724 - val_loss: 1.6748 - val_accuracy: 0.3671\n",
      "Epoch 650/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.6245 - accuracy: 0.3716 - val_loss: 1.6736 - val_accuracy: 0.3611\n",
      "Epoch 651/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1176/1176 [==============================] - 0s 41us/step - loss: 1.6263 - accuracy: 0.3665 - val_loss: 1.6727 - val_accuracy: 0.3591\n",
      "Epoch 652/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.6205 - accuracy: 0.3827 - val_loss: 1.6706 - val_accuracy: 0.3611\n",
      "Epoch 653/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.6305 - accuracy: 0.3741 - val_loss: 1.6714 - val_accuracy: 0.3651\n",
      "Epoch 654/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6446 - accuracy: 0.3665 - val_loss: 1.6771 - val_accuracy: 0.3690\n",
      "Epoch 655/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6483 - accuracy: 0.3793 - val_loss: 1.6723 - val_accuracy: 0.3730\n",
      "Epoch 656/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6326 - accuracy: 0.3690 - val_loss: 1.6767 - val_accuracy: 0.3730\n",
      "Epoch 657/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.6253 - accuracy: 0.3818 - val_loss: 1.6773 - val_accuracy: 0.3710\n",
      "Epoch 658/1000\n",
      "1176/1176 [==============================] - 0s 54us/step - loss: 1.6353 - accuracy: 0.3682 - val_loss: 1.6735 - val_accuracy: 0.3690\n",
      "Epoch 659/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6300 - accuracy: 0.3835 - val_loss: 1.6806 - val_accuracy: 0.3671\n",
      "Epoch 660/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6178 - accuracy: 0.3827 - val_loss: 1.6726 - val_accuracy: 0.3690\n",
      "Epoch 661/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.6242 - accuracy: 0.3741 - val_loss: 1.6762 - val_accuracy: 0.3651\n",
      "Epoch 662/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6166 - accuracy: 0.3767 - val_loss: 1.6702 - val_accuracy: 0.3710\n",
      "Epoch 663/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6234 - accuracy: 0.3818 - val_loss: 1.6796 - val_accuracy: 0.3631\n",
      "Epoch 664/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6290 - accuracy: 0.3827 - val_loss: 1.6733 - val_accuracy: 0.3651\n",
      "Epoch 665/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6285 - accuracy: 0.3699 - val_loss: 1.6734 - val_accuracy: 0.3690\n",
      "Epoch 666/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6309 - accuracy: 0.3827 - val_loss: 1.6717 - val_accuracy: 0.3690\n",
      "Epoch 667/1000\n",
      "1176/1176 [==============================] - 0s 45us/step - loss: 1.6255 - accuracy: 0.3801 - val_loss: 1.6773 - val_accuracy: 0.3631\n",
      "Epoch 668/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.6276 - accuracy: 0.3810 - val_loss: 1.6713 - val_accuracy: 0.3710\n",
      "Epoch 669/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6265 - accuracy: 0.3759 - val_loss: 1.6797 - val_accuracy: 0.3730\n",
      "Epoch 670/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.6221 - accuracy: 0.3793 - val_loss: 1.6798 - val_accuracy: 0.3690\n",
      "Epoch 671/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6244 - accuracy: 0.3724 - val_loss: 1.6752 - val_accuracy: 0.3671\n",
      "Epoch 672/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.6346 - accuracy: 0.3724 - val_loss: 1.6719 - val_accuracy: 0.3690\n",
      "Epoch 673/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.6196 - accuracy: 0.3690 - val_loss: 1.6814 - val_accuracy: 0.3690\n",
      "Epoch 674/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.6220 - accuracy: 0.3937 - val_loss: 1.6732 - val_accuracy: 0.3571\n",
      "Epoch 675/1000\n",
      "1176/1176 [==============================] - 0s 42us/step - loss: 1.6248 - accuracy: 0.3750 - val_loss: 1.6786 - val_accuracy: 0.3671\n",
      "Epoch 676/1000\n",
      "1176/1176 [==============================] - 0s 42us/step - loss: 1.6330 - accuracy: 0.3733 - val_loss: 1.6868 - val_accuracy: 0.3730\n",
      "Epoch 677/1000\n",
      "1176/1176 [==============================] - 0s 48us/step - loss: 1.6193 - accuracy: 0.3614 - val_loss: 1.6828 - val_accuracy: 0.3671\n",
      "Epoch 678/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.6219 - accuracy: 0.3835 - val_loss: 1.6738 - val_accuracy: 0.3671\n",
      "Epoch 679/1000\n",
      "1176/1176 [==============================] - 0s 41us/step - loss: 1.6226 - accuracy: 0.3784 - val_loss: 1.6793 - val_accuracy: 0.3710\n",
      "Epoch 680/1000\n",
      "1176/1176 [==============================] - 0s 40us/step - loss: 1.6303 - accuracy: 0.3810 - val_loss: 1.6829 - val_accuracy: 0.3690\n",
      "Epoch 681/1000\n",
      "1176/1176 [==============================] - 0s 40us/step - loss: 1.6084 - accuracy: 0.3801 - val_loss: 1.6736 - val_accuracy: 0.3690\n",
      "Epoch 682/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.6383 - accuracy: 0.3724 - val_loss: 1.6783 - val_accuracy: 0.3690\n",
      "Epoch 683/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.6333 - accuracy: 0.3724 - val_loss: 1.6849 - val_accuracy: 0.3671\n",
      "Epoch 684/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6273 - accuracy: 0.3793 - val_loss: 1.6782 - val_accuracy: 0.3690\n",
      "Epoch 685/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.6266 - accuracy: 0.3793 - val_loss: 1.6793 - val_accuracy: 0.3671\n",
      "Epoch 686/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.6317 - accuracy: 0.3810 - val_loss: 1.6902 - val_accuracy: 0.3631\n",
      "Epoch 687/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.6169 - accuracy: 0.3835 - val_loss: 1.6786 - val_accuracy: 0.3631\n",
      "Epoch 688/1000\n",
      "1176/1176 [==============================] - 0s 49us/step - loss: 1.6127 - accuracy: 0.3818 - val_loss: 1.6812 - val_accuracy: 0.3651\n",
      "Epoch 689/1000\n",
      "1176/1176 [==============================] - 0s 48us/step - loss: 1.6252 - accuracy: 0.3827 - val_loss: 1.6760 - val_accuracy: 0.3571\n",
      "Epoch 690/1000\n",
      "1176/1176 [==============================] - 0s 42us/step - loss: 1.6195 - accuracy: 0.3988 - val_loss: 1.6754 - val_accuracy: 0.3591\n",
      "Epoch 691/1000\n",
      "1176/1176 [==============================] - 0s 42us/step - loss: 1.6291 - accuracy: 0.3622 - val_loss: 1.6788 - val_accuracy: 0.3690\n",
      "Epoch 692/1000\n",
      "1176/1176 [==============================] - 0s 41us/step - loss: 1.6216 - accuracy: 0.3690 - val_loss: 1.6816 - val_accuracy: 0.3651\n",
      "Epoch 693/1000\n",
      "1176/1176 [==============================] - 0s 42us/step - loss: 1.6330 - accuracy: 0.3733 - val_loss: 1.6775 - val_accuracy: 0.3710\n",
      "Epoch 694/1000\n",
      "1176/1176 [==============================] - 0s 40us/step - loss: 1.6260 - accuracy: 0.3793 - val_loss: 1.6809 - val_accuracy: 0.3690\n",
      "Epoch 695/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.6085 - accuracy: 0.3827 - val_loss: 1.6880 - val_accuracy: 0.3631\n",
      "Epoch 696/1000\n",
      "1176/1176 [==============================] - 0s 41us/step - loss: 1.6148 - accuracy: 0.3733 - val_loss: 1.6879 - val_accuracy: 0.3631\n",
      "Epoch 697/1000\n",
      "1176/1176 [==============================] - 0s 41us/step - loss: 1.6278 - accuracy: 0.3767 - val_loss: 1.6880 - val_accuracy: 0.3631\n",
      "Epoch 698/1000\n",
      "1176/1176 [==============================] - 0s 42us/step - loss: 1.6263 - accuracy: 0.3563 - val_loss: 1.6783 - val_accuracy: 0.3730\n",
      "Epoch 699/1000\n",
      "1176/1176 [==============================] - 0s 40us/step - loss: 1.6295 - accuracy: 0.3767 - val_loss: 1.6787 - val_accuracy: 0.3671\n",
      "Epoch 700/1000\n",
      "1176/1176 [==============================] - 0s 41us/step - loss: 1.6310 - accuracy: 0.3759 - val_loss: 1.6856 - val_accuracy: 0.3690\n",
      "Epoch 701/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.6346 - accuracy: 0.3682 - val_loss: 1.6844 - val_accuracy: 0.3651\n",
      "Epoch 702/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6182 - accuracy: 0.3776 - val_loss: 1.6817 - val_accuracy: 0.3690\n",
      "Epoch 703/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.6246 - accuracy: 0.3767 - val_loss: 1.6731 - val_accuracy: 0.3710\n",
      "Epoch 704/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6191 - accuracy: 0.3861 - val_loss: 1.6901 - val_accuracy: 0.3571\n",
      "Epoch 705/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.6361 - accuracy: 0.3656 - val_loss: 1.6783 - val_accuracy: 0.3750\n",
      "Epoch 706/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.6319 - accuracy: 0.3690 - val_loss: 1.6827 - val_accuracy: 0.3690\n",
      "Epoch 707/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.6362 - accuracy: 0.3903 - val_loss: 1.6844 - val_accuracy: 0.3690\n",
      "Epoch 708/1000\n",
      "1176/1176 [==============================] - 0s 46us/step - loss: 1.6173 - accuracy: 0.3690 - val_loss: 1.6783 - val_accuracy: 0.3690\n",
      "Epoch 709/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6272 - accuracy: 0.3869 - val_loss: 1.6814 - val_accuracy: 0.3671\n",
      "Epoch 710/1000\n",
      "1176/1176 [==============================] - 0s 42us/step - loss: 1.6426 - accuracy: 0.3648 - val_loss: 1.6815 - val_accuracy: 0.3671\n",
      "Epoch 711/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.6213 - accuracy: 0.3759 - val_loss: 1.6801 - val_accuracy: 0.3690\n",
      "Epoch 712/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6302 - accuracy: 0.3614 - val_loss: 1.6806 - val_accuracy: 0.3671\n",
      "Epoch 713/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6127 - accuracy: 0.3869 - val_loss: 1.6826 - val_accuracy: 0.3651\n",
      "Epoch 714/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.6142 - accuracy: 0.3895 - val_loss: 1.6793 - val_accuracy: 0.3710\n",
      "Epoch 715/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6320 - accuracy: 0.3810 - val_loss: 1.6825 - val_accuracy: 0.3710\n",
      "Epoch 716/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6192 - accuracy: 0.3776 - val_loss: 1.6798 - val_accuracy: 0.3671\n",
      "Epoch 717/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.6294 - accuracy: 0.3767 - val_loss: 1.6806 - val_accuracy: 0.3651\n",
      "Epoch 718/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6218 - accuracy: 0.3801 - val_loss: 1.6879 - val_accuracy: 0.3611\n",
      "Epoch 719/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.6300 - accuracy: 0.3733 - val_loss: 1.6801 - val_accuracy: 0.3631\n",
      "Epoch 720/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6203 - accuracy: 0.3716 - val_loss: 1.6779 - val_accuracy: 0.3631\n",
      "Epoch 721/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.6324 - accuracy: 0.3869 - val_loss: 1.6818 - val_accuracy: 0.3651\n",
      "Epoch 722/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.6270 - accuracy: 0.3724 - val_loss: 1.6858 - val_accuracy: 0.3631\n",
      "Epoch 723/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.6261 - accuracy: 0.3801 - val_loss: 1.6888 - val_accuracy: 0.3671\n",
      "Epoch 724/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.6189 - accuracy: 0.3716 - val_loss: 1.6792 - val_accuracy: 0.3710\n",
      "Epoch 725/1000\n",
      "1176/1176 [==============================] - 0s 40us/step - loss: 1.6205 - accuracy: 0.3699 - val_loss: 1.6802 - val_accuracy: 0.3790\n",
      "Epoch 726/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.6270 - accuracy: 0.3639 - val_loss: 1.6810 - val_accuracy: 0.3710\n",
      "Epoch 727/1000\n",
      "1176/1176 [==============================] - 0s 40us/step - loss: 1.6263 - accuracy: 0.3767 - val_loss: 1.6777 - val_accuracy: 0.3730\n",
      "Epoch 728/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.6367 - accuracy: 0.3639 - val_loss: 1.6823 - val_accuracy: 0.3770\n",
      "Epoch 729/1000\n",
      "1176/1176 [==============================] - 0s 44us/step - loss: 1.6307 - accuracy: 0.3682 - val_loss: 1.6713 - val_accuracy: 0.3710\n",
      "Epoch 730/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6262 - accuracy: 0.3886 - val_loss: 1.6826 - val_accuracy: 0.3631\n",
      "Epoch 731/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.6019 - accuracy: 0.3724 - val_loss: 1.6893 - val_accuracy: 0.3671\n",
      "Epoch 732/1000\n",
      "1176/1176 [==============================] - 0s 41us/step - loss: 1.6176 - accuracy: 0.3690 - val_loss: 1.6776 - val_accuracy: 0.3671\n",
      "Epoch 733/1000\n",
      "1176/1176 [==============================] - 0s 41us/step - loss: 1.6309 - accuracy: 0.3767 - val_loss: 1.6850 - val_accuracy: 0.3710\n",
      "Epoch 734/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6183 - accuracy: 0.3827 - val_loss: 1.6863 - val_accuracy: 0.3671\n",
      "Epoch 735/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6324 - accuracy: 0.3682 - val_loss: 1.6759 - val_accuracy: 0.3671\n",
      "Epoch 736/1000\n",
      "1176/1176 [==============================] - 0s 40us/step - loss: 1.6211 - accuracy: 0.3818 - val_loss: 1.6757 - val_accuracy: 0.3690\n",
      "Epoch 737/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.6351 - accuracy: 0.3673 - val_loss: 1.6794 - val_accuracy: 0.3671\n",
      "Epoch 738/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6202 - accuracy: 0.3784 - val_loss: 1.6761 - val_accuracy: 0.3671\n",
      "Epoch 739/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.6306 - accuracy: 0.3639 - val_loss: 1.6819 - val_accuracy: 0.3690\n",
      "Epoch 740/1000\n",
      "1176/1176 [==============================] - 0s 42us/step - loss: 1.6348 - accuracy: 0.3844 - val_loss: 1.6884 - val_accuracy: 0.3770\n",
      "Epoch 741/1000\n",
      "1176/1176 [==============================] - 0s 40us/step - loss: 1.6272 - accuracy: 0.3852 - val_loss: 1.6744 - val_accuracy: 0.3690\n",
      "Epoch 742/1000\n",
      "1176/1176 [==============================] - 0s 40us/step - loss: 1.6330 - accuracy: 0.3724 - val_loss: 1.6789 - val_accuracy: 0.3671\n",
      "Epoch 743/1000\n",
      "1176/1176 [==============================] - 0s 41us/step - loss: 1.6250 - accuracy: 0.3733 - val_loss: 1.6749 - val_accuracy: 0.3690\n",
      "Epoch 744/1000\n",
      "1176/1176 [==============================] - 0s 42us/step - loss: 1.6397 - accuracy: 0.3810 - val_loss: 1.6741 - val_accuracy: 0.3730\n",
      "Epoch 745/1000\n",
      "1176/1176 [==============================] - 0s 42us/step - loss: 1.6258 - accuracy: 0.3690 - val_loss: 1.6752 - val_accuracy: 0.3770\n",
      "Epoch 746/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.6297 - accuracy: 0.3810 - val_loss: 1.6847 - val_accuracy: 0.3710\n",
      "Epoch 747/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.6307 - accuracy: 0.3869 - val_loss: 1.6816 - val_accuracy: 0.3710\n",
      "Epoch 748/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.6246 - accuracy: 0.3648 - val_loss: 1.6889 - val_accuracy: 0.3690\n",
      "Epoch 749/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.6249 - accuracy: 0.3861 - val_loss: 1.6868 - val_accuracy: 0.3730\n",
      "Epoch 750/1000\n",
      "1176/1176 [==============================] - 0s 44us/step - loss: 1.6368 - accuracy: 0.3614 - val_loss: 1.6778 - val_accuracy: 0.3710\n",
      "Epoch 751/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6086 - accuracy: 0.3759 - val_loss: 1.6851 - val_accuracy: 0.3750\n",
      "Epoch 752/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6196 - accuracy: 0.3784 - val_loss: 1.6738 - val_accuracy: 0.3690\n",
      "Epoch 753/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.6233 - accuracy: 0.3759 - val_loss: 1.6854 - val_accuracy: 0.3750\n",
      "Epoch 754/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.6357 - accuracy: 0.3827 - val_loss: 1.6765 - val_accuracy: 0.3790\n",
      "Epoch 755/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.6197 - accuracy: 0.3793 - val_loss: 1.6801 - val_accuracy: 0.3750\n",
      "Epoch 756/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6248 - accuracy: 0.3690 - val_loss: 1.6815 - val_accuracy: 0.3710\n",
      "Epoch 757/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6294 - accuracy: 0.3682 - val_loss: 1.6802 - val_accuracy: 0.3710\n",
      "Epoch 758/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6177 - accuracy: 0.3767 - val_loss: 1.6773 - val_accuracy: 0.3810\n",
      "Epoch 759/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.6199 - accuracy: 0.3810 - val_loss: 1.6934 - val_accuracy: 0.3690\n",
      "Epoch 760/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.6138 - accuracy: 0.3776 - val_loss: 1.6775 - val_accuracy: 0.3770\n",
      "Epoch 761/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6191 - accuracy: 0.3741 - val_loss: 1.6806 - val_accuracy: 0.3770\n",
      "Epoch 762/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6305 - accuracy: 0.3852 - val_loss: 1.6860 - val_accuracy: 0.3710\n",
      "Epoch 763/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6274 - accuracy: 0.3767 - val_loss: 1.6863 - val_accuracy: 0.3710\n",
      "Epoch 764/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.6070 - accuracy: 0.3852 - val_loss: 1.6782 - val_accuracy: 0.3730\n",
      "Epoch 765/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6295 - accuracy: 0.3801 - val_loss: 1.6732 - val_accuracy: 0.3750\n",
      "Epoch 766/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6208 - accuracy: 0.3895 - val_loss: 1.6800 - val_accuracy: 0.3810\n",
      "Epoch 767/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.6323 - accuracy: 0.3563 - val_loss: 1.6851 - val_accuracy: 0.3710\n",
      "Epoch 768/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.6466 - accuracy: 0.3648 - val_loss: 1.6872 - val_accuracy: 0.3651\n",
      "Epoch 769/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.6183 - accuracy: 0.3707 - val_loss: 1.6754 - val_accuracy: 0.3790\n",
      "Epoch 770/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6029 - accuracy: 0.3614 - val_loss: 1.6851 - val_accuracy: 0.3730\n",
      "Epoch 771/1000\n",
      "1176/1176 [==============================] - 0s 42us/step - loss: 1.6149 - accuracy: 0.3741 - val_loss: 1.6787 - val_accuracy: 0.3651\n",
      "Epoch 772/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6231 - accuracy: 0.3733 - val_loss: 1.6732 - val_accuracy: 0.3710\n",
      "Epoch 773/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.6104 - accuracy: 0.3861 - val_loss: 1.6755 - val_accuracy: 0.3770\n",
      "Epoch 774/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.6019 - accuracy: 0.3852 - val_loss: 1.6854 - val_accuracy: 0.3690\n",
      "Epoch 775/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.6190 - accuracy: 0.3759 - val_loss: 1.6865 - val_accuracy: 0.3710\n",
      "Epoch 776/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6260 - accuracy: 0.3673 - val_loss: 1.6826 - val_accuracy: 0.3750\n",
      "Epoch 777/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.6231 - accuracy: 0.3767 - val_loss: 1.6824 - val_accuracy: 0.3690\n",
      "Epoch 778/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.6293 - accuracy: 0.3673 - val_loss: 1.6768 - val_accuracy: 0.3671\n",
      "Epoch 779/1000\n",
      "1176/1176 [==============================] - 0s 42us/step - loss: 1.6176 - accuracy: 0.3733 - val_loss: 1.6802 - val_accuracy: 0.3651\n",
      "Epoch 780/1000\n",
      "1176/1176 [==============================] - 0s 42us/step - loss: 1.6222 - accuracy: 0.3750 - val_loss: 1.6814 - val_accuracy: 0.3651\n",
      "Epoch 781/1000\n",
      "1176/1176 [==============================] - 0s 41us/step - loss: 1.6130 - accuracy: 0.3741 - val_loss: 1.6782 - val_accuracy: 0.3710\n",
      "Epoch 782/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.6147 - accuracy: 0.3878 - val_loss: 1.6804 - val_accuracy: 0.3710\n",
      "Epoch 783/1000\n",
      "1176/1176 [==============================] - 0s 41us/step - loss: 1.6207 - accuracy: 0.3733 - val_loss: 1.6803 - val_accuracy: 0.3810\n",
      "Epoch 784/1000\n",
      "1176/1176 [==============================] - 0s 42us/step - loss: 1.6228 - accuracy: 0.3699 - val_loss: 1.6819 - val_accuracy: 0.3790\n",
      "Epoch 785/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.6137 - accuracy: 0.3759 - val_loss: 1.6856 - val_accuracy: 0.3730\n",
      "Epoch 786/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.6196 - accuracy: 0.3733 - val_loss: 1.6934 - val_accuracy: 0.3690\n",
      "Epoch 787/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.6148 - accuracy: 0.3699 - val_loss: 1.6925 - val_accuracy: 0.3611\n",
      "Epoch 788/1000\n",
      "1176/1176 [==============================] - 0s 40us/step - loss: 1.6341 - accuracy: 0.3784 - val_loss: 1.6837 - val_accuracy: 0.3690\n",
      "Epoch 789/1000\n",
      "1176/1176 [==============================] - 0s 41us/step - loss: 1.6296 - accuracy: 0.3767 - val_loss: 1.6819 - val_accuracy: 0.3770\n",
      "Epoch 790/1000\n",
      "1176/1176 [==============================] - 0s 40us/step - loss: 1.6179 - accuracy: 0.3844 - val_loss: 1.6814 - val_accuracy: 0.3750\n",
      "Epoch 791/1000\n",
      "1176/1176 [==============================] - 0s 49us/step - loss: 1.6174 - accuracy: 0.3750 - val_loss: 1.6826 - val_accuracy: 0.3770\n",
      "Epoch 792/1000\n",
      "1176/1176 [==============================] - 0s 44us/step - loss: 1.6151 - accuracy: 0.3707 - val_loss: 1.6984 - val_accuracy: 0.3651\n",
      "Epoch 793/1000\n",
      "1176/1176 [==============================] - 0s 41us/step - loss: 1.6192 - accuracy: 0.3844 - val_loss: 1.6784 - val_accuracy: 0.3710\n",
      "Epoch 794/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.6333 - accuracy: 0.3716 - val_loss: 1.6872 - val_accuracy: 0.3690\n",
      "Epoch 795/1000\n",
      "1176/1176 [==============================] - 0s 42us/step - loss: 1.6209 - accuracy: 0.3835 - val_loss: 1.6745 - val_accuracy: 0.3710\n",
      "Epoch 796/1000\n",
      "1176/1176 [==============================] - 0s 41us/step - loss: 1.6106 - accuracy: 0.3605 - val_loss: 1.6798 - val_accuracy: 0.3631\n",
      "Epoch 797/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.6175 - accuracy: 0.3724 - val_loss: 1.6759 - val_accuracy: 0.3690\n",
      "Epoch 798/1000\n",
      "1176/1176 [==============================] - 0s 42us/step - loss: 1.6064 - accuracy: 0.3869 - val_loss: 1.6828 - val_accuracy: 0.3690\n",
      "Epoch 799/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6138 - accuracy: 0.3724 - val_loss: 1.6730 - val_accuracy: 0.3730\n",
      "Epoch 800/1000\n",
      "1176/1176 [==============================] - 0s 40us/step - loss: 1.6209 - accuracy: 0.3767 - val_loss: 1.6852 - val_accuracy: 0.3671\n",
      "Epoch 801/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.6102 - accuracy: 0.3869 - val_loss: 1.6753 - val_accuracy: 0.3750\n",
      "Epoch 802/1000\n",
      "1176/1176 [==============================] - 0s 40us/step - loss: 1.6233 - accuracy: 0.3759 - val_loss: 1.6751 - val_accuracy: 0.3690\n",
      "Epoch 803/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.6249 - accuracy: 0.3656 - val_loss: 1.6823 - val_accuracy: 0.3710\n",
      "Epoch 804/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.6203 - accuracy: 0.3716 - val_loss: 1.6867 - val_accuracy: 0.3671\n",
      "Epoch 805/1000\n",
      "1176/1176 [==============================] - 0s 40us/step - loss: 1.6151 - accuracy: 0.3750 - val_loss: 1.6870 - val_accuracy: 0.3690\n",
      "Epoch 806/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.6292 - accuracy: 0.3682 - val_loss: 1.6788 - val_accuracy: 0.3690\n",
      "Epoch 807/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.6389 - accuracy: 0.3656 - val_loss: 1.6802 - val_accuracy: 0.3651\n",
      "Epoch 808/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.6151 - accuracy: 0.3776 - val_loss: 1.6788 - val_accuracy: 0.3671\n",
      "Epoch 809/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6183 - accuracy: 0.3793 - val_loss: 1.6758 - val_accuracy: 0.3690\n",
      "Epoch 810/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6109 - accuracy: 0.3844 - val_loss: 1.6742 - val_accuracy: 0.3710\n",
      "Epoch 811/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6240 - accuracy: 0.3827 - val_loss: 1.6776 - val_accuracy: 0.3671\n",
      "Epoch 812/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.6171 - accuracy: 0.3699 - val_loss: 1.6713 - val_accuracy: 0.3770\n",
      "Epoch 813/1000\n",
      "1176/1176 [==============================] - 0s 44us/step - loss: 1.6226 - accuracy: 0.3852 - val_loss: 1.6717 - val_accuracy: 0.3770\n",
      "Epoch 814/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6307 - accuracy: 0.3716 - val_loss: 1.6795 - val_accuracy: 0.3770\n",
      "Epoch 815/1000\n",
      "1176/1176 [==============================] - 0s 40us/step - loss: 1.6249 - accuracy: 0.3776 - val_loss: 1.6788 - val_accuracy: 0.3770\n",
      "Epoch 816/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.6188 - accuracy: 0.3759 - val_loss: 1.6827 - val_accuracy: 0.3710\n",
      "Epoch 817/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6309 - accuracy: 0.3750 - val_loss: 1.6863 - val_accuracy: 0.3651\n",
      "Epoch 818/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6188 - accuracy: 0.3810 - val_loss: 1.6751 - val_accuracy: 0.3730\n",
      "Epoch 819/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6275 - accuracy: 0.3835 - val_loss: 1.6828 - val_accuracy: 0.3750\n",
      "Epoch 820/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6207 - accuracy: 0.3818 - val_loss: 1.6852 - val_accuracy: 0.3710\n",
      "Epoch 821/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6237 - accuracy: 0.3580 - val_loss: 1.6846 - val_accuracy: 0.3671\n",
      "Epoch 822/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.6165 - accuracy: 0.3827 - val_loss: 1.6802 - val_accuracy: 0.3631\n",
      "Epoch 823/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6182 - accuracy: 0.3597 - val_loss: 1.6832 - val_accuracy: 0.3651\n",
      "Epoch 824/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6313 - accuracy: 0.3759 - val_loss: 1.6883 - val_accuracy: 0.3671\n",
      "Epoch 825/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6135 - accuracy: 0.3784 - val_loss: 1.6736 - val_accuracy: 0.3671\n",
      "Epoch 826/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6145 - accuracy: 0.3750 - val_loss: 1.6903 - val_accuracy: 0.3671\n",
      "Epoch 827/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6336 - accuracy: 0.3665 - val_loss: 1.6753 - val_accuracy: 0.3710\n",
      "Epoch 828/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6041 - accuracy: 0.3784 - val_loss: 1.6755 - val_accuracy: 0.3671\n",
      "Epoch 829/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6177 - accuracy: 0.3776 - val_loss: 1.6796 - val_accuracy: 0.3651\n",
      "Epoch 830/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.6295 - accuracy: 0.3852 - val_loss: 1.6725 - val_accuracy: 0.3730\n",
      "Epoch 831/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.6228 - accuracy: 0.3801 - val_loss: 1.6737 - val_accuracy: 0.3710\n",
      "Epoch 832/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.6137 - accuracy: 0.3852 - val_loss: 1.6812 - val_accuracy: 0.3651\n",
      "Epoch 833/1000\n",
      "1176/1176 [==============================] - 0s 41us/step - loss: 1.6205 - accuracy: 0.3690 - val_loss: 1.6864 - val_accuracy: 0.3690\n",
      "Epoch 834/1000\n",
      "1176/1176 [==============================] - 0s 46us/step - loss: 1.6092 - accuracy: 0.3750 - val_loss: 1.6829 - val_accuracy: 0.3710\n",
      "Epoch 835/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6230 - accuracy: 0.3827 - val_loss: 1.6909 - val_accuracy: 0.3690\n",
      "Epoch 836/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.6277 - accuracy: 0.3759 - val_loss: 1.6844 - val_accuracy: 0.3710\n",
      "Epoch 837/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6127 - accuracy: 0.3912 - val_loss: 1.6826 - val_accuracy: 0.3710\n",
      "Epoch 838/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6309 - accuracy: 0.3733 - val_loss: 1.6772 - val_accuracy: 0.3651\n",
      "Epoch 839/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6078 - accuracy: 0.3784 - val_loss: 1.6766 - val_accuracy: 0.3651\n",
      "Epoch 840/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6190 - accuracy: 0.3852 - val_loss: 1.6817 - val_accuracy: 0.3611\n",
      "Epoch 841/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.5981 - accuracy: 0.3690 - val_loss: 1.6891 - val_accuracy: 0.3671\n",
      "Epoch 842/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.6169 - accuracy: 0.3673 - val_loss: 1.6884 - val_accuracy: 0.3690\n",
      "Epoch 843/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6140 - accuracy: 0.3750 - val_loss: 1.6915 - val_accuracy: 0.3671\n",
      "Epoch 844/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6259 - accuracy: 0.3690 - val_loss: 1.6799 - val_accuracy: 0.3611\n",
      "Epoch 845/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6297 - accuracy: 0.3793 - val_loss: 1.6857 - val_accuracy: 0.3611\n",
      "Epoch 846/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6112 - accuracy: 0.3895 - val_loss: 1.6875 - val_accuracy: 0.3690\n",
      "Epoch 847/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.6320 - accuracy: 0.3707 - val_loss: 1.6892 - val_accuracy: 0.3730\n",
      "Epoch 848/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6312 - accuracy: 0.3716 - val_loss: 1.6848 - val_accuracy: 0.3730\n",
      "Epoch 849/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6076 - accuracy: 0.3818 - val_loss: 1.6811 - val_accuracy: 0.3671\n",
      "Epoch 850/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6171 - accuracy: 0.3707 - val_loss: 1.6841 - val_accuracy: 0.3671\n",
      "Epoch 851/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.6046 - accuracy: 0.3818 - val_loss: 1.6920 - val_accuracy: 0.3710\n",
      "Epoch 852/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.6086 - accuracy: 0.3656 - val_loss: 1.6824 - val_accuracy: 0.3671\n",
      "Epoch 853/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.6259 - accuracy: 0.3563 - val_loss: 1.6925 - val_accuracy: 0.3730\n",
      "Epoch 854/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.6124 - accuracy: 0.3818 - val_loss: 1.6933 - val_accuracy: 0.3671\n",
      "Epoch 855/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6121 - accuracy: 0.3724 - val_loss: 1.6776 - val_accuracy: 0.3651\n",
      "Epoch 856/1000\n",
      "1176/1176 [==============================] - 0s 42us/step - loss: 1.6215 - accuracy: 0.3776 - val_loss: 1.6761 - val_accuracy: 0.3631\n",
      "Epoch 857/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6149 - accuracy: 0.3861 - val_loss: 1.6871 - val_accuracy: 0.3730\n",
      "Epoch 858/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6131 - accuracy: 0.3639 - val_loss: 1.6929 - val_accuracy: 0.3631\n",
      "Epoch 859/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.6162 - accuracy: 0.3750 - val_loss: 1.6860 - val_accuracy: 0.3770\n",
      "Epoch 860/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.6154 - accuracy: 0.3835 - val_loss: 1.6836 - val_accuracy: 0.3790\n",
      "Epoch 861/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.6141 - accuracy: 0.3869 - val_loss: 1.6852 - val_accuracy: 0.3790\n",
      "Epoch 862/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6230 - accuracy: 0.3631 - val_loss: 1.6919 - val_accuracy: 0.3750\n",
      "Epoch 863/1000\n",
      "1176/1176 [==============================] - 0s 36us/step - loss: 1.6188 - accuracy: 0.3682 - val_loss: 1.6824 - val_accuracy: 0.3671\n",
      "Epoch 864/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6187 - accuracy: 0.3665 - val_loss: 1.6867 - val_accuracy: 0.3611\n",
      "Epoch 865/1000\n",
      "1176/1176 [==============================] - 0s 36us/step - loss: 1.6063 - accuracy: 0.3776 - val_loss: 1.6800 - val_accuracy: 0.3611\n",
      "Epoch 866/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6295 - accuracy: 0.3827 - val_loss: 1.6847 - val_accuracy: 0.3611\n",
      "Epoch 867/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6209 - accuracy: 0.3801 - val_loss: 1.6939 - val_accuracy: 0.3690\n",
      "Epoch 868/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6155 - accuracy: 0.3665 - val_loss: 1.6955 - val_accuracy: 0.3671\n",
      "Epoch 869/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.6308 - accuracy: 0.3852 - val_loss: 1.6898 - val_accuracy: 0.3690\n",
      "Epoch 870/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.6150 - accuracy: 0.3656 - val_loss: 1.6835 - val_accuracy: 0.3690\n",
      "Epoch 871/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.6270 - accuracy: 0.3776 - val_loss: 1.6804 - val_accuracy: 0.3611\n",
      "Epoch 872/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.6234 - accuracy: 0.3767 - val_loss: 1.6764 - val_accuracy: 0.3690\n",
      "Epoch 873/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.6244 - accuracy: 0.3827 - val_loss: 1.6819 - val_accuracy: 0.3690\n",
      "Epoch 874/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.6078 - accuracy: 0.3835 - val_loss: 1.6846 - val_accuracy: 0.3611\n",
      "Epoch 875/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.6280 - accuracy: 0.3784 - val_loss: 1.6898 - val_accuracy: 0.3631\n",
      "Epoch 876/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6164 - accuracy: 0.3767 - val_loss: 1.6898 - val_accuracy: 0.3671\n",
      "Epoch 877/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.6141 - accuracy: 0.3784 - val_loss: 1.6946 - val_accuracy: 0.3690\n",
      "Epoch 878/1000\n",
      "1176/1176 [==============================] - 0s 40us/step - loss: 1.6095 - accuracy: 0.3750 - val_loss: 1.6746 - val_accuracy: 0.3631\n",
      "Epoch 879/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6292 - accuracy: 0.3716 - val_loss: 1.6772 - val_accuracy: 0.3591\n",
      "Epoch 880/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.6068 - accuracy: 0.3793 - val_loss: 1.6849 - val_accuracy: 0.3611\n",
      "Epoch 881/1000\n",
      "1176/1176 [==============================] - 0s 41us/step - loss: 1.6160 - accuracy: 0.3784 - val_loss: 1.6864 - val_accuracy: 0.3611\n",
      "Epoch 882/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.6031 - accuracy: 0.3878 - val_loss: 1.6881 - val_accuracy: 0.3651\n",
      "Epoch 883/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.6234 - accuracy: 0.3741 - val_loss: 1.6815 - val_accuracy: 0.3671\n",
      "Epoch 884/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6155 - accuracy: 0.3741 - val_loss: 1.6957 - val_accuracy: 0.3690\n",
      "Epoch 885/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.6223 - accuracy: 0.3750 - val_loss: 1.6769 - val_accuracy: 0.3690\n",
      "Epoch 886/1000\n",
      "1176/1176 [==============================] - 0s 41us/step - loss: 1.6100 - accuracy: 0.3733 - val_loss: 1.6867 - val_accuracy: 0.3710\n",
      "Epoch 887/1000\n",
      "1176/1176 [==============================] - 0s 41us/step - loss: 1.6189 - accuracy: 0.3801 - val_loss: 1.6880 - val_accuracy: 0.3651\n",
      "Epoch 888/1000\n",
      "1176/1176 [==============================] - 0s 52us/step - loss: 1.6152 - accuracy: 0.3690 - val_loss: 1.6818 - val_accuracy: 0.3571\n",
      "Epoch 889/1000\n",
      "1176/1176 [==============================] - 0s 41us/step - loss: 1.6238 - accuracy: 0.3750 - val_loss: 1.6785 - val_accuracy: 0.3611\n",
      "Epoch 890/1000\n",
      "1176/1176 [==============================] - 0s 40us/step - loss: 1.6247 - accuracy: 0.3903 - val_loss: 1.6881 - val_accuracy: 0.3631\n",
      "Epoch 891/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.6123 - accuracy: 0.3801 - val_loss: 1.6936 - val_accuracy: 0.3730\n",
      "Epoch 892/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.6175 - accuracy: 0.3750 - val_loss: 1.6840 - val_accuracy: 0.3710\n",
      "Epoch 893/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6186 - accuracy: 0.3946 - val_loss: 1.6829 - val_accuracy: 0.3710\n",
      "Epoch 894/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.6229 - accuracy: 0.3724 - val_loss: 1.6802 - val_accuracy: 0.3730\n",
      "Epoch 895/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.6110 - accuracy: 0.3886 - val_loss: 1.6821 - val_accuracy: 0.3810\n",
      "Epoch 896/1000\n",
      "1176/1176 [==============================] - 0s 40us/step - loss: 1.6089 - accuracy: 0.3827 - val_loss: 1.6828 - val_accuracy: 0.3730\n",
      "Epoch 897/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.5949 - accuracy: 0.3818 - val_loss: 1.6822 - val_accuracy: 0.3671\n",
      "Epoch 898/1000\n",
      "1176/1176 [==============================] - 0s 49us/step - loss: 1.6252 - accuracy: 0.3835 - val_loss: 1.6813 - val_accuracy: 0.3651\n",
      "Epoch 899/1000\n",
      "1176/1176 [==============================] - 0s 42us/step - loss: 1.6120 - accuracy: 0.3827 - val_loss: 1.6911 - val_accuracy: 0.3690\n",
      "Epoch 900/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.6220 - accuracy: 0.3801 - val_loss: 1.6854 - val_accuracy: 0.3631\n",
      "Epoch 901/1000\n",
      "1176/1176 [==============================] - 0s 42us/step - loss: 1.6209 - accuracy: 0.3784 - val_loss: 1.6970 - val_accuracy: 0.3631\n",
      "Epoch 902/1000\n",
      "1176/1176 [==============================] - 0s 49us/step - loss: 1.6110 - accuracy: 0.3852 - val_loss: 1.7018 - val_accuracy: 0.3611\n",
      "Epoch 903/1000\n",
      "1176/1176 [==============================] - 0s 40us/step - loss: 1.6075 - accuracy: 0.3818 - val_loss: 1.6902 - val_accuracy: 0.3690\n",
      "Epoch 904/1000\n",
      "1176/1176 [==============================] - 0s 42us/step - loss: 1.6181 - accuracy: 0.3733 - val_loss: 1.6929 - val_accuracy: 0.3770\n",
      "Epoch 905/1000\n",
      "1176/1176 [==============================] - 0s 41us/step - loss: 1.6056 - accuracy: 0.3793 - val_loss: 1.6927 - val_accuracy: 0.3790\n",
      "Epoch 906/1000\n",
      "1176/1176 [==============================] - 0s 42us/step - loss: 1.6134 - accuracy: 0.3784 - val_loss: 1.6954 - val_accuracy: 0.3750\n",
      "Epoch 907/1000\n",
      "1176/1176 [==============================] - 0s 42us/step - loss: 1.5993 - accuracy: 0.3971 - val_loss: 1.6944 - val_accuracy: 0.3730\n",
      "Epoch 908/1000\n",
      "1176/1176 [==============================] - 0s 41us/step - loss: 1.6077 - accuracy: 0.3682 - val_loss: 1.6843 - val_accuracy: 0.3770\n",
      "Epoch 909/1000\n",
      "1176/1176 [==============================] - 0s 40us/step - loss: 1.6206 - accuracy: 0.3912 - val_loss: 1.6844 - val_accuracy: 0.3631\n",
      "Epoch 910/1000\n",
      "1176/1176 [==============================] - 0s 60us/step - loss: 1.6124 - accuracy: 0.3733 - val_loss: 1.7036 - val_accuracy: 0.3790\n",
      "Epoch 911/1000\n",
      "1176/1176 [==============================] - 0s 40us/step - loss: 1.6023 - accuracy: 0.3895 - val_loss: 1.6868 - val_accuracy: 0.3611\n",
      "Epoch 912/1000\n",
      "1176/1176 [==============================] - 0s 41us/step - loss: 1.6203 - accuracy: 0.3835 - val_loss: 1.6814 - val_accuracy: 0.3651\n",
      "Epoch 913/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.6196 - accuracy: 0.3827 - val_loss: 1.6940 - val_accuracy: 0.3690\n",
      "Epoch 914/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6292 - accuracy: 0.3656 - val_loss: 1.6884 - val_accuracy: 0.3671\n",
      "Epoch 915/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6196 - accuracy: 0.3673 - val_loss: 1.6870 - val_accuracy: 0.3770\n",
      "Epoch 916/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.6179 - accuracy: 0.3716 - val_loss: 1.6765 - val_accuracy: 0.3671\n",
      "Epoch 917/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.6112 - accuracy: 0.3767 - val_loss: 1.6797 - val_accuracy: 0.3671\n",
      "Epoch 918/1000\n",
      "1176/1176 [==============================] - 0s 45us/step - loss: 1.6243 - accuracy: 0.3733 - val_loss: 1.6911 - val_accuracy: 0.3651\n",
      "Epoch 919/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.6089 - accuracy: 0.3716 - val_loss: 1.6860 - val_accuracy: 0.3671\n",
      "Epoch 920/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6231 - accuracy: 0.3818 - val_loss: 1.6818 - val_accuracy: 0.3651\n",
      "Epoch 921/1000\n",
      "1176/1176 [==============================] - 0s 40us/step - loss: 1.6195 - accuracy: 0.3784 - val_loss: 1.6818 - val_accuracy: 0.3591\n",
      "Epoch 922/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.6104 - accuracy: 0.3869 - val_loss: 1.6807 - val_accuracy: 0.3651\n",
      "Epoch 923/1000\n",
      "1176/1176 [==============================] - 0s 41us/step - loss: 1.6171 - accuracy: 0.3929 - val_loss: 1.6809 - val_accuracy: 0.3730\n",
      "Epoch 924/1000\n",
      "1176/1176 [==============================] - 0s 40us/step - loss: 1.6201 - accuracy: 0.3741 - val_loss: 1.6796 - val_accuracy: 0.3710\n",
      "Epoch 925/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.6082 - accuracy: 0.3920 - val_loss: 1.6826 - val_accuracy: 0.3710\n",
      "Epoch 926/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1176/1176 [==============================] - 0s 41us/step - loss: 1.5995 - accuracy: 0.3750 - val_loss: 1.6873 - val_accuracy: 0.3631\n",
      "Epoch 927/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.6090 - accuracy: 0.3690 - val_loss: 1.6822 - val_accuracy: 0.3651\n",
      "Epoch 928/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6037 - accuracy: 0.3912 - val_loss: 1.6869 - val_accuracy: 0.3671\n",
      "Epoch 929/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.5995 - accuracy: 0.3793 - val_loss: 1.6868 - val_accuracy: 0.3671\n",
      "Epoch 930/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6054 - accuracy: 0.3801 - val_loss: 1.6905 - val_accuracy: 0.3690\n",
      "Epoch 931/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6198 - accuracy: 0.3793 - val_loss: 1.6845 - val_accuracy: 0.3730\n",
      "Epoch 932/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6055 - accuracy: 0.3741 - val_loss: 1.6805 - val_accuracy: 0.3710\n",
      "Epoch 933/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6020 - accuracy: 0.3793 - val_loss: 1.6778 - val_accuracy: 0.3671\n",
      "Epoch 934/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6224 - accuracy: 0.3827 - val_loss: 1.6844 - val_accuracy: 0.3690\n",
      "Epoch 935/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.6224 - accuracy: 0.3810 - val_loss: 1.6747 - val_accuracy: 0.3631\n",
      "Epoch 936/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.6115 - accuracy: 0.3767 - val_loss: 1.6685 - val_accuracy: 0.3730\n",
      "Epoch 937/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.6297 - accuracy: 0.3776 - val_loss: 1.6836 - val_accuracy: 0.3631\n",
      "Epoch 938/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.6188 - accuracy: 0.3835 - val_loss: 1.6760 - val_accuracy: 0.3671\n",
      "Epoch 939/1000\n",
      "1176/1176 [==============================] - 0s 46us/step - loss: 1.6127 - accuracy: 0.3665 - val_loss: 1.6859 - val_accuracy: 0.3710\n",
      "Epoch 940/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.6139 - accuracy: 0.3801 - val_loss: 1.6830 - val_accuracy: 0.3651\n",
      "Epoch 941/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6322 - accuracy: 0.3852 - val_loss: 1.6826 - val_accuracy: 0.3690\n",
      "Epoch 942/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.6124 - accuracy: 0.3869 - val_loss: 1.6828 - val_accuracy: 0.3690\n",
      "Epoch 943/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.6122 - accuracy: 0.3597 - val_loss: 1.6817 - val_accuracy: 0.3690\n",
      "Epoch 944/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.6192 - accuracy: 0.3733 - val_loss: 1.6800 - val_accuracy: 0.3690\n",
      "Epoch 945/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.6087 - accuracy: 0.3699 - val_loss: 1.6843 - val_accuracy: 0.3671\n",
      "Epoch 946/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.6240 - accuracy: 0.3767 - val_loss: 1.6773 - val_accuracy: 0.3730\n",
      "Epoch 947/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6199 - accuracy: 0.3818 - val_loss: 1.6793 - val_accuracy: 0.3710\n",
      "Epoch 948/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.6217 - accuracy: 0.3844 - val_loss: 1.6781 - val_accuracy: 0.3730\n",
      "Epoch 949/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.6008 - accuracy: 0.3733 - val_loss: 1.6843 - val_accuracy: 0.3651\n",
      "Epoch 950/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.6273 - accuracy: 0.3920 - val_loss: 1.6973 - val_accuracy: 0.3591\n",
      "Epoch 951/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6225 - accuracy: 0.3801 - val_loss: 1.6850 - val_accuracy: 0.3651\n",
      "Epoch 952/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.6142 - accuracy: 0.3665 - val_loss: 1.6921 - val_accuracy: 0.3671\n",
      "Epoch 953/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.6126 - accuracy: 0.3716 - val_loss: 1.6737 - val_accuracy: 0.3651\n",
      "Epoch 954/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.6262 - accuracy: 0.3844 - val_loss: 1.6856 - val_accuracy: 0.3730\n",
      "Epoch 955/1000\n",
      "1176/1176 [==============================] - 0s 40us/step - loss: 1.6073 - accuracy: 0.3767 - val_loss: 1.6775 - val_accuracy: 0.3750\n",
      "Epoch 956/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.6177 - accuracy: 0.3784 - val_loss: 1.6873 - val_accuracy: 0.3829\n",
      "Epoch 957/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6103 - accuracy: 0.3673 - val_loss: 1.6749 - val_accuracy: 0.3750\n",
      "Epoch 958/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.6175 - accuracy: 0.3776 - val_loss: 1.6874 - val_accuracy: 0.3750\n",
      "Epoch 959/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.6180 - accuracy: 0.3937 - val_loss: 1.6808 - val_accuracy: 0.3651\n",
      "Epoch 960/1000\n",
      "1176/1176 [==============================] - 0s 46us/step - loss: 1.6107 - accuracy: 0.3835 - val_loss: 1.6859 - val_accuracy: 0.3671\n",
      "Epoch 961/1000\n",
      "1176/1176 [==============================] - 0s 44us/step - loss: 1.6129 - accuracy: 0.3869 - val_loss: 1.6866 - val_accuracy: 0.3730\n",
      "Epoch 962/1000\n",
      "1176/1176 [==============================] - 0s 46us/step - loss: 1.6188 - accuracy: 0.3665 - val_loss: 1.6838 - val_accuracy: 0.3690\n",
      "Epoch 963/1000\n",
      "1176/1176 [==============================] - 0s 48us/step - loss: 1.6109 - accuracy: 0.3869 - val_loss: 1.6788 - val_accuracy: 0.3651\n",
      "Epoch 964/1000\n",
      "1176/1176 [==============================] - 0s 54us/step - loss: 1.6076 - accuracy: 0.3929 - val_loss: 1.6846 - val_accuracy: 0.3710\n",
      "Epoch 965/1000\n",
      "1176/1176 [==============================] - 0s 50us/step - loss: 1.5977 - accuracy: 0.3801 - val_loss: 1.6828 - val_accuracy: 0.3730\n",
      "Epoch 966/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6325 - accuracy: 0.3844 - val_loss: 1.6911 - val_accuracy: 0.3651\n",
      "Epoch 967/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6083 - accuracy: 0.3614 - val_loss: 1.6817 - val_accuracy: 0.3671\n",
      "Epoch 968/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6149 - accuracy: 0.3776 - val_loss: 1.6838 - val_accuracy: 0.3730\n",
      "Epoch 969/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.6139 - accuracy: 0.3861 - val_loss: 1.6881 - val_accuracy: 0.3671\n",
      "Epoch 970/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.6159 - accuracy: 0.3852 - val_loss: 1.6871 - val_accuracy: 0.3710\n",
      "Epoch 971/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.6223 - accuracy: 0.3622 - val_loss: 1.6959 - val_accuracy: 0.3690\n",
      "Epoch 972/1000\n",
      "1176/1176 [==============================] - 0s 40us/step - loss: 1.6164 - accuracy: 0.3733 - val_loss: 1.6926 - val_accuracy: 0.3631\n",
      "Epoch 973/1000\n",
      "1176/1176 [==============================] - 0s 41us/step - loss: 1.6191 - accuracy: 0.3793 - val_loss: 1.6982 - val_accuracy: 0.3750\n",
      "Epoch 974/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.6074 - accuracy: 0.3852 - val_loss: 1.6921 - val_accuracy: 0.3651\n",
      "Epoch 975/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.6227 - accuracy: 0.3707 - val_loss: 1.6906 - val_accuracy: 0.3671\n",
      "Epoch 976/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.5979 - accuracy: 0.3801 - val_loss: 1.6986 - val_accuracy: 0.3750\n",
      "Epoch 977/1000\n",
      "1176/1176 [==============================] - 0s 40us/step - loss: 1.6042 - accuracy: 0.3741 - val_loss: 1.6919 - val_accuracy: 0.3730\n",
      "Epoch 978/1000\n",
      "1176/1176 [==============================] - 0s 41us/step - loss: 1.6102 - accuracy: 0.3741 - val_loss: 1.6947 - val_accuracy: 0.3730\n",
      "Epoch 979/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.6176 - accuracy: 0.3801 - val_loss: 1.6889 - val_accuracy: 0.3710\n",
      "Epoch 980/1000\n",
      "1176/1176 [==============================] - 0s 45us/step - loss: 1.6229 - accuracy: 0.3622 - val_loss: 1.6913 - val_accuracy: 0.3770\n",
      "Epoch 981/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.6172 - accuracy: 0.3852 - val_loss: 1.7042 - val_accuracy: 0.3730\n",
      "Epoch 982/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.6118 - accuracy: 0.3699 - val_loss: 1.7005 - val_accuracy: 0.3710\n",
      "Epoch 983/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.6073 - accuracy: 0.3699 - val_loss: 1.6963 - val_accuracy: 0.3750\n",
      "Epoch 984/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6164 - accuracy: 0.3784 - val_loss: 1.6888 - val_accuracy: 0.3849\n",
      "Epoch 985/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.6282 - accuracy: 0.3741 - val_loss: 1.6999 - val_accuracy: 0.3710\n",
      "Epoch 986/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.6038 - accuracy: 0.3835 - val_loss: 1.6971 - val_accuracy: 0.3790\n",
      "Epoch 987/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.6199 - accuracy: 0.3801 - val_loss: 1.6895 - val_accuracy: 0.3810\n",
      "Epoch 988/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6050 - accuracy: 0.3827 - val_loss: 1.7001 - val_accuracy: 0.3770\n",
      "Epoch 989/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.6196 - accuracy: 0.3673 - val_loss: 1.6968 - val_accuracy: 0.3730\n",
      "Epoch 990/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.6038 - accuracy: 0.3784 - val_loss: 1.7030 - val_accuracy: 0.3770\n",
      "Epoch 991/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.6200 - accuracy: 0.3852 - val_loss: 1.6944 - val_accuracy: 0.3611\n",
      "Epoch 992/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.6173 - accuracy: 0.3759 - val_loss: 1.7080 - val_accuracy: 0.3750\n",
      "Epoch 993/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6064 - accuracy: 0.3801 - val_loss: 1.6895 - val_accuracy: 0.3690\n",
      "Epoch 994/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.6130 - accuracy: 0.3759 - val_loss: 1.7012 - val_accuracy: 0.3810\n",
      "Epoch 995/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.6165 - accuracy: 0.3724 - val_loss: 1.7018 - val_accuracy: 0.3790\n",
      "Epoch 996/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.6157 - accuracy: 0.3818 - val_loss: 1.6899 - val_accuracy: 0.3730\n",
      "Epoch 997/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6159 - accuracy: 0.3903 - val_loss: 1.7018 - val_accuracy: 0.3849\n",
      "Epoch 998/1000\n",
      "1176/1176 [==============================] - 0s 37us/step - loss: 1.6228 - accuracy: 0.3861 - val_loss: 1.6949 - val_accuracy: 0.3730\n",
      "Epoch 999/1000\n",
      "1176/1176 [==============================] - 0s 38us/step - loss: 1.6178 - accuracy: 0.3776 - val_loss: 1.7255 - val_accuracy: 0.3770\n",
      "Epoch 1000/1000\n",
      "1176/1176 [==============================] - 0s 39us/step - loss: 1.6220 - accuracy: 0.3835 - val_loss: 1.6933 - val_accuracy: 0.3730\n"
     ]
    }
   ],
   "source": [
    "inputs = Input(shape=(6,))\n",
    "x = Dense(10, activation='relu')(inputs)\n",
    "x = Dropout(0.1)(x)\n",
    "x = Dense(10, activation='relu')(x)\n",
    "x = Dropout(0.1)(x)\n",
    "x = Dense(10, activation='sigmoid')(x)\n",
    "x = Dropout(0.1)(x)\n",
    "\n",
    "output = Dense(20, activation='softmax')(x)\n",
    "model = Model(inputs=inputs, outputs=output)\n",
    "\n",
    "sgd = optimizers.SGD(lr=0.01, momentum=0.00, decay=0.001, nesterov=False)\n",
    "RMSprop = keras.optimizers.RMSprop(lr=0.001, rho=0.09, epsilon=0.001, decay=0.001)\n",
    "Adagrad = keras.optimizers.Adagrad(lr=0.01, epsilon=0.01, decay=0.0)\n",
    "Adadelta = keras.optimizers.Adadelta(lr=1.0, rho=0.95, epsilon=0.01, decay=0.0)\n",
    "Adam = keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=0.01, decay=0.0, amsgrad=False)\n",
    "Adamax = keras.optimizers.Adamax(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=0.01, decay=0.0)\n",
    "# Nadam = keras.optimizers.Nadam(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=0.01, schedule_decay=0.004)\n",
    "Nadam = keras.optimizers.Nadam(lr=0.002, beta_1=0.99, beta_2=0.9999, epsilon=0.01, schedule_decay=0.0005)\n",
    "\n",
    "# tbCallBack = TensorBoard(log_dir=r'C:\\Users\\Big data\\Desktop\\class\\DL\\tensorboard\\funcardproject',  # log 目录\n",
    "#                  histogram_freq=0,  # 按照何等频率（epoch）来计算直方图，0为不计算\n",
    "# #                  batch_size=32,     # 用多大量的数据计算直方图\n",
    "#                  write_graph=True,  # 是否存储网络结构图\n",
    "#                  write_grads=True, # 是否可视化梯度直方图\n",
    "#                  write_images=True,# 是否可视化参数\n",
    "#                  embeddings_freq=0, \n",
    "#                  embeddings_layer_names=None, \n",
    "#                  embeddings_metadata=None)\n",
    "model.summary()\n",
    "model.compile(optimizer=Nadam,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "history = model.fit(train_data,train_targets,\n",
    "                   epochs=1000,\n",
    "                   batch_size=32,\n",
    "                   validation_data=(test_data,test_targets)\n",
    "#                   ,callbacks=[tbCallBack]\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 35347 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 32244 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 33287 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 39511 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 35657 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 30340 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 25613 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 22833 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 20989 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 25976 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 35347 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 32244 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 33287 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 39511 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 35657 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 30340 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 25613 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 22833 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 20989 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 25976 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEWCAYAAAB2X2wCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAgAElEQVR4nO3deXxU1f3/8deHEEAWBSNtlS1YWxUwQEwtfqGCYq1LXerXDYMLailoLWrbn1SsW0u/blVERaVuVFKpdanWqtQFpS6FJshOLVQBEaoBBQUUDHx+f5xJMplMkkmYkNzJ+/l4zGPmnnvm3nNzJ585c+4955i7IyIi0deqqQsgIiLpoYAuIpIhFNBFRDKEArqISIZQQBcRyRAK6CIiGUIBXUQkQ7Ru6gKIAJjZycDPk6z6G3BMkvR17n66mT0N5CRZfxowBjg6ybqJQJsa9vccMB34Q3PaZ5J0kWoU0KW52Be4zt1fKk8ws47A/cCr7n51fGYzezz28kt3H5Kw7lagHXAQMMzdy+LWfR/4amx9sv3dBbRvhvsUqZOaXEREMoQCuohIhlBAFxHJEAroIiIZQgFdRCRDKKCLiGQIBXQRkQyhgC4ikiHUsUiak9+a2Sdxy1nAB8A5ZjYkIW95T81DzOzVhHVfJ3TWAXjZzOKn5coBflvL/v4Te93c9ilSJ6trCjozawfMBtoSvgAed/drE/JcAVwElAGlwAXuvqpRSiwiIkml0uSyDTjK3fsDA4BjzWxQQp63gQJ3zwMeB25ObzFFRKQudQZ0DzbHFrNjD0/IM8vdt8YW/wF0T2spRUSkTim1oZtZFlACHADc7e5zasl+IfB8DdsZDYwG6NChw6EHHXRQ/UorItLClZSUrHf3rsnW1dmGXiWzWWfgKeBSd1+cZP1I4MfAUHffVtu2CgoKvLi4OOV9i4gImFmJuxckW1ev2xbdfSPwKnBskp0cDUwATqormIuISPrVGdDNrGusZo6Z7UEYvP9fCXkGAvcRgvlHjVFQERGpXSpt6PsC02Lt6K2Ax9z9WTO7ASh292eAW4COwJ/MDGC1u5/UWIUWEZHq6gzo7r4QGJgk/Zq418mm3BKRZuTLL79kzZo1fPHFF01dFElBu3bt6N69O9nZ2Sm/Rz1FRVqINWvW0KlTJ3Jzc4n9kpZmyt3ZsGEDa9asoXfv3im/L1JjuRQVQW4utGoVnouKmrpEItHxxRdfkJOTo2AeAWZGTk5OvX9NRaaGXlQEo0fD1lj3pVWrwjJAYWHTlUskShTMo6Mh5yoyNfQJEyqDebmtW0O6iIhEKKCvXl2/dBFpXjZs2MCAAQMYMGAAX/va1+jWrVvF8vbt21PaxqhRo3jnnXdqzXP33XdTlKb22CFDhjB//vy0bGt3iEyTS8+eoZklWbqIpF9RUfgFvHp1+D+bOHHXmjdzcnIqguN1111Hx44d+dnPflYlj7vj7rRqlbyu+dBDD9W5n0suuaThhYy4yNTQJ06E9u2rprVvH9JFJL3Kr1mtWgXuldesGuNGhBUrVtCvXz/GjBlDfn4+69atY/To0RQUFNC3b19uuOGGirzlNeaysjI6d+7M+PHj6d+/P4cffjgffRT6NF599dVMmjSpIv/48eM57LDDOPDAA3nzzTcB2LJlC//7v/9L//79GTFiBAUFBXXWxKdPn84hhxxCv379uOqqqwAoKyvjnHPOqUifPHkyALfffjt9+vShf//+jBw5Mu1/s5pEJqAXFsLUqdCrF5iF56lTdUFUpDHs7mtWS5cu5cILL+Ttt9+mW7du3HjjjRQXF7NgwQJefPFFli5dWu09mzZtYujQoSxYsIDDDz+cBx98MOm23Z25c+dyyy23VHw53HnnnXzta19jwYIFjB8/nrfffrvW8q1Zs4arr76aWbNm8fbbb/PGG2/w7LPPUlJSwvr161m0aBGLFy/m3HPPBeDmm29m/vz5LFiwgLvuuqvWbadTZAI6hOC9ciXs3BmeFcxFGsfuvmb19a9/nW9961sVy48++ij5+fnk5+ezbNmypAF9jz324LjjjgPg0EMPZeXKlUm3feqpp1bL8/rrr3PWWWcB0L9/f/r27Vtr+ebMmcNRRx3FPvvsQ3Z2NmeffTazZ8/mgAMO4J133mHcuHHMnDmTvfbaC4C+ffsycuRIioqK6tUxaFdFKqCLyO5R07Wpxrpm1aFDh4rXy5cv54477uCVV15h4cKFHHvssUnvx27Tpk3F66ysLMrKypJuu23bttXy1GeU2dry5+TksHDhQoYMGcLkyZP50Y9+BMDMmTMZM2YMc+fOpaCggB07dtRrfw2lgC4i1TTlNatPP/2UTp06seeee7Ju3TpmzpyZ9n0MGTKExx57DIBFixYl/QUQb9CgQcyaNYsNGzZQVlbGjBkzGDp0KKWlpbg7p59+Otdffz3z5s1jx44drFmzhqOOOopbbrmF0tJStia2XzWSyNzlIiK7T3lzZjrvcklVfn4+ffr0oV+/fuy///4MHjw47fu49NJLOffcc8nLyyM/P59+/fpVNJck0717d2644QaGDRuGu3PiiSdywgknMG/ePC688ELcHTPjpptuoqysjLPPPpvPPvuMnTt3cuWVV9KpU6e0H0My9ZrgIp00wYXI7rVs2TIOPvjgpi5Gs1BWVkZZWRnt2rVj+fLlHHPMMSxfvpzWrZtXHTfZOattgovmVXoRkd1g8+bNDB8+nLKyMtyd++67r9kF84aI/hGIiNRT586dKSkpaepipJ0uioqIZAgFdBGRDJHKnKLtzGyumS0wsyVmdn2SPG3N7I9mtsLM5phZbmMUVkREapZKDX0bcJS79wcGAMea2aCEPBcCn7j7AcDtwE3pLaaIiNSlzoDuwebYYnbskXiv48nAtNjrx4HhppH0RSTOsGHDqnUSmjRpEhdffHGt7+vYsSMAa9eu5bTTTqtx23XdBj1p0qQqHXyOP/54Nm7cmErRa3Xddddx66237vJ20iGlNnQzyzKz+cBHwIvuPichSzfgfQB3LwM2ATlJtjPazIrNrLi0tHTXSi4ikTJixAhmzJhRJW3GjBmMGDEipffvt99+PP744w3ef2JAf+655+jcuXODt9ccpRTQ3X2Huw8AugOHmVm/hCzJauPVeiy5+1R3L3D3gq5du9a/tMAbb8App8D77zfo7SLSRE477TSeffZZtm3bBsDKlStZu3YtQ4YMqbgvPD8/n0MOOYSnn3662vtXrlxJv34h9Hz++eecddZZ5OXlceaZZ/L5559X5Bs7dmzF0LvXXnstAJMnT2bt2rUceeSRHHnkkQDk5uayfv16AG677Tb69etHv379KobeXblyJQcffDA//OEP6du3L8ccc0yV/SQzf/58Bg0aRF5eHj/4wQ/45JNPKvbfp08f8vLyKgYFe+211yom+Bg4cCCfffZZg/+25ep1H7q7bzSzV4FjgcVxq9YAPYA1ZtYa2Av4eJdLl8TatfD00/DrX0OPHo2xB5HMd9llkO6JeAYMgFgsTConJ4fDDjuMF154gZNPPpkZM2Zw5plnYma0a9eOp556ij333JP169czaNAgTjrppBrn1bznnnto3749CxcuZOHCheTn51esmzhxInvvvTc7duxg+PDhLFy4kJ/85CfcdtttzJo1i3322afKtkpKSnjooYeYM2cO7s63v/1thg4dSpcuXVi+fDmPPvoov/vd7zjjjDN44oknah3f/Nxzz+XOO+9k6NChXHPNNVx//fVMmjSJG2+8kffee4+2bdtWNPPceuut3H333QwePJjNmzfTrl27evy1k0vlLpeuZtY59noP4GjgXwnZngHOi70+DXjFG2lMgays8LxzZ2NsXUQaU3yzS3xzi7tz1VVXkZeXx9FHH80HH3zAhx9+WON2Zs+eXRFY8/LyyMvLq1j32GOPkZ+fz8CBA1myZEmdA2+9/vrr/OAHP6BDhw507NiRU089lb///e8A9O7dmwEDBgC1D9ELYXz2jRs3MnToUADOO+88Zs+eXVHGwsJCpk+fXtEjdfDgwVxxxRVMnjyZjRs3pqWnaipb2BeYZmZZhC+Ax9z9WTO7ASh292eAB4BHzGwFoWZ+1i6XrAblM1PtptEoRTJSbTXpxnTKKadwxRVXMG/ePD7//POKmnVRURGlpaWUlJSQnZ1Nbm5u0iFz4yWrvb/33nvceuut/POf/6RLly6cf/75dW6ntrpn+dC7EIbfravJpSZ//etfmT17Ns888wy/+tWvWLJkCePHj+eEE07gueeeY9CgQbz00kscdNBBDdp+uVTuclno7gPdPc/d+7n7DbH0a2LBHHf/wt1Pd/cD3P0wd393l0pVC9XQRaKrY8eODBs2jAsuuKDKxdBNmzbxla98hezsbGbNmsWqZBMIxzniiCMqJoJevHgxCxcuBMLQux06dGCvvfbiww8/5Pnnn694T6dOnZK2Ux9xxBH8+c9/ZuvWrWzZsoWnnnqK73znO/U+tr322osuXbpU1O4feeQRhg4dys6dO3n//fc58sgjufnmm9m4cSObN2/mP//5D4cccghXXnklBQUF/OtfiQ0f9Re5sVxUQxeJthEjRnDqqadWueOlsLCQE088kYKCAgYMGFBnTXXs2LGMGjWKvLw8BgwYwGGHHQaE2YcGDhxI3759qw29O3r0aI477jj23XdfZs2aVZGen5/P+eefX7GNiy66iIEDB9bavFKTadOmMWbMGLZu3cr+++/PQw89xI4dOxg5ciSbNm3C3bn88svp3Lkzv/zlL5k1axZZWVn06dOnYvalXRG54XNfeAGOOw7eegsGJXZvEpEaafjc6Knv8LmRG8tFNXQRkeQiF9DVhi4iklzkArpq6CIN11RNrFJ/DTlXkQvoqqGLNEy7du3YsGGDgnoEuDsbNmyod2cj3eUi0kJ0796dNWvWoHGUoqFdu3Z07969Xu+JXEBXDV2kYbKzs+ndu3dTF0MaUeSaXFRDFxFJLnIB/W9/C88nnAC5uRDrLCYi0uJFKqAXFcFvflO5vGoVjB6toC4iAhEL6BMmQOI4O1u3hnQRkZYuUgF99er6pYuItCSRCug9e9YvXUSkJYlUQJ84ERLvs2/fPqSLiLR0kQrohYVh6rlyvXrB1KkhXUSkpYtUQIcwQTTAtGmwcqWCuYhIuVTmFO1hZrPMbJmZLTGzcUny7GVmfzGzBbE8oxqnuOopKiJSk1S6/pcBP3X3eWbWCSgxsxfdPX7m1UuApe5+opl1Bd4xsyJ3357uAqunqIhIcqnMKbrO3efFXn8GLAO6JWYDOlmYtbUjYaLosjSXFVANXUSkJvVqQzezXGAgMCdh1V3AwcBaYBEwzt2rhVwzG21mxWZW3NAR31RDFxFJLuWAbmYdgSeAy9z904TV3wPmA/sBA4C7zGzPxG24+1R3L3D3gq5duzaowKqhi4gkl1JAN7NsQjAvcvcnk2QZBTzpwQrgPaD2absbSDV0EZHkUrnLxYAHgGXuflsN2VYDw2P5vwocCLybrkLGUw1dRCS5VO5yGQycAywys/mxtKuAngDufi/wK+BhM1sEGHClu69vhPKqhi4iUoM6A7q7v04I0rXlWQsck65C1UY1dBGR5CLXU1Q1dBGR5CIX0FVDFxFJLnIBXTV0EZHkIhfQVUMXEUkucgHdYpdnVUMXEakqkgG9VSvV0EVEEkUuoEMI6Kqhi4hUFcmAnpWlGrqISKJIBnTV0EVEqotkQFcNXUSkukgGdNXQRUSqi2RAVw1dRKS6SAZ01dBFRKqLZEBXDV1EpLrIBfSiItiwAe69F3Jzw7KIiEQsoBcVwejRlc0tq1aFZQV1EZGIBfQJE2Dr1qppW7eGdBGRli6VOUV7mNksM1tmZkvMbFwN+YaZ2fxYntfSX1RYvbp+6SIiLUkqc4qWAT9193lm1gkoMbMX3X1peQYz6wxMAY5199Vm9pXGKGzPnqGZJVm6iEhLV2cN3d3Xufu82OvPgGVAt4RsZwNPuvvqWL6P0l1QgIkToX37qmnt24d0EZGWrl5t6GaWCwwE5iSs+ibQxcxeNbMSMzu3hvePNrNiMysuLS2td2ELC2HqVGgd+13Rq1dYLiys96ZERDKOuXtqGc06Aq8BE939yYR1dwEFwHBgD+At4AR3/3dN2ysoKPDi4uIGFbpvX+jTB/70pwa9XUQkssysxN0Lkq1LpQ0dM8sGngCKEoN5zBpgvbtvAbaY2WygP1BjQN8V6ikqIlJdKne5GPAAsMzdb6sh29PAd8ystZm1B75NaGtvFOopKiJSXSo19MHAOcAiM5sfS7sK6Ang7ve6+zIzewFYCOwE7nf3xY1RYFANXUQkmToDuru/DlgK+W4BbklHoeqiGrqISHWR6ilaTjV0EZHqIhnQVUMXEakukgFdNXQRkeoiGdCzshTQRUQSRTKgt2qlJhcRkUSRDOiqoYuIVKeALiKSISIZ0Fu3VkAXEUkUyYCelQVlZU1dChGR5iWSAV01dBGR6iIb0FVDFxGpKnIBvagI/vpXWLYMcnPDsoiIRCygFxXB6NGwdWtYXrUqLCuoi4hELKBPmFAZzMtt3RrSRURaukgF9NWr65cuItKSRCqg9+xZv3QRkZYkUgF94kRo375qWvv2IV1EpKVLZU7RHmY2y8yWmdkSMxtXS95vmdkOMzstvcUMCgth6lTo1Cks9+oVlgsLG2NvIiLRksqcomXAT919npl1AkrM7EV3XxqfycyygJuAmY1QzgqFhTB/PkyZAitXNuaeRESipc4auruvc/d5sdefAcuAbkmyXgo8AXyU1hImoa7/IiLV1asN3cxygYHAnIT0bsAPgHvreP9oMys2s+LS0tL6lTSOeoqKiFSXckA3s46EGvhl7v5pwupJwJXuXusIK+4+1d0L3L2ga9eu9S9tTOvWYYIL9wZvQkQk46TSho6ZZROCeZG7P5kkSwEww8wA9gGON7Myd/9z2koap3Ws1Dt2VL4WEWnp6gyHFqL0A8Ayd78tWR537x2X/2Hg2cYK5lAZxMvKFNBFRMqlEg4HA+cAi8xsfiztKqAngLvX2m7eGOIDuoiIBHUGdHd/HbBUN+ju5+9KgVKRlRWeFdBFRCpFqqdoOdXQRUSqi3RA16xFIiKVIh3QVUMXEamkgC4ikiEiGdDnzg3Pubmahk5EpFzkAnpRETz4YOWypqETEQkiF9AnTIDt26umaRo6EZEIBnRNQyciklzkArqmoRMRSS5yAX3iRGjbtmqapqETEYlgQC8shMsuq1zWNHQiIkHkAjrAd78bnl97LUxDp2AuIhLRgK6u/yIi1UU6oKunqIhIJQV0EZEMoYAuIpIhIhnQNcGFiEh1dQZ0M+thZrPMbJmZLTGzcUnyFJrZwtjjTTPr3zjFDVRDFxGpLpUaehnwU3c/GBgEXGJmfRLyvAcMdfc84FfA1PQWs6rnnw/PZ5yh0RZFRMqlMqfoOmBd7PVnZrYM6AYsjcvzZtxb/gF0T3M5KxQVwTXXVC6Xj7YIuh9dRFq2erWhm1kuMBCYU0u2C4Hna3j/aDMrNrPi0tLS+uy6woQJ8MUXVdM02qKISD0Cupl1BJ4ALnP3T2vIcyQhoF+ZbL27T3X3Ancv6Nq1a0PKq9EWRURqkFJAN7NsQjAvcvcna8iTB9wPnOzuG9JXxKo02qKISHKp3OViwAPAMne/rYY8PYEngXPc/d/pLWJVEyfCHntUTdNoiyIiKVwUBQYD5wCLzGx+LO0qoCeAu98LXAPkAFNC/KfM3QvSX9xw4XP7drjggrDcq1cI5rogKiItnbl7k+y4oKDAi4uLG/TenTtD56Jrr4XrrktvuUREmjMzK6mpwhzJnqKPPhqer79e96GLiJSLXEAvKqq87xwq70NXUBeRli5yAX3ChHDfeTzdhy4iEsGArvvQRUSSi1xA133oIiLJRS6gT5wY7juPZwbHH9805RERaS4iF9ALC+G886qmucO0abowKiItW+QCOsBzz1VP04VREWnpIhnQV62qX7qISEsQyYAuIiLVZVxAVzu6iLRUGRfQR45UUBeRlinjAjooqItIyxTJgN6rV915zj9fQV1EWpZIBvRUJrMoK6scM11EpCWIZEAvLITWKUzNsX07dOnS+OUREWkOUpmCroeZzTKzZWa2xMzGJcljZjbZzFaY2UIzy2+c4lYaOza1fBs3hqEB9tlHTTAiktlSqaGXAT9194OBQcAlZtYnIc9xwDdij9HAPWktZRKnnFK//Bs2qF1dRDJbnQHd3de5+7zY68+AZUC3hGwnA7/34B9AZzPbN+2ljbNvbOtjxqT+nrIy+NGPGqc8IiJNrV5t6GaWCwwE5iSs6ga8H7e8hupBP60OOCC0o3fpAu3apf6+LVvg6KMbr1wiIk0l5YBuZh2BJ4DL3P3TxNVJ3lJt9mkzG21mxWZWXFpaWr+SJsjOhm9+E5YsgfvvT+0iabmXX4aLL96l3YuINDspBXQzyyYE8yJ3fzJJljVAj7jl7sDaxEzuPtXdC9y9oGvXrg0pbxV9+sCiReGul4cfTu3+9HL3NHorv4jI7pXKXS4GPAAsc/fbasj2DHBu7G6XQcAmd1+XxnImNXQovPceLF4cgvrKlTB9eurvV9OLiGSSVGrog4FzgKPMbH7scbyZjTGz8kuSzwHvAiuA3wG7pUHjjDMgKwumTKlMKyxM/ZbGl19unHKJiDSFOlue3f11kreRx+dx4JJ0FSpVX/lKuGtlyhTYe2+44QZo1SosDx4ceopu3177Nvr2De3wIiJRF8meovHuuAMuvDAMB3DWWfDFFyG9sBC2bQudimqzdKnuTReRzBD5gN66Nfzud3DLLfCnP8Hw4bB+feX6VO5T19R1IpIJIh/QIdTCf/YzeOwxKCmB/HyYNSusmzKl7jZ1TV0nIpkgIwJ6udNPh7//Hdq3h2OOgTvvDOlTpoSae210X7qIRF1GBXSAb30L5s6F44+Hn/wk1Nx37oSXXqr9fbovXUSiLuMCOsCee8KTT8Ill8BvfwvnnFP33S6gi6MiEm316DAfLVlZocmlRw8YPx46dw7NLrXdez5yZHguLNw9ZRQRSaeMDegQLpZeeSWUloaa+uOPw6uvwo4dNb+nfJYjBXURiZqMbHJJ9JvfwKGHhrtd7r679rzbt+s2RhGJphYR0Nu0gQcegI8/Drc11tXZSLcxikgUtYiADtC/P1x2WeiEdOaZdefXwF0iEjUtJqAD/PznoWdp9+515335Zc1FKiLR0qIC+le/CiedFMZO33vv1N6zYUO4UKqgLiLNXYsK6ACXXx7Gejn55NTfs317uKVRtXURac5aXEAfPBgOPhj+/e/Ux00vt2EDnHeegrqINE8tLqCbheF233gjDLdbXzt2qLYuIs1TiwvoEGrm++0Hv/gF9OzZsG2obV1EmptU5hR90Mw+MrPFNazfy8z+YmYLzGyJmY1KfzHTq317uPZaePNNOO20sNwQ5W3rnTqFmZJycxXgRaTppFJDfxg4tpb1lwBL3b0/MAz4rZm12fWiNa5Ro+CAA0JHo6lTU7/rJZnNm8E9dEhSc4yINJU6A7q7zwY+ri0L0MnMDOgYy1uWnuI1nuxs+P734bXXQhD++OMQ5NNhw4awTd3HLiK7Uzra0O8CDgbWAouAce6+M1lGMxttZsVmVlxaWpqGXe+aCy+suvzQQ9C7d3r3UR7cNYGGiDS2dAT07wHzgf2AAcBdZrZnsozuPtXdC9y9oGvXrmnY9a7p1w9Wr66c2QjgvfcaZ1/33BNq7IkPtbuLSLqkI6CPAp70YAXwHnBQGra7W/ToAT/+MWzbBjk5u3//5e3u7dqF5hldXBWRhkpHQF8NDAcws68CBwLvpmG7u1WbNqEH6c6d8Pvfw1VXhUC/u2zbFppn4i+uJqvRq01eRGpi7l57BrNHCXev7AN8CFwLZAO4+71mth/hTph9AQNudPfpde24oKDAi4uLd6Xsjc4d7r8fbr4ZVqxo6tLULCsrdHjq1QsmTtTkHCKZzMxK3L0g6bq6AnpjiUJAj1dUFGrtq1eHmnIT/dlSMnx4+AJavTp0nFKQF8kctQX0FtlTtCEKC0NTiHtoljn33LonymgqL79cWdby5pusrHCnTVFRaKNXW71I5lENPU0uvjh0UKptvtLmqmNHuPde1eJFokA19N1gyhQoKwu14unTQ404KjZvrrwI26mTau0iUaWA3ggKC2HatOpjxGRnN/9Anxjc1TQjkj6ffAJjxoT/s8aggN5ICgtDE0yvXiE49uoVeqJOmxZeR0HiGDXZ2SGwqx1epGFuugnuuy/MbdwYWjfOZgVCUE/WLp0sragIxo0L96I3V2VlIbDHW7UKRo8Or9UGL5LcZ5/BK6+E/ibQeNfaVENvJgoLQ8cm9+qP6dNDx6fmauvWEOhzc8PFYdXepTbusG5dU5cCHnwQXngB5s6F//kf2LIlPdtdtw7efRcuvRS++91QG99zTzjlFJg0KeRptDvk3L1JHoceeqhL/Ywd656VVT3kt23r3qFDsq+C5vHIyXEfPryy7FlZ4VikaWzf7r5lS/X0zZt3bbulpe533eW+c2fN+/2//3O/4orwOVi8uO5tfvqp+5dfhtcrVoTnd991X7vW/Ysv3G++2X3yZPd77nF/9VX3118Pn7UlS9z//nf3Sy5xf+cd9yOPdF+3zn3iRPePP3ZftKj653T48LCP+L/Nxx9XL9OSJSH/zTdXpu3c6b5smXt+fmr/E7/6VWp/02SAYq8hriqgZ5jp05t3cI9/1BTUp09379XL3Sw8T5/esDxSacYM95tucn/zzcq//86d7mef7d6tm/tJJ4W0004LgfeDD9wvuMD95JPd99/ffeVK9z32CHleeMG9f3/3OXPc99knVChGj3b/3vfC+sMOc7/66hDc7rvP/fLLwzafeabq+R82zP33v3e/9tpQjs8/D2X94x/dL7rI/aijQr6LLnI/8cTw+vTTU/tsDRlS87pRo2p/74EHuj//fOXyVVe533ln+PvNnes+Zsyuf/avuabh51IBvQUqD3gQgl5TB++6Hq1aheecHPc2baquM6sa/KdPd2/fvmqe9u1Dnl0N8p9+Gv55U9nOwoXuM2fWvUHU9J0AAAq2SURBVM2yssrXW7dW7mfVKvcPPwyBdfp09wUL3D/5JNQS//vfUOt85hn35ctDzTYvz/32293/8pfqwWn8+BB0x4+vXPfDH7r37t3057Y+n4Ejjti9+3zppeqft119vPGGe3Gx+wMPhPM3ebL7mjXuzz4bluM/Dw2hgN7CJdZm45s/Mv3xne+49+wZXmdlVf9y69zZfdw491//OtQYk20jKysExv79w0/43/7WfcSIqushBIYf/cj9D38ItdvCwlDbiw9YEGq8Tf13iX98+9tVl+ODao8e7t/8Znr2c8QR7q+95j5lSsPef/HF7q1bh7/9L38ZavJ33RXWjRwZas+nnBJ+hbRvH35tgPt++1Vu49JL3X/2s/DFuG5d+P/47LNQrvJfKePHu591VmhSKSqqWoavfz0877ln1fSCAvfrrw9NQY1NAV1qNH16qBUnBh09mt+jR4/KoFP+yMlx//733Tt1qp6//MvruONCc8gjj7jfdlv4dbB5s/vSpZWfg/ffd586tebPyd/+5v7jH4fgt3ix+1tvhV8y77wTap9//rP7jh0h7403hqYYcN97b/dp06rXSjdvdn/qqdAc88IL4VfKH//ofsABoRa7eLH7tm2hvDfcUFm2zZurt9Fv2RLa0xO3v2OH+yuvVP4qqqltv9yOHZV54/30p+FYPvmkMm3btvD3LCmpvu/GpoAu9RbfZKNH0z9q+kXVqlXN69q0qdpcVNd1h/pcl4j/fJTvv1ev0OyVrDkslW011+shO3a4b9rU1KWopIAuuyT+Hy4qF1z1qHw0l2soHTpU/wWYkxOaUVJ5f/l7E9u8hw+v/JzG/9rs0CEs1+cLKlnexO3m5NTvizLdagvoGpxL6u3oo8OIjiJRl5UFw4bBW2+F/hTxhg8Pz+n4rOfkwBlnwGOPVXYezMmBO+6of4c8jYcuaVdUBBMmVI65fvzxYViDxH8KEalZmzahg1N9grpGW5S0KyyElSvD2PArV4bRJsvHroHKQcia+2BkIk1p+/ZQMUqXOgO6mT1oZh+Z2eJa8gwzs/lmtsTMXktf8SRKyoO8e+VQwmVlYeiC8kHKcnKgQ4emLqlI87F6dfq2lUoN/WHg2JpWmllnYApwkrv3BU5PT9EkU8TX5tevrxzFMfERH/h79apsw0zUtu1uLb5Io+rZM33bqjOgu/ts4ONaspwNPOnuq2P5P0pT2aSFSWzGeeml6kF++nT44ovk6cnS3GHs2NT2n5PTfKcVlMw1cWIaN1bT7S/xDyAXWFzDuknA3cCrQAlwbi3bGQ0UA8U9e/Zs3Ht7ROI01j3WeuixK48+fer/WWZX70OvI6DfBfwD6ADsAywHvlnXNnUfukRRbcE+/gsjfjknp/I+5vL3lKeV39tffo91+UiUyTp2JY5SWVMv3/j7zjt0aNy+Ay1lCInGeOy3X8M+g40d0McD18UtPwCcXtc2FdBFdq9kX0bxX0rTpyf/JVPTYGjJ8o8dW/VLJvFR3iln7NiqXzxt21btBDR8eMM6RMV/MTZ1wK7tUd4ZqiEaO6AfDLxMmP2oPbAY6FfXNhXQRaKjvr0h6+pdWd991jQKZ/yXUUO2kfgo/1JKli/+l1P8F1h9muE6dtz1nqS7FNCBR4F1wJfAGuBCYAwwJi7Pz4GlsWB+WV3bdAV0EamndHSxb4xu+olfGqkON9BQtQV09RQVEYkQ9RQVEWkBFNBFRDKEArqISIZQQBcRyRAK6CIiGaLJ7nIxs1JgVQPfvg+wPo3FiQIdc8ugY24ZduWYe7l712Qrmiyg7wozK67ptp1MpWNuGXTMLUNjHbOaXEREMoQCuohIhohqQJ/a1AVoAjrmlkHH3DI0yjFHsg1dRESqi2oNXUREEiigi4hkiMgFdDM71szeMbMVZja+qcuTDmbWw8xmmdkyM1tiZuNi6Xub2Ytmtjz23CWWbmY2OfY3WGhm+U17BA1nZllm9raZPRtb7m1mc2LH/EczaxNLbxtbXhFbn9uU5W4oM+tsZo+b2b9i5/vwTD/PZnZ57HO92MweNbN2mXaezexBM/vIzBbHpdX7vJrZebH8y83svPqWI1IB3cyyCPOXHgf0AUaYWZ+mLVValAE/dfeDgUHAJbHjGg+87O7fIEwiUv4FdhzwjdhjNHDP7i9y2owDlsUt3wTcHjvmTwjj7xN7/sTdDwBuj+WLojuAF9z9IKA/4dgz9jybWTfgJ0CBu/cDsoCzyLzz/DBwbEJavc6rme0NXAt8GzgMuLb8SyBlNQ2U3hwfwOHAzLjlXwC/aOpyNcJxPg18F3gH2DeWti/wTuz1fcCIuPwV+aL0ALrHPuhHAc8CRug91zrxfAMzgcNjr1vH8llTH0M9j3dP4L3EcmfyeQa6Ae8De8fO27PA9zLxPJMws1t9zyswArgvLr1KvlQekaqhU/nhKLcmlpYxYj8xBwJzgK+6+zqA2PNXYtky5e8wCfh/wM7Ycg6w0d3LYsvxx1VxzLH1m2L5o2R/oBR4KNbMdL+ZdSCDz7O7fwDcCqwmzHy2CSghs89zufqe110+31EL6JYkLWPuuzSzjsAThGn8Pq0ta5K0SP0dzOz7wEfuXhKfnCSrp7AuKloD+cA97j4Q2ELlz/BkIn/MsSaDk4HewH5AB0KTQ6JMOs91qekYd/nYoxbQ1wA94pa7A2ubqCxpZWbZhGBe5O5PxpI/NLN9Y+v3BT6KpWfC32EwcJKZrQRmEJpdJgGdzax1LE/8cVUcc2z9XsDHu7PAabAGWOPuc2LLjxMCfCaf56OB99y91N2/BJ4E/ofMPs/l6nted/l8Ry2g/xP4RuwKeRvCxZVnmrhMu8zMDHgAWObut8WtegYov9J9HqFtvTz93NjV8kHApvKfdlHh7r9w9+7unks4j6+4eyEwCzgtli3xmMv/FqfF8keq5ubu/wXeN7MDY0nDCZOrZ+x5JjS1DDKz9rHPefkxZ+x5jlPf8zoTOMbMusR+2RwTS0tdU19IaMCFh+OBfwP/ASY0dXnSdExDCD+tFgLzY4/jCW2HLwPLY897x/Ib4W6f/wCLCHcQNPlx7MLxDwOejb3eH5gLrAD+BLSNpbeLLa+Ird+/qcvdwGMdABTHzvWfgS6Zfp6B64F/AYuBR4C2mXaegUcJ1wi+JNS0L2zIeQUuiB37CmBUfcuhrv8iIhkiak0uIiJSAwV0EZEMoYAuIpIhFNBFRDKEArqISIZQQJcWxcw2N3UZRBqLArqISIZQQJcWz8x6mdnLsbGpXzaznrH002NjeC8ws9mxtL5mNtfM5sfyf6NpSy9SSR2LpEUxs83u3jEh7S/A4+4+zcwuAE5y91PMbBFwrLt/YGad3X2jmd0J/MPdi2LDT2S5++dNcCgi1aiGLhLG4/5D7PUjhKEYAN4AHjazHxImZgB4C7jKzK4EeimYS3OigC5SnQO4+xjgasIIePPNLMfd/wCcBHwOzDSzo5qumCJVKaCLwJuEER8BCoHXAczs6+4+x92vIcyc08PM9gfedffJhFHz8pqiwCLJqA1dWhQz20nVMaZvI4zR/SCwD2FGoVHuvtrMniTM+2iE0fIuI0xIMZIwqt5/gbPdParjdUuGUUAXEckQanIREckQCugiIhlCAV1EJEMooIuIZAgFdBGRDKGALiKSIRTQRUQyxP8HmNmdCSKRAkwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#繪圖\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(loss)+ 1)\n",
    "plt.plot(epochs, loss,'bo',label='Training loss')\n",
    "plt.plot(epochs, val_loss,'b',label='Validation loss')\n",
    "plt.title('訓練與驗證的損失函數')\n",
    "plt.xlabel('Epohs')\n",
    "plt.xlabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()\n",
    "plt.figure(figsize=(12, 7))  \n",
    "acc = history.history['accuracy']\n",
    "val_acc=history.history['val_accuracy']\n",
    "\n",
    "plt.plot(epochs, acc, 'r',label='Training acc')\n",
    "plt.plot(epochs, val_acc,'b',label='Validation acc')\n",
    "plt.title('')\n",
    "plt.xlabel('Epohs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 測試小綠同學"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>serveTime</th>\n",
       "      <th>Loan</th>\n",
       "      <th>SalPerY</th>\n",
       "      <th>holdCard</th>\n",
       "      <th>Career</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>120</td>\n",
       "      <td>4</td>\n",
       "      <td>600000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>6000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>87</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  age serveTime Loan  SalPerY holdCard Career\n",
       "0   8       120    4   600000        1      1\n",
       "1  28        12    0  6000000        0      0\n",
       "2  28        12    0       87        2      0"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "小綠 = pd.DataFrame(columns=[\"age\",\"serveTime\",\"Loan\",\"SalPerY\",\"holdCard\",\"Career\"])\n",
    "小綠.loc[0]=8,120,4,600000,1,1\n",
    "小綠.loc[1]=28,12,0,6000000,0,0\n",
    "小綠.loc[2]=28,12,0,87,2,0\n",
    "小綠"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 因為先前輸入時有先標準化,因此輸入也要標準化\n",
    "小綠-=train_data_min\n",
    "小綠/=train_data_range\n",
    "#轉array\n",
    "小綠 = 小綠.astype(float)\n",
    "# 小綠 = np.array(小綠).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.81298182e-03, 4.00218256e-02, 5.86975664e-02, 8.23580325e-02,\n",
       "       1.24504596e-01, 6.93644881e-02, 1.49908409e-01, 6.63447380e-02,\n",
       "       9.24009755e-02, 6.84787557e-02, 1.08294696e-01, 7.16294744e-05,\n",
       "       8.88442397e-02, 7.81617593e-03, 2.54195952e-03, 1.06555126e-04,\n",
       "       4.07484313e-03, 7.00481614e-05, 2.02694144e-02, 6.01802999e-03],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 他給出的是每一群的機率(相加為一)\n",
    "preds = model.predict(小綠)\n",
    "preds[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#接著我們找出裡面機率最大的值的所在位子\n",
    "qq = np.where(preds[1]==np.max(preds[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#回傳值\n",
    "qq[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
