{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'momentum' from 'keras.optimizers' (C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-52-38fe26ed4d2a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcross_validate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mAdam\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mAdagrad\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmomentum\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'momentum' from 'keras.optimizers' (C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py)"
     ]
    }
   ],
   "source": [
    "from keras.datasets import boston_housing\n",
    "from keras.datasets import reuters\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "from keras import losses\n",
    "from keras import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.optimizers import Adam,Adagrad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1687"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel(r'C:\\Users\\Big data\\Desktop\\class\\funcardproject\\斷詞與和卡額度_20群.xls',encoding='utf-16')\n",
    "df = df.loc[:, [\"age\",\"serveTime\",\"credLimit\",\"Loan\",\"SalPerY\",\"holdCard\",\"Career\",\"credLimit_group\"]] \n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df =df.dropna(\n",
    "    axis=0,     # 0: 对行进行操作; 1: 对列进行操作\n",
    "    how='any'   # 'any': 只要存在 NaN 就 drop 掉; 'all': 必须全部是 NaN 才 drop \n",
    "    ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['credLimit_group'] = df['credLimit_group'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1680 entries, 0 to 1686\n",
      "Data columns (total 8 columns):\n",
      "age                1680 non-null float64\n",
      "serveTime          1680 non-null float64\n",
      "credLimit          1680 non-null int64\n",
      "Loan               1680 non-null float64\n",
      "SalPerY            1680 non-null int64\n",
      "holdCard           1680 non-null int64\n",
      "Career             1680 non-null int64\n",
      "credLimit_group    1680 non-null int32\n",
      "dtypes: float64(3), int32(1), int64(4)\n",
      "memory usage: 111.6 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1176, 6)\n",
      "(504, 6)\n",
      "(1176, 1)\n",
      "(504, 1)\n"
     ]
    }
   ],
   "source": [
    "#先打散資料(三次)\n",
    "for i in range(3):\n",
    "    df = shuffle(df)\n",
    "#再切成訓練與測試\n",
    "train_data, test_data, train_targets, test_targets = train_test_split(df.loc[:, [\"age\",\"serveTime\",\"Loan\",\"SalPerY\",\"holdCard\",\"Career\"]] , df.loc[:, [\"credLimit_group\"]] , test_size=0.3, random_state=42)\n",
    "print(train_data.shape)\n",
    "print(test_data.shape)\n",
    "print(train_targets.shape)\n",
    "print(test_targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#轉array\n",
    "train_data = np.array(train_data).astype(float)\n",
    "test_data = np.array(test_data).astype(float)\n",
    "train_targets = np.array(train_targets).astype(int)\n",
    "test_targets = np.array(test_targets).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_one_hot(labels, dimension=20):\n",
    "    results = np.zeros((len(labels),dimension))\n",
    "    for i,label in enumerate(labels):\n",
    "        results[i,label]=1.\n",
    "    return results\n",
    "train_targets = to_one_hot(train_targets)\n",
    "test_targets = to_one_hot(test_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1176, 6)\n",
      "(504, 6)\n",
      "(1176, 20)\n",
      "(504, 20)\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape)\n",
    "print(test_data.shape)\n",
    "print(train_targets.shape)\n",
    "print(test_targets.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 正規化(例如本資料serveTime與SalPerY不同單位且數值差異甚大,因此需轉為標準差)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 懶人正規化??????????????????????\n",
    "mean = train_data.mean(axis=0)\n",
    "train_data -=mean\n",
    "std = train_data.std(axis=0)\n",
    "train_data/=std\n",
    "test_data-=mean\n",
    "test_data/=std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.08103657, -0.75815913, -0.56035474, -0.54675532, -1.21267813,\n",
       "        -0.2173947 ],\n",
       "       [ 0.71436196,  0.04796538,  0.7140517 , -0.00441929,  0.82462113,\n",
       "        -0.2173947 ],\n",
       "       [ 2.5097605 , -0.12477558,  0.47722092,  0.36960557,  0.82462113,\n",
       "        -0.2173947 ],\n",
       "       ...,\n",
       "       [ 0.26551233, -0.61420832,  0.10138331, -0.02312053,  0.82462113,\n",
       "        -0.2173947 ],\n",
       "       [ 1.61206123,  2.63907989,  0.33452527,  0.08908693, -1.21267813,\n",
       "         1.33203662],\n",
       "       [-1.08103657,  0.30707683, -0.17428534, -0.28493793,  0.82462113,\n",
       "        -0.2173947 ]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 建立模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#模型定義\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(30, activation='relu',input_shape=(6 , )))\n",
    "model.add(layers.Dense(25, activation='relu'))\n",
    "model.add(layers.Dense(20, activation='relu'))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model.add(layers.Dense(20, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.compile(optimizer=optimizers.RMSprop(lr=0.0001, rho=0.9),\n",
    "              loss='categorical_crossentropy',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_5 (Dense)              (None, 30)                210       \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 25)                775       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 20)                520       \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 20)                420       \n",
      "=================================================================\n",
      "Total params: 1,925\n",
      "Trainable params: 1,925\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1176 samples, validate on 504 samples\n",
      "Epoch 1/200\n",
      "1176/1176 [==============================] - 0s 281us/step - loss: 1.9394 - accuracy: 0.3656 - val_loss: 11.7389 - val_accuracy: 0.2996\n",
      "Epoch 2/200\n",
      "1176/1176 [==============================] - 0s 210us/step - loss: 1.9254 - accuracy: 0.3656 - val_loss: 11.9624 - val_accuracy: 0.3016\n",
      "Epoch 3/200\n",
      "1176/1176 [==============================] - 0s 214us/step - loss: 1.9164 - accuracy: 0.3682 - val_loss: 12.0816 - val_accuracy: 0.3036\n",
      "Epoch 4/200\n",
      "1176/1176 [==============================] - 0s 212us/step - loss: 1.9122 - accuracy: 0.3724 - val_loss: 12.2808 - val_accuracy: 0.3036\n",
      "Epoch 5/200\n",
      "1176/1176 [==============================] - 0s 210us/step - loss: 1.8911 - accuracy: 0.3724 - val_loss: 12.2826 - val_accuracy: 0.3036\n",
      "Epoch 6/200\n",
      "1176/1176 [==============================] - 0s 217us/step - loss: 1.8745 - accuracy: 0.3724 - val_loss: 12.3096 - val_accuracy: 0.3056\n",
      "Epoch 7/200\n",
      "1176/1176 [==============================] - 0s 216us/step - loss: 1.8659 - accuracy: 0.3724 - val_loss: 12.4013 - val_accuracy: 0.3056\n",
      "Epoch 8/200\n",
      "1176/1176 [==============================] - 0s 223us/step - loss: 1.8677 - accuracy: 0.3724 - val_loss: 12.5007 - val_accuracy: 0.3056\n",
      "Epoch 9/200\n",
      "1176/1176 [==============================] - 0s 211us/step - loss: 1.8665 - accuracy: 0.3724 - val_loss: 12.5862 - val_accuracy: 0.3075\n",
      "Epoch 10/200\n",
      "1176/1176 [==============================] - 0s 215us/step - loss: 1.8664 - accuracy: 0.3741 - val_loss: 12.6077 - val_accuracy: 0.3075\n",
      "Epoch 11/200\n",
      "1176/1176 [==============================] - 0s 215us/step - loss: 1.8605 - accuracy: 0.3733 - val_loss: 12.6691 - val_accuracy: 0.3075\n",
      "Epoch 12/200\n",
      "1176/1176 [==============================] - 0s 206us/step - loss: 1.8626 - accuracy: 0.3741 - val_loss: 12.7506 - val_accuracy: 0.3075\n",
      "Epoch 13/200\n",
      "1176/1176 [==============================] - 0s 230us/step - loss: 1.8616 - accuracy: 0.3750 - val_loss: 12.7759 - val_accuracy: 0.3075\n",
      "Epoch 14/200\n",
      "1176/1176 [==============================] - 0s 234us/step - loss: 1.8636 - accuracy: 0.3759 - val_loss: 12.7910 - val_accuracy: 0.3075\n",
      "Epoch 15/200\n",
      "1176/1176 [==============================] - 0s 222us/step - loss: 1.8616 - accuracy: 0.3741 - val_loss: 12.7957 - val_accuracy: 0.3075\n",
      "Epoch 16/200\n",
      "1176/1176 [==============================] - 0s 225us/step - loss: 1.8614 - accuracy: 0.3759 - val_loss: 12.8457 - val_accuracy: 0.3075\n",
      "Epoch 17/200\n",
      "1176/1176 [==============================] - 0s 205us/step - loss: 1.8609 - accuracy: 0.3759 - val_loss: 12.8910 - val_accuracy: 0.3075\n",
      "Epoch 18/200\n",
      "1176/1176 [==============================] - 0s 208us/step - loss: 1.8603 - accuracy: 0.3750 - val_loss: 12.9747 - val_accuracy: 0.3075\n",
      "Epoch 19/200\n",
      "1176/1176 [==============================] - 0s 205us/step - loss: 1.8606 - accuracy: 0.3759 - val_loss: 12.9862 - val_accuracy: 0.3075\n",
      "Epoch 20/200\n",
      "1176/1176 [==============================] - 0s 200us/step - loss: 1.8612 - accuracy: 0.3750 - val_loss: 13.0128 - val_accuracy: 0.3075\n",
      "Epoch 21/200\n",
      "1176/1176 [==============================] - 0s 203us/step - loss: 1.8570 - accuracy: 0.3750 - val_loss: 13.0343 - val_accuracy: 0.3075\n",
      "Epoch 22/200\n",
      "1176/1176 [==============================] - 0s 208us/step - loss: 1.8575 - accuracy: 0.3759 - val_loss: 13.0466 - val_accuracy: 0.3075\n",
      "Epoch 23/200\n",
      "1176/1176 [==============================] - 0s 210us/step - loss: 1.8570 - accuracy: 0.3767 - val_loss: 13.0851 - val_accuracy: 0.3075\n",
      "Epoch 24/200\n",
      "1176/1176 [==============================] - 0s 205us/step - loss: 1.8572 - accuracy: 0.3767 - val_loss: 13.1165 - val_accuracy: 0.3075\n",
      "Epoch 25/200\n",
      "1176/1176 [==============================] - 0s 201us/step - loss: 1.8546 - accuracy: 0.3767 - val_loss: 13.1559 - val_accuracy: 0.3075\n",
      "Epoch 26/200\n",
      "1176/1176 [==============================] - 0s 200us/step - loss: 1.8552 - accuracy: 0.3767 - val_loss: 13.2723 - val_accuracy: 0.3075\n",
      "Epoch 27/200\n",
      "1176/1176 [==============================] - 0s 209us/step - loss: 1.8559 - accuracy: 0.3767 - val_loss: 13.2921 - val_accuracy: 0.3075\n",
      "Epoch 28/200\n",
      "1176/1176 [==============================] - 0s 200us/step - loss: 1.8544 - accuracy: 0.3750 - val_loss: 13.3192 - val_accuracy: 0.3075\n",
      "Epoch 29/200\n",
      "1176/1176 [==============================] - 0s 203us/step - loss: 1.8533 - accuracy: 0.3750 - val_loss: 13.3370 - val_accuracy: 0.3056\n",
      "Epoch 30/200\n",
      "1176/1176 [==============================] - 0s 200us/step - loss: 1.8542 - accuracy: 0.3776 - val_loss: 13.4446 - val_accuracy: 0.3075\n",
      "Epoch 31/200\n",
      "1176/1176 [==============================] - 0s 208us/step - loss: 1.8556 - accuracy: 0.3759 - val_loss: 13.4204 - val_accuracy: 0.3075\n",
      "Epoch 32/200\n",
      "1176/1176 [==============================] - 0s 207us/step - loss: 1.8522 - accuracy: 0.3759 - val_loss: 13.4181 - val_accuracy: 0.3056\n",
      "Epoch 33/200\n",
      "1176/1176 [==============================] - 0s 203us/step - loss: 1.8516 - accuracy: 0.3767 - val_loss: 13.4426 - val_accuracy: 0.3056\n",
      "Epoch 34/200\n",
      "1176/1176 [==============================] - 0s 204us/step - loss: 1.8502 - accuracy: 0.3759 - val_loss: 13.4484 - val_accuracy: 0.3056\n",
      "Epoch 35/200\n",
      "1176/1176 [==============================] - 0s 215us/step - loss: 1.8502 - accuracy: 0.3759 - val_loss: 13.4606 - val_accuracy: 0.3056\n",
      "Epoch 36/200\n",
      "1176/1176 [==============================] - 0s 203us/step - loss: 1.8497 - accuracy: 0.3767 - val_loss: 13.4518 - val_accuracy: 0.3056\n",
      "Epoch 37/200\n",
      "1176/1176 [==============================] - 0s 207us/step - loss: 1.8515 - accuracy: 0.3767 - val_loss: 13.5227 - val_accuracy: 0.3056\n",
      "Epoch 38/200\n",
      "1176/1176 [==============================] - 0s 202us/step - loss: 1.8503 - accuracy: 0.3759 - val_loss: 13.4659 - val_accuracy: 0.3056\n",
      "Epoch 39/200\n",
      "1176/1176 [==============================] - 0s 206us/step - loss: 1.8453 - accuracy: 0.3759 - val_loss: 13.5628 - val_accuracy: 0.3056\n",
      "Epoch 40/200\n",
      "1176/1176 [==============================] - 0s 205us/step - loss: 1.8462 - accuracy: 0.3750 - val_loss: 13.4670 - val_accuracy: 0.3056\n",
      "Epoch 41/200\n",
      "1176/1176 [==============================] - 0s 207us/step - loss: 1.8454 - accuracy: 0.3759 - val_loss: 13.5190 - val_accuracy: 0.3056\n",
      "Epoch 42/200\n",
      "1176/1176 [==============================] - 0s 207us/step - loss: 1.8429 - accuracy: 0.3767 - val_loss: 13.5493 - val_accuracy: 0.3056\n",
      "Epoch 43/200\n",
      "1176/1176 [==============================] - 0s 208us/step - loss: 1.8439 - accuracy: 0.3759 - val_loss: 13.5525 - val_accuracy: 0.3056\n",
      "Epoch 44/200\n",
      "1176/1176 [==============================] - 0s 205us/step - loss: 1.8455 - accuracy: 0.3759 - val_loss: 13.5159 - val_accuracy: 0.3056\n",
      "Epoch 45/200\n",
      "1176/1176 [==============================] - 0s 206us/step - loss: 1.8456 - accuracy: 0.3759 - val_loss: 13.6400 - val_accuracy: 0.3056\n",
      "Epoch 46/200\n",
      "1176/1176 [==============================] - 0s 212us/step - loss: 1.8458 - accuracy: 0.3759 - val_loss: 13.6940 - val_accuracy: 0.3056\n",
      "Epoch 47/200\n",
      "1176/1176 [==============================] - 0s 205us/step - loss: 1.8468 - accuracy: 0.3759 - val_loss: 13.7311 - val_accuracy: 0.3056\n",
      "Epoch 48/200\n",
      "1176/1176 [==============================] - 0s 210us/step - loss: 1.8443 - accuracy: 0.3759 - val_loss: 13.7255 - val_accuracy: 0.3056\n",
      "Epoch 49/200\n",
      "1176/1176 [==============================] - 0s 201us/step - loss: 1.8463 - accuracy: 0.3759 - val_loss: 13.6926 - val_accuracy: 0.3056\n",
      "Epoch 50/200\n",
      "1176/1176 [==============================] - 0s 204us/step - loss: 1.8434 - accuracy: 0.3767 - val_loss: 13.7621 - val_accuracy: 0.3056\n",
      "Epoch 51/200\n",
      "1176/1176 [==============================] - 0s 205us/step - loss: 1.8448 - accuracy: 0.3767 - val_loss: 13.7794 - val_accuracy: 0.3056\n",
      "Epoch 52/200\n",
      "1176/1176 [==============================] - 0s 214us/step - loss: 1.8429 - accuracy: 0.3767 - val_loss: 13.8207 - val_accuracy: 0.3056\n",
      "Epoch 53/200\n",
      "1176/1176 [==============================] - 0s 206us/step - loss: 1.8456 - accuracy: 0.3759 - val_loss: 13.8487 - val_accuracy: 0.3056\n",
      "Epoch 54/200\n",
      "1176/1176 [==============================] - 0s 206us/step - loss: 1.8429 - accuracy: 0.3767 - val_loss: 13.8184 - val_accuracy: 0.3056\n",
      "Epoch 55/200\n",
      "1176/1176 [==============================] - 0s 206us/step - loss: 1.8428 - accuracy: 0.3759 - val_loss: 13.7787 - val_accuracy: 0.3056\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/200\n",
      "1176/1176 [==============================] - 0s 212us/step - loss: 1.8383 - accuracy: 0.3741 - val_loss: 13.7378 - val_accuracy: 0.3056\n",
      "Epoch 57/200\n",
      "1176/1176 [==============================] - 0s 203us/step - loss: 1.8397 - accuracy: 0.3759 - val_loss: 13.7514 - val_accuracy: 0.3056\n",
      "Epoch 58/200\n",
      "1176/1176 [==============================] - 0s 199us/step - loss: 1.8407 - accuracy: 0.3759 - val_loss: 13.8221 - val_accuracy: 0.3056\n",
      "Epoch 59/200\n",
      "1176/1176 [==============================] - 0s 202us/step - loss: 1.8408 - accuracy: 0.3759 - val_loss: 13.8270 - val_accuracy: 0.3056\n",
      "Epoch 60/200\n",
      "1176/1176 [==============================] - 0s 206us/step - loss: 1.8393 - accuracy: 0.3759 - val_loss: 13.8736 - val_accuracy: 0.3056\n",
      "Epoch 61/200\n",
      "1176/1176 [==============================] - 0s 207us/step - loss: 1.8407 - accuracy: 0.3750 - val_loss: 13.7698 - val_accuracy: 0.3056\n",
      "Epoch 62/200\n",
      "1176/1176 [==============================] - 0s 204us/step - loss: 1.8393 - accuracy: 0.3759 - val_loss: 13.8126 - val_accuracy: 0.3056\n",
      "Epoch 63/200\n",
      "1176/1176 [==============================] - 0s 203us/step - loss: 1.8378 - accuracy: 0.3759 - val_loss: 13.7965 - val_accuracy: 0.3056\n",
      "Epoch 64/200\n",
      "1176/1176 [==============================] - 0s 207us/step - loss: 1.8366 - accuracy: 0.3759 - val_loss: 13.7678 - val_accuracy: 0.3056\n",
      "Epoch 65/200\n",
      "1176/1176 [==============================] - 0s 200us/step - loss: 1.8361 - accuracy: 0.3767 - val_loss: 13.8543 - val_accuracy: 0.3056\n",
      "Epoch 66/200\n",
      "1176/1176 [==============================] - 0s 202us/step - loss: 1.8371 - accuracy: 0.3759 - val_loss: 13.8278 - val_accuracy: 0.3056\n",
      "Epoch 67/200\n",
      "1176/1176 [==============================] - 0s 206us/step - loss: 1.8362 - accuracy: 0.3767 - val_loss: 13.8867 - val_accuracy: 0.3056\n",
      "Epoch 68/200\n",
      "1176/1176 [==============================] - 0s 212us/step - loss: 1.8383 - accuracy: 0.3767 - val_loss: 13.8828 - val_accuracy: 0.3056\n",
      "Epoch 69/200\n",
      "1176/1176 [==============================] - 0s 204us/step - loss: 1.8394 - accuracy: 0.3767 - val_loss: 13.8984 - val_accuracy: 0.3056\n",
      "Epoch 70/200\n",
      "1176/1176 [==============================] - 0s 212us/step - loss: 1.8384 - accuracy: 0.3767 - val_loss: 13.9381 - val_accuracy: 0.3056\n",
      "Epoch 71/200\n",
      "1176/1176 [==============================] - 0s 203us/step - loss: 1.8388 - accuracy: 0.3759 - val_loss: 13.9540 - val_accuracy: 0.3056\n",
      "Epoch 72/200\n",
      "1176/1176 [==============================] - 0s 207us/step - loss: 1.8381 - accuracy: 0.3759 - val_loss: 13.9792 - val_accuracy: 0.3056\n",
      "Epoch 73/200\n",
      "1176/1176 [==============================] - 0s 205us/step - loss: 1.8371 - accuracy: 0.3767 - val_loss: 14.0118 - val_accuracy: 0.3056\n",
      "Epoch 74/200\n",
      "1176/1176 [==============================] - 0s 212us/step - loss: 1.8376 - accuracy: 0.3767 - val_loss: 14.0492 - val_accuracy: 0.3056\n",
      "Epoch 75/200\n",
      "1176/1176 [==============================] - 0s 207us/step - loss: 1.8359 - accuracy: 0.3767 - val_loss: 14.0439 - val_accuracy: 0.3056\n",
      "Epoch 76/200\n",
      "1176/1176 [==============================] - 0s 208us/step - loss: 1.8387 - accuracy: 0.3776 - val_loss: 14.0864 - val_accuracy: 0.3056\n",
      "Epoch 77/200\n",
      "1176/1176 [==============================] - 0s 201us/step - loss: 1.8382 - accuracy: 0.3759 - val_loss: 14.1216 - val_accuracy: 0.3056\n",
      "Epoch 78/200\n",
      "1176/1176 [==============================] - 0s 203us/step - loss: 1.8377 - accuracy: 0.3767 - val_loss: 14.1624 - val_accuracy: 0.3056\n",
      "Epoch 79/200\n",
      "1176/1176 [==============================] - 0s 203us/step - loss: 1.8395 - accuracy: 0.3767 - val_loss: 14.2318 - val_accuracy: 0.3056\n",
      "Epoch 80/200\n",
      "1176/1176 [==============================] - 0s 204us/step - loss: 1.8405 - accuracy: 0.3767 - val_loss: 14.2300 - val_accuracy: 0.3056\n",
      "Epoch 81/200\n",
      "1176/1176 [==============================] - 0s 208us/step - loss: 1.8405 - accuracy: 0.3759 - val_loss: 14.2739 - val_accuracy: 0.3056\n",
      "Epoch 82/200\n",
      "1176/1176 [==============================] - 0s 222us/step - loss: 1.8392 - accuracy: 0.3759 - val_loss: 14.2768 - val_accuracy: 0.3056\n",
      "Epoch 83/200\n",
      "1176/1176 [==============================] - 0s 226us/step - loss: 1.8396 - accuracy: 0.3767 - val_loss: 14.2931 - val_accuracy: 0.3056\n",
      "Epoch 84/200\n",
      "1176/1176 [==============================] - 0s 243us/step - loss: 1.8420 - accuracy: 0.3767 - val_loss: 14.2989 - val_accuracy: 0.3056\n",
      "Epoch 85/200\n",
      "1176/1176 [==============================] - 0s 232us/step - loss: 1.8383 - accuracy: 0.3767 - val_loss: 14.2991 - val_accuracy: 0.3056\n",
      "Epoch 86/200\n",
      "1176/1176 [==============================] - 0s 229us/step - loss: 1.8409 - accuracy: 0.3767 - val_loss: 14.3341 - val_accuracy: 0.3056\n",
      "Epoch 87/200\n",
      "1176/1176 [==============================] - 0s 225us/step - loss: 1.8388 - accuracy: 0.3759 - val_loss: 14.3753 - val_accuracy: 0.3056\n",
      "Epoch 88/200\n",
      "1176/1176 [==============================] - 0s 230us/step - loss: 1.8390 - accuracy: 0.3776 - val_loss: 14.3208 - val_accuracy: 0.3056\n",
      "Epoch 89/200\n",
      "1176/1176 [==============================] - 0s 212us/step - loss: 1.8374 - accuracy: 0.3759 - val_loss: 14.3014 - val_accuracy: 0.3056\n",
      "Epoch 90/200\n",
      "1176/1176 [==============================] - 0s 209us/step - loss: 1.8376 - accuracy: 0.3776 - val_loss: 14.3636 - val_accuracy: 0.3056\n",
      "Epoch 91/200\n",
      "1176/1176 [==============================] - 0s 207us/step - loss: 1.8380 - accuracy: 0.3767 - val_loss: 14.3334 - val_accuracy: 0.3056\n",
      "Epoch 92/200\n",
      "1176/1176 [==============================] - 0s 212us/step - loss: 1.8383 - accuracy: 0.3776 - val_loss: 14.3800 - val_accuracy: 0.3056\n",
      "Epoch 93/200\n",
      "1176/1176 [==============================] - 0s 211us/step - loss: 1.8381 - accuracy: 0.3767 - val_loss: 14.3716 - val_accuracy: 0.3056\n",
      "Epoch 94/200\n",
      "1176/1176 [==============================] - 0s 208us/step - loss: 1.8379 - accuracy: 0.3776 - val_loss: 14.3948 - val_accuracy: 0.3056\n",
      "Epoch 95/200\n",
      "1176/1176 [==============================] - 0s 207us/step - loss: 1.8382 - accuracy: 0.3767 - val_loss: 14.3925 - val_accuracy: 0.3056\n",
      "Epoch 96/200\n",
      "1176/1176 [==============================] - 0s 211us/step - loss: 1.8370 - accuracy: 0.3776 - val_loss: 14.4533 - val_accuracy: 0.3056\n",
      "Epoch 97/200\n",
      "1176/1176 [==============================] - 0s 210us/step - loss: 1.8376 - accuracy: 0.3767 - val_loss: 14.4863 - val_accuracy: 0.3056\n",
      "Epoch 98/200\n",
      "1176/1176 [==============================] - 0s 212us/step - loss: 1.8385 - accuracy: 0.3776 - val_loss: 14.5457 - val_accuracy: 0.3056\n",
      "Epoch 99/200\n",
      "1176/1176 [==============================] - 0s 210us/step - loss: 1.8384 - accuracy: 0.3776 - val_loss: 14.5906 - val_accuracy: 0.3075\n",
      "Epoch 100/200\n",
      "1176/1176 [==============================] - 0s 216us/step - loss: 1.8379 - accuracy: 0.3767 - val_loss: 14.5780 - val_accuracy: 0.3075\n",
      "Epoch 101/200\n",
      "1176/1176 [==============================] - 0s 206us/step - loss: 1.8401 - accuracy: 0.3776 - val_loss: 14.5361 - val_accuracy: 0.3056\n",
      "Epoch 102/200\n",
      "1176/1176 [==============================] - 0s 208us/step - loss: 1.8387 - accuracy: 0.3767 - val_loss: 14.6041 - val_accuracy: 0.3075\n",
      "Epoch 103/200\n",
      "1176/1176 [==============================] - 0s 207us/step - loss: 1.8380 - accuracy: 0.3776 - val_loss: 14.6036 - val_accuracy: 0.3056\n",
      "Epoch 104/200\n",
      "1176/1176 [==============================] - 0s 209us/step - loss: 1.8398 - accuracy: 0.3767 - val_loss: 14.6106 - val_accuracy: 0.3075\n",
      "Epoch 105/200\n",
      "1176/1176 [==============================] - 0s 205us/step - loss: 1.8379 - accuracy: 0.3767 - val_loss: 14.5851 - val_accuracy: 0.3056\n",
      "Epoch 106/200\n",
      "1176/1176 [==============================] - 0s 209us/step - loss: 1.8379 - accuracy: 0.3767 - val_loss: 14.5557 - val_accuracy: 0.3036\n",
      "Epoch 107/200\n",
      "1176/1176 [==============================] - 0s 209us/step - loss: 1.8361 - accuracy: 0.3776 - val_loss: 14.5789 - val_accuracy: 0.3036\n",
      "Epoch 108/200\n",
      "1176/1176 [==============================] - 0s 218us/step - loss: 1.8388 - accuracy: 0.3776 - val_loss: 14.5489 - val_accuracy: 0.3036\n",
      "Epoch 109/200\n",
      "1176/1176 [==============================] - 0s 209us/step - loss: 1.8366 - accuracy: 0.3767 - val_loss: 14.6079 - val_accuracy: 0.3036\n",
      "Epoch 110/200\n",
      "1176/1176 [==============================] - 0s 210us/step - loss: 1.8379 - accuracy: 0.3776 - val_loss: 14.5956 - val_accuracy: 0.3036\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 111/200\n",
      "1176/1176 [==============================] - 0s 207us/step - loss: 1.8374 - accuracy: 0.3776 - val_loss: 14.6025 - val_accuracy: 0.3036\n",
      "Epoch 112/200\n",
      "1176/1176 [==============================] - 0s 210us/step - loss: 1.8411 - accuracy: 0.3776 - val_loss: 14.6508 - val_accuracy: 0.3036\n",
      "Epoch 113/200\n",
      "1176/1176 [==============================] - 0s 206us/step - loss: 1.8369 - accuracy: 0.3767 - val_loss: 14.7072 - val_accuracy: 0.3036\n",
      "Epoch 114/200\n",
      "1176/1176 [==============================] - 0s 210us/step - loss: 1.8389 - accuracy: 0.3776 - val_loss: 14.7536 - val_accuracy: 0.3036\n",
      "Epoch 115/200\n",
      "1176/1176 [==============================] - 0s 211us/step - loss: 1.8385 - accuracy: 0.3767 - val_loss: 14.6783 - val_accuracy: 0.3036\n",
      "Epoch 116/200\n",
      "1176/1176 [==============================] - 0s 212us/step - loss: 1.8388 - accuracy: 0.3776 - val_loss: 14.7858 - val_accuracy: 0.3056\n",
      "Epoch 117/200\n",
      "1176/1176 [==============================] - 0s 208us/step - loss: 1.8381 - accuracy: 0.3776 - val_loss: 14.8104 - val_accuracy: 0.3056\n",
      "Epoch 118/200\n",
      "1176/1176 [==============================] - 0s 210us/step - loss: 1.8390 - accuracy: 0.3784 - val_loss: 14.8020 - val_accuracy: 0.3036\n",
      "Epoch 119/200\n",
      "1176/1176 [==============================] - 0s 209us/step - loss: 1.8377 - accuracy: 0.3776 - val_loss: 14.8554 - val_accuracy: 0.3056\n",
      "Epoch 120/200\n",
      "1176/1176 [==============================] - 0s 210us/step - loss: 1.8378 - accuracy: 0.3767 - val_loss: 14.8377 - val_accuracy: 0.3056\n",
      "Epoch 121/200\n",
      "1176/1176 [==============================] - 0s 210us/step - loss: 1.8385 - accuracy: 0.3776 - val_loss: 14.8742 - val_accuracy: 0.3056\n",
      "Epoch 122/200\n",
      "1176/1176 [==============================] - 0s 209us/step - loss: 1.8421 - accuracy: 0.3767 - val_loss: 14.8211 - val_accuracy: 0.3036\n",
      "Epoch 123/200\n",
      "1176/1176 [==============================] - 0s 211us/step - loss: 1.8358 - accuracy: 0.3776 - val_loss: 14.8419 - val_accuracy: 0.3036\n",
      "Epoch 124/200\n",
      "1176/1176 [==============================] - 0s 212us/step - loss: 1.8380 - accuracy: 0.3767 - val_loss: 14.8331 - val_accuracy: 0.3036\n",
      "Epoch 125/200\n",
      "1176/1176 [==============================] - 0s 208us/step - loss: 1.8375 - accuracy: 0.3776 - val_loss: 14.8456 - val_accuracy: 0.3036\n",
      "Epoch 126/200\n",
      "1176/1176 [==============================] - 0s 209us/step - loss: 1.8391 - accuracy: 0.3776 - val_loss: 14.8985 - val_accuracy: 0.3056\n",
      "Epoch 127/200\n",
      "1176/1176 [==============================] - 0s 208us/step - loss: 1.8373 - accuracy: 0.3767 - val_loss: 14.8813 - val_accuracy: 0.3036\n",
      "Epoch 128/200\n",
      "1176/1176 [==============================] - 0s 213us/step - loss: 1.8375 - accuracy: 0.3784 - val_loss: 14.9462 - val_accuracy: 0.3056\n",
      "Epoch 129/200\n",
      "1176/1176 [==============================] - 0s 207us/step - loss: 1.8390 - accuracy: 0.3793 - val_loss: 14.8661 - val_accuracy: 0.3036\n",
      "Epoch 130/200\n",
      "1176/1176 [==============================] - 0s 211us/step - loss: 1.8376 - accuracy: 0.3776 - val_loss: 14.8306 - val_accuracy: 0.3036\n",
      "Epoch 131/200\n",
      "1176/1176 [==============================] - 0s 210us/step - loss: 1.8371 - accuracy: 0.3776 - val_loss: 14.8146 - val_accuracy: 0.3036\n",
      "Epoch 132/200\n",
      "1176/1176 [==============================] - 0s 210us/step - loss: 1.8382 - accuracy: 0.3784 - val_loss: 14.8221 - val_accuracy: 0.3036\n",
      "Epoch 133/200\n",
      "1176/1176 [==============================] - 0s 206us/step - loss: 1.8377 - accuracy: 0.3767 - val_loss: 14.8665 - val_accuracy: 0.3036\n",
      "Epoch 134/200\n",
      "1176/1176 [==============================] - 0s 207us/step - loss: 1.8374 - accuracy: 0.3776 - val_loss: 14.9162 - val_accuracy: 0.3056\n",
      "Epoch 135/200\n",
      "1176/1176 [==============================] - 0s 203us/step - loss: 1.8375 - accuracy: 0.3784 - val_loss: 14.8834 - val_accuracy: 0.3036\n",
      "Epoch 136/200\n",
      "1176/1176 [==============================] - 0s 217us/step - loss: 1.8393 - accuracy: 0.3801 - val_loss: 14.9035 - val_accuracy: 0.3036\n",
      "Epoch 137/200\n",
      "1176/1176 [==============================] - 0s 209us/step - loss: 1.8398 - accuracy: 0.3784 - val_loss: 14.9508 - val_accuracy: 0.3056\n",
      "Epoch 138/200\n",
      "1176/1176 [==============================] - 0s 208us/step - loss: 1.8406 - accuracy: 0.3801 - val_loss: 14.8913 - val_accuracy: 0.3056\n",
      "Epoch 139/200\n",
      "1176/1176 [==============================] - 0s 208us/step - loss: 1.8381 - accuracy: 0.3784 - val_loss: 14.8439 - val_accuracy: 0.3036\n",
      "Epoch 140/200\n",
      "1176/1176 [==============================] - 0s 248us/step - loss: 1.8388 - accuracy: 0.3776 - val_loss: 14.8039 - val_accuracy: 0.3036\n",
      "Epoch 141/200\n",
      "1176/1176 [==============================] - 0s 204us/step - loss: 1.8385 - accuracy: 0.3776 - val_loss: 14.7927 - val_accuracy: 0.3036\n",
      "Epoch 142/200\n",
      "1176/1176 [==============================] - 0s 212us/step - loss: 1.8382 - accuracy: 0.3776 - val_loss: 14.8334 - val_accuracy: 0.3036\n",
      "Epoch 143/200\n",
      "1176/1176 [==============================] - 0s 210us/step - loss: 1.8367 - accuracy: 0.3776 - val_loss: 14.8296 - val_accuracy: 0.3036\n",
      "Epoch 144/200\n",
      "1176/1176 [==============================] - 0s 211us/step - loss: 1.8382 - accuracy: 0.3776 - val_loss: 14.8166 - val_accuracy: 0.3036\n",
      "Epoch 145/200\n",
      "1176/1176 [==============================] - 0s 210us/step - loss: 1.8366 - accuracy: 0.3767 - val_loss: 14.9067 - val_accuracy: 0.3036\n",
      "Epoch 146/200\n",
      "1176/1176 [==============================] - 0s 211us/step - loss: 1.8414 - accuracy: 0.3776 - val_loss: 14.8644 - val_accuracy: 0.3036\n",
      "Epoch 147/200\n",
      "1176/1176 [==============================] - 0s 212us/step - loss: 1.8379 - accuracy: 0.3776 - val_loss: 14.8464 - val_accuracy: 0.3036\n",
      "Epoch 148/200\n",
      "1176/1176 [==============================] - 0s 251us/step - loss: 1.8382 - accuracy: 0.3784 - val_loss: 14.8840 - val_accuracy: 0.3036\n",
      "Epoch 149/200\n",
      "1176/1176 [==============================] - 0s 222us/step - loss: 1.8380 - accuracy: 0.3784 - val_loss: 14.8545 - val_accuracy: 0.3036\n",
      "Epoch 150/200\n",
      "1176/1176 [==============================] - 0s 225us/step - loss: 1.8395 - accuracy: 0.3793 - val_loss: 14.8607 - val_accuracy: 0.3036\n",
      "Epoch 151/200\n",
      "1176/1176 [==============================] - 0s 228us/step - loss: 1.8388 - accuracy: 0.3776 - val_loss: 14.8499 - val_accuracy: 0.3036\n",
      "Epoch 152/200\n",
      "1176/1176 [==============================] - 0s 223us/step - loss: 1.8384 - accuracy: 0.3784 - val_loss: 14.8365 - val_accuracy: 0.3036\n",
      "Epoch 153/200\n",
      "1176/1176 [==============================] - 0s 223us/step - loss: 1.8362 - accuracy: 0.3776 - val_loss: 14.8879 - val_accuracy: 0.3056\n",
      "Epoch 154/200\n",
      "1176/1176 [==============================] - 0s 222us/step - loss: 1.8395 - accuracy: 0.3793 - val_loss: 14.8892 - val_accuracy: 0.3056\n",
      "Epoch 155/200\n",
      "1176/1176 [==============================] - 0s 222us/step - loss: 1.8389 - accuracy: 0.3793 - val_loss: 14.8913 - val_accuracy: 0.3056\n",
      "Epoch 156/200\n",
      "1176/1176 [==============================] - 0s 217us/step - loss: 1.8388 - accuracy: 0.3784 - val_loss: 14.9068 - val_accuracy: 0.3056\n",
      "Epoch 157/200\n",
      "1176/1176 [==============================] - 0s 227us/step - loss: 1.8404 - accuracy: 0.3793 - val_loss: 14.8237 - val_accuracy: 0.3036\n",
      "Epoch 158/200\n",
      "1176/1176 [==============================] - 0s 223us/step - loss: 1.8373 - accuracy: 0.3784 - val_loss: 14.8583 - val_accuracy: 0.3036\n",
      "Epoch 159/200\n",
      "1176/1176 [==============================] - 0s 210us/step - loss: 1.8385 - accuracy: 0.3784 - val_loss: 14.8811 - val_accuracy: 0.3036\n",
      "Epoch 160/200\n",
      "1176/1176 [==============================] - 0s 205us/step - loss: 1.8371 - accuracy: 0.3776 - val_loss: 14.9032 - val_accuracy: 0.3036\n",
      "Epoch 161/200\n",
      "1176/1176 [==============================] - 0s 211us/step - loss: 1.8377 - accuracy: 0.3784 - val_loss: 14.8971 - val_accuracy: 0.3036\n",
      "Epoch 162/200\n",
      "1176/1176 [==============================] - 0s 206us/step - loss: 1.8382 - accuracy: 0.3784 - val_loss: 14.8541 - val_accuracy: 0.3036\n",
      "Epoch 163/200\n",
      "1176/1176 [==============================] - 0s 208us/step - loss: 1.8394 - accuracy: 0.3801 - val_loss: 14.8597 - val_accuracy: 0.3036\n",
      "Epoch 164/200\n",
      "1176/1176 [==============================] - 0s 241us/step - loss: 1.8382 - accuracy: 0.3784 - val_loss: 14.8538 - val_accuracy: 0.3036\n",
      "Epoch 165/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1176/1176 [==============================] - 0s 210us/step - loss: 1.8393 - accuracy: 0.3784 - val_loss: 14.8838 - val_accuracy: 0.3036\n",
      "Epoch 166/200\n",
      "1176/1176 [==============================] - 0s 207us/step - loss: 1.8388 - accuracy: 0.3784 - val_loss: 14.9154 - val_accuracy: 0.3056\n",
      "Epoch 167/200\n",
      "1176/1176 [==============================] - 0s 212us/step - loss: 1.8392 - accuracy: 0.3793 - val_loss: 14.8205 - val_accuracy: 0.3016\n",
      "Epoch 168/200\n",
      "1176/1176 [==============================] - 0s 209us/step - loss: 1.8377 - accuracy: 0.3776 - val_loss: 14.9040 - val_accuracy: 0.3036\n",
      "Epoch 169/200\n",
      "1176/1176 [==============================] - 0s 202us/step - loss: 1.8420 - accuracy: 0.3784 - val_loss: 14.8969 - val_accuracy: 0.3056\n",
      "Epoch 170/200\n",
      "1176/1176 [==============================] - 0s 208us/step - loss: 1.8390 - accuracy: 0.3784 - val_loss: 14.8690 - val_accuracy: 0.3036\n",
      "Epoch 171/200\n",
      "1176/1176 [==============================] - 0s 211us/step - loss: 1.8380 - accuracy: 0.3793 - val_loss: 14.9085 - val_accuracy: 0.3056\n",
      "Epoch 172/200\n",
      "1176/1176 [==============================] - 0s 229us/step - loss: 1.8378 - accuracy: 0.3784 - val_loss: 14.8808 - val_accuracy: 0.3056\n",
      "Epoch 173/200\n",
      "1176/1176 [==============================] - 0s 206us/step - loss: 1.8419 - accuracy: 0.3784 - val_loss: 14.9151 - val_accuracy: 0.3056\n",
      "Epoch 174/200\n",
      "1176/1176 [==============================] - 0s 211us/step - loss: 1.8376 - accuracy: 0.3793 - val_loss: 14.8473 - val_accuracy: 0.3036\n",
      "Epoch 175/200\n",
      "1176/1176 [==============================] - 0s 226us/step - loss: 1.8377 - accuracy: 0.3776 - val_loss: 14.8915 - val_accuracy: 0.3036\n",
      "Epoch 176/200\n",
      "1176/1176 [==============================] - 0s 206us/step - loss: 1.8393 - accuracy: 0.3784 - val_loss: 14.9025 - val_accuracy: 0.3056\n",
      "Epoch 177/200\n",
      "1176/1176 [==============================] - 0s 212us/step - loss: 1.8385 - accuracy: 0.3784 - val_loss: 14.8519 - val_accuracy: 0.3036\n",
      "Epoch 178/200\n",
      "1176/1176 [==============================] - 0s 232us/step - loss: 1.8405 - accuracy: 0.3793 - val_loss: 14.9120 - val_accuracy: 0.3056\n",
      "Epoch 179/200\n",
      "1176/1176 [==============================] - 0s 212us/step - loss: 1.8375 - accuracy: 0.3784 - val_loss: 14.8750 - val_accuracy: 0.3056\n",
      "Epoch 180/200\n",
      "1176/1176 [==============================] - 0s 205us/step - loss: 1.8396 - accuracy: 0.3793 - val_loss: 14.9108 - val_accuracy: 0.3056\n",
      "Epoch 181/200\n",
      "1176/1176 [==============================] - 0s 209us/step - loss: 1.8379 - accuracy: 0.3784 - val_loss: 14.9419 - val_accuracy: 0.3056\n",
      "Epoch 182/200\n",
      "1176/1176 [==============================] - 0s 211us/step - loss: 1.8378 - accuracy: 0.3793 - val_loss: 14.8743 - val_accuracy: 0.3056\n",
      "Epoch 183/200\n",
      "1176/1176 [==============================] - 0s 216us/step - loss: 1.8377 - accuracy: 0.3784 - val_loss: 14.8638 - val_accuracy: 0.3036\n",
      "Epoch 184/200\n",
      "1176/1176 [==============================] - 0s 202us/step - loss: 1.8376 - accuracy: 0.3793 - val_loss: 14.8456 - val_accuracy: 0.3016\n",
      "Epoch 185/200\n",
      "1176/1176 [==============================] - 0s 208us/step - loss: 1.8370 - accuracy: 0.3784 - val_loss: 14.8300 - val_accuracy: 0.3016\n",
      "Epoch 186/200\n",
      "1176/1176 [==============================] - 0s 210us/step - loss: 1.8367 - accuracy: 0.3784 - val_loss: 14.8845 - val_accuracy: 0.3036\n",
      "Epoch 187/200\n",
      "1176/1176 [==============================] - 0s 222us/step - loss: 1.8361 - accuracy: 0.3784 - val_loss: 14.8496 - val_accuracy: 0.3016\n",
      "Epoch 188/200\n",
      "1176/1176 [==============================] - 0s 265us/step - loss: 1.8359 - accuracy: 0.3784 - val_loss: 14.9252 - val_accuracy: 0.3036\n",
      "Epoch 189/200\n",
      "1176/1176 [==============================] - 0s 255us/step - loss: 1.8367 - accuracy: 0.3784 - val_loss: 14.9304 - val_accuracy: 0.3056\n",
      "Epoch 190/200\n",
      "1176/1176 [==============================] - 0s 243us/step - loss: 1.8352 - accuracy: 0.3784 - val_loss: 14.9905 - val_accuracy: 0.3056\n",
      "Epoch 191/200\n",
      "1176/1176 [==============================] - 0s 209us/step - loss: 1.8375 - accuracy: 0.3801 - val_loss: 14.9264 - val_accuracy: 0.3056\n",
      "Epoch 192/200\n",
      "1176/1176 [==============================] - 0s 208us/step - loss: 1.8358 - accuracy: 0.3793 - val_loss: 14.9562 - val_accuracy: 0.3056\n",
      "Epoch 193/200\n",
      "1176/1176 [==============================] - 0s 206us/step - loss: 1.8368 - accuracy: 0.3801 - val_loss: 15.0181 - val_accuracy: 0.3056\n",
      "Epoch 194/200\n",
      "1176/1176 [==============================] - 0s 210us/step - loss: 1.8367 - accuracy: 0.3784 - val_loss: 14.9696 - val_accuracy: 0.3056\n",
      "Epoch 195/200\n",
      "1176/1176 [==============================] - 0s 209us/step - loss: 1.8362 - accuracy: 0.3784 - val_loss: 14.9519 - val_accuracy: 0.3056\n",
      "Epoch 196/200\n",
      "1176/1176 [==============================] - 0s 220us/step - loss: 1.8376 - accuracy: 0.3793 - val_loss: 14.9076 - val_accuracy: 0.3056\n",
      "Epoch 197/200\n",
      "1176/1176 [==============================] - 0s 213us/step - loss: 1.8350 - accuracy: 0.3793 - val_loss: 14.8374 - val_accuracy: 0.3016\n",
      "Epoch 198/200\n",
      "1176/1176 [==============================] - 0s 206us/step - loss: 1.8384 - accuracy: 0.3784 - val_loss: 14.9716 - val_accuracy: 0.3056\n",
      "Epoch 199/200\n",
      "1176/1176 [==============================] - 0s 227us/step - loss: 1.8377 - accuracy: 0.3801 - val_loss: 14.8790 - val_accuracy: 0.3056\n",
      "Epoch 200/200\n",
      "1176/1176 [==============================] - 0s 230us/step - loss: 1.8366 - accuracy: 0.3793 - val_loss: 14.9729 - val_accuracy: 0.3056\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_data,\n",
    "                    train_targets,\n",
    "                    epochs=200,\n",
    "                    batch_size=4,\n",
    "                    validation_data=(test_data,test_targets)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 35347 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 32244 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 33287 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 39511 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 35657 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 30340 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 25613 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 22833 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 20989 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 25976 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 35347 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 32244 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 33287 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 39511 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 35657 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 30340 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 25613 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 22833 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 20989 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 25976 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#繪圖\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(loss)+ 1)\n",
    "plt.plot(epochs, loss,'bo',label='Training loss')\n",
    "plt.plot(epochs, val_loss,'b',label='Validation loss')\n",
    "plt.title('訓練與驗證的損失函數')\n",
    "plt.xlabel('Epohs')\n",
    "plt.xlabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()\n",
    "acc = history.history['accuracy']\n",
    "val_acc=history.history['val_accuracy']\n",
    "\n",
    "plt.plot(epochs, acc, 'bo',label='Training acc')\n",
    "plt.plot(epochs, val_acc,'b',label='Validation acc')\n",
    "plt.title('Fuck you')\n",
    "plt.xlabel('Epohs')\n",
    "plt.xlabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 測試 小綠同學"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>serveTime</th>\n",
       "      <th>Loan</th>\n",
       "      <th>SalPerY</th>\n",
       "      <th>holdCard</th>\n",
       "      <th>Career</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>120</td>\n",
       "      <td>4</td>\n",
       "      <td>600000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>600000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>87</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  age serveTime Loan SalPerY holdCard Career\n",
       "0   8       120    4  600000        1      1\n",
       "1  28        12    0  600000        0      0\n",
       "2  28        12    0      87        2      0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "小綠 = pd.DataFrame(columns=[\"age\",\"serveTime\",\"Loan\",\"SalPerY\",\"holdCard\",\"Career\"])\n",
    "小綠.loc[0]=8,120,4,600000,1,1\n",
    "小綠.loc[1]=28,12,0,600000,0,0\n",
    "小綠.loc[2]=28,12,0,87,2,0\n",
    "小綠"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>serveTime</th>\n",
       "      <th>Loan</th>\n",
       "      <th>SalPerY</th>\n",
       "      <th>holdCard</th>\n",
       "      <th>Career</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-4.23014</td>\n",
       "      <td>1.82604</td>\n",
       "      <td>4.51669</td>\n",
       "      <td>-0.089548</td>\n",
       "      <td>0.860026</td>\n",
       "      <td>-1.77042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.238194</td>\n",
       "      <td>-0.349899</td>\n",
       "      <td>-0.576944</td>\n",
       "      <td>-0.089548</td>\n",
       "      <td>-1.16276</td>\n",
       "      <td>-3.32533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.238194</td>\n",
       "      <td>-0.349899</td>\n",
       "      <td>-0.576944</td>\n",
       "      <td>-0.486312</td>\n",
       "      <td>2.88281</td>\n",
       "      <td>-3.32533</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age serveTime      Loan   SalPerY  holdCard   Career\n",
       "0  -4.23014   1.82604   4.51669 -0.089548  0.860026 -1.77042\n",
       "1  0.238194 -0.349899 -0.576944 -0.089548  -1.16276 -3.32533\n",
       "2  0.238194 -0.349899 -0.576944 -0.486312   2.88281 -3.32533"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 因為先前輸入時有先標準化,因此輸入也要標準化\n",
    "小綠-=mean\n",
    "小綠/=std\n",
    "小綠"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 他給出的是每一群的機率(相加為一)\n",
    "preds = model.predict(小綠)\n",
    "preds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0], dtype=int64),)\n"
     ]
    }
   ],
   "source": [
    "#接著我們找出裡面機率最大的值的所在位子\n",
    "print(np.where(preds[0]==np.max(preds[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.9975902e-01, 2.4104267e-04, 8.6009363e-13, 1.7380719e-21,\n",
       "       2.7840226e-18, 2.6001981e-17, 7.7214279e-20, 3.4693040e-28,\n",
       "       2.8330106e-21, 6.3681742e-32, 1.1261915e-24, 1.2584696e-29,\n",
       "       9.3763090e-28, 2.1129929e-26, 2.0012438e-26, 5.9992626e-23,\n",
       "       3.5284997e-27, 7.2059457e-22, 0.0000000e+00, 1.1678877e-22],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
