{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import word2vec\n",
    "import gensim.models\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numba import jit# 加速套件\n",
    "import glob\n",
    "import os\n",
    "import statistics as stat\n",
    "from scipy import stats\n",
    "from sklearn import feature_extraction\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd\n",
    "import xlsxwriter\n",
    "import numpy as np\n",
    "import numpy as ndarray\n",
    "from gensim.models import word2vec\n",
    "#from gensim.models import Word2vec\n",
    "from gensim import models\n",
    "import logging\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.test.utils import common_texts, get_tmpfile\n",
    "import jieba\n",
    "from gensim.test.utils import datapath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# #將所有判決合併成訓練資料\n",
    "# path = r'C:\\Users\\Big data\\Desktop\\class\\funcardproject\\data\\文章\\斷詞完\\article_news.xlsx'\n",
    "# files = glob.glob(path)\n",
    "# for file in files:\n",
    "#     with open(file,'r',encoding='utf-8')as f:\n",
    "#         rows = f.readlines()\n",
    "#         with open('死刑_無期_train_data(合併重要詞信賴區間).txt','a',encoding='utf-8')as fin:\n",
    "#             for row in rows:\n",
    "#                 fin.write(row)\n",
    "#             fin.close()\n",
    "#             f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#這邊用pycharm跑 不然會爆掉\n",
    "#將所有判決合併成訓練資料\n",
    "# datanews = pd.read_excel(r\"C:\\Users\\Big data\\Desktop\\class\\funcardproject\\data\\文章\\斷詞完\\article_news.xlsx\")\n",
    "# datanews = datanews.loc[:,[\"seg\"]]\n",
    "# #轉list\n",
    "# train_data = np.array(datanews)#np.ndarray()\n",
    "# datanews=train_data.tolist()#list\n",
    "# train_data=''\n",
    "# for datanew in datanews:\n",
    "#     train_data+=str(datanew)+'\\n'\n",
    "# # train_data.to_excel(r\"C:\\Users\\Big data\\Desktop\\class\\funcardproject\\data\\文章\\斷詞完\\article_news_合併.xlsx\", sheet_name='Sheet1', index=False, engine='xlsxwriter')        \n",
    "# # # train_data.to_excel(r\"C:\\Users\\Big data\\Desktop\\class\\funcardproject\\data\\文章\\斷詞完\\article_news_合併.xls\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 存成TXT\n",
    "# with open(r\"C:\\Users\\Big data\\Desktop\\class\\funcardproject\\data\\文章\\一整大篇.txt\",\"w\",encoding=\"utf-8\")as f:\n",
    "#     f.write(str(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-e79f502ae0f6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m15\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0msentences\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mword2vec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLineSentence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr\"C:\\Users\\Big data\\Desktop\\class\\funcardproject\\data\\文章\\一整大篇_乾淨.txt\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mword2vec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mWord2Vec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mwindow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmin_count\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m         \u001b[0mBIN\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[1;34mr'C:\\Users\\Big data\\Desktop\\class\\funcardproject\\word2vec\\(合併重要詞信賴區間)penaltysize'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'win'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'cbow'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'.bin'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_word2vec_format\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBIN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbinary\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\gensim\\models\\word2vec.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, sentences, corpus_file, size, alpha, window, min_count, max_vocab_size, sample, seed, workers, min_alpha, sg, hs, negative, ns_exponent, cbow_mean, hashfxn, iter, null_word, trim_rule, sorted_vocab, batch_words, compute_loss, callbacks, max_final_vocab)\u001b[0m\n\u001b[0;32m    781\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_words\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_words\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrim_rule\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrim_rule\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msg\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwindow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mwindow\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m             \u001b[0mseed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnegative\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnegative\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcbow_mean\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcbow_mean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_alpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmin_alpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompute_loss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 783\u001b[1;33m             fast_version=FAST_VERSION)\n\u001b[0m\u001b[0;32m    784\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    785\u001b[0m     def _do_train_epoch(self, corpus_file, thread_id, offset, cython_vocab, thread_private_mem, cur_epoch,\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\gensim\\models\\base_any2vec.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, sentences, corpus_file, workers, vector_size, epochs, callbacks, batch_words, trim_rule, sg, alpha, window, seed, hs, negative, ns_exponent, cbow_mean, min_alpha, compute_loss, fast_version, **kwargs)\u001b[0m\n\u001b[0;32m    761\u001b[0m                 \u001b[0msentences\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msentences\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcorpus_file\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcorpus_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal_examples\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcorpus_count\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    762\u001b[0m                 \u001b[0mtotal_words\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcorpus_total_words\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstart_alpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 763\u001b[1;33m                 end_alpha=self.min_alpha, compute_loss=compute_loss)\n\u001b[0m\u001b[0;32m    764\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    765\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtrim_rule\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\gensim\\models\\word2vec.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, sentences, corpus_file, total_examples, total_words, epochs, start_alpha, end_alpha, word_count, queue_factor, report_delay, compute_loss, callbacks)\u001b[0m\n\u001b[0;32m    908\u001b[0m             \u001b[0msentences\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msentences\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcorpus_file\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcorpus_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal_examples\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtotal_examples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal_words\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtotal_words\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    909\u001b[0m             \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstart_alpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstart_alpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend_alpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mend_alpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword_count\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mword_count\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 910\u001b[1;33m             queue_factor=queue_factor, report_delay=report_delay, compute_loss=compute_loss, callbacks=callbacks)\n\u001b[0m\u001b[0;32m    911\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    912\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msentences\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal_sentences\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1e6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mqueue_factor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreport_delay\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\gensim\\models\\base_any2vec.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, sentences, corpus_file, total_examples, total_words, epochs, start_alpha, end_alpha, word_count, queue_factor, report_delay, compute_loss, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m   1079\u001b[0m             \u001b[0mtotal_words\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtotal_words\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstart_alpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstart_alpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend_alpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mend_alpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword_count\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mword_count\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1080\u001b[0m             \u001b[0mqueue_factor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mqueue_factor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreport_delay\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreport_delay\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompute_loss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1081\u001b[1;33m             **kwargs)\n\u001b[0m\u001b[0;32m   1082\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1083\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_job_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcur_epoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\gensim\\models\\base_any2vec.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, data_iterable, corpus_file, epochs, total_examples, total_words, queue_factor, report_delay, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    551\u001b[0m                 trained_word_count_epoch, raw_word_count_epoch, job_tally_epoch = self._train_epoch(\n\u001b[0;32m    552\u001b[0m                     \u001b[0mdata_iterable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcur_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcur_epoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal_examples\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtotal_examples\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 553\u001b[1;33m                     total_words=total_words, queue_factor=queue_factor, report_delay=report_delay)\n\u001b[0m\u001b[0;32m    554\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    555\u001b[0m                 trained_word_count_epoch, raw_word_count_epoch, job_tally_epoch = self._train_epoch_corpusfile(\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\gensim\\models\\base_any2vec.py\u001b[0m in \u001b[0;36m_train_epoch\u001b[1;34m(self, data_iterable, cur_epoch, total_examples, total_words, queue_factor, report_delay)\u001b[0m\n\u001b[0;32m    487\u001b[0m         trained_word_count, raw_word_count, job_tally = self._log_epoch_progress(\n\u001b[0;32m    488\u001b[0m             \u001b[0mprogress_queue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjob_queue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcur_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcur_epoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal_examples\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtotal_examples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal_words\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtotal_words\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 489\u001b[1;33m             report_delay=report_delay, is_corpus_file_mode=False)\n\u001b[0m\u001b[0;32m    490\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtrained_word_count\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraw_word_count\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjob_tally\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\gensim\\models\\base_any2vec.py\u001b[0m in \u001b[0;36m_log_epoch_progress\u001b[1;34m(self, progress_queue, job_queue, cur_epoch, total_examples, total_words, report_delay, is_corpus_file_mode)\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    345\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[0munfinished_worker_count\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 346\u001b[1;33m             \u001b[0mreport\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprogress_queue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# blocks if workers too slow\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    347\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mreport\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# a thread reporting that it finished\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    348\u001b[0m                 \u001b[0munfinished_worker_count\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\queue.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m    168\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    169\u001b[0m                 \u001b[1;32mwhile\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_qsize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 170\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    171\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"'timeout' must be a non-negative number\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    294\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 296\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#訓練語意空間\n",
    "size = [25,50,75,100,125,150]\n",
    "cbow = [0,1]\n",
    "for x in size:\n",
    "    for z in cbow:\n",
    "        y = 15\n",
    "        sentences = word2vec.LineSentence(r\"C:\\Users\\Big data\\Desktop\\class\\funcardproject\\data\\文章\\一整大篇_乾淨.txt\")\n",
    "        model = word2vec.Word2Vec(sentences,size=x,window=y,min_count=2,sg = z)\n",
    "        BIN =  r'C:\\Users\\Big data\\Desktop\\class\\funcardproject\\word2vec\\(合併重要詞信賴區間)penaltysize'+str(x)+'win'+str(y)+'cbow'+str(z)+'.bin'\n",
    "        model.wv.save_word2vec_format(BIN, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-13 21:38:15,342 : INFO : collecting all words and their counts\n",
      "2019-12-13 21:38:15,344 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2019-12-13 21:38:16,019 : INFO : collected 129329 word types from a corpus of 1957985 raw words and 5594 sentences\n",
      "2019-12-13 21:38:16,020 : INFO : Loading a fresh vocabulary\n",
      "2019-12-13 21:38:16,134 : INFO : effective_min_count=3 retains 38017 unique words (29% of original 129329, drops 91312)\n",
      "2019-12-13 21:38:16,135 : INFO : effective_min_count=3 leaves 1848466 word corpus (94% of original 1957985, drops 109519)\n",
      "2019-12-13 21:38:16,260 : INFO : deleting the raw counts dictionary of 129329 items\n",
      "2019-12-13 21:38:16,268 : INFO : sample=0.001 downsamples 34 most-common words\n",
      "2019-12-13 21:38:16,269 : INFO : downsampling leaves estimated 1722374 word corpus (93.2% of prior 1848466)\n",
      "2019-12-13 21:38:16,402 : INFO : estimated required memory for 38017 words and 100 dimensions: 49422100 bytes\n",
      "2019-12-13 21:38:16,404 : INFO : resetting layer weights\n",
      "2019-12-13 21:38:16,821 : INFO : training model with 3 workers on 38017 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=20\n",
      "2019-12-13 21:38:17,999 : INFO : EPOCH 1 - PROGRESS: at 4.42% examples, 75598 words/s, in_qsize 5, out_qsize 0\n",
      "2019-12-13 21:38:19,166 : INFO : EPOCH 1 - PROGRESS: at 9.64% examples, 81714 words/s, in_qsize 6, out_qsize 0\n",
      "2019-12-13 21:38:20,345 : INFO : EPOCH 1 - PROGRESS: at 14.98% examples, 83191 words/s, in_qsize 5, out_qsize 0\n",
      "2019-12-13 21:38:21,487 : INFO : EPOCH 1 - PROGRESS: at 20.13% examples, 84512 words/s, in_qsize 5, out_qsize 0\n",
      "2019-12-13 21:38:22,713 : INFO : EPOCH 1 - PROGRESS: at 25.71% examples, 84552 words/s, in_qsize 5, out_qsize 0\n",
      "2019-12-13 21:38:23,826 : INFO : EPOCH 1 - PROGRESS: at 31.66% examples, 85812 words/s, in_qsize 5, out_qsize 0\n",
      "2019-12-13 21:38:25,010 : INFO : EPOCH 1 - PROGRESS: at 37.27% examples, 85895 words/s, in_qsize 5, out_qsize 0\n",
      "2019-12-13 21:38:26,161 : INFO : EPOCH 1 - PROGRESS: at 43.22% examples, 86153 words/s, in_qsize 5, out_qsize 0\n",
      "2019-12-13 21:38:27,332 : INFO : EPOCH 1 - PROGRESS: at 49.11% examples, 86286 words/s, in_qsize 6, out_qsize 0\n",
      "2019-12-13 21:38:28,484 : INFO : EPOCH 1 - PROGRESS: at 55.29% examples, 86556 words/s, in_qsize 5, out_qsize 0\n",
      "2019-12-13 21:38:29,580 : INFO : EPOCH 1 - PROGRESS: at 61.46% examples, 87085 words/s, in_qsize 5, out_qsize 0\n",
      "2019-12-13 21:38:30,708 : INFO : EPOCH 1 - PROGRESS: at 68.13% examples, 87353 words/s, in_qsize 6, out_qsize 0\n",
      "2019-12-13 21:38:31,819 : INFO : EPOCH 1 - PROGRESS: at 75.88% examples, 87731 words/s, in_qsize 5, out_qsize 0\n",
      "2019-12-13 21:38:32,931 : INFO : EPOCH 1 - PROGRESS: at 84.66% examples, 88029 words/s, in_qsize 5, out_qsize 0\n",
      "2019-12-13 21:38:34,069 : INFO : EPOCH 1 - PROGRESS: at 91.10% examples, 88305 words/s, in_qsize 6, out_qsize 0\n",
      "2019-12-13 21:38:35,110 : INFO : EPOCH 1 - PROGRESS: at 94.82% examples, 88168 words/s, in_qsize 5, out_qsize 0\n",
      "2019-12-13 21:38:36,091 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-12-13 21:38:36,172 : INFO : EPOCH 1 - PROGRESS: at 99.46% examples, 88567 words/s, in_qsize 1, out_qsize 1\n",
      "2019-12-13 21:38:36,173 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-12-13 21:38:36,261 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-12-13 21:38:36,263 : INFO : EPOCH - 1 : training on 1957985 raw words (1722459 effective words) took 19.4s, 88610 effective words/s\n",
      "2019-12-13 21:38:37,444 : INFO : EPOCH 2 - PROGRESS: at 4.40% examples, 75143 words/s, in_qsize 5, out_qsize 1\n",
      "2019-12-13 21:38:38,589 : INFO : EPOCH 2 - PROGRESS: at 9.64% examples, 82341 words/s, in_qsize 6, out_qsize 0\n",
      "2019-12-13 21:38:39,734 : INFO : EPOCH 2 - PROGRESS: at 14.98% examples, 84483 words/s, in_qsize 6, out_qsize 0\n",
      "2019-12-13 21:38:40,817 : INFO : EPOCH 2 - PROGRESS: at 20.13% examples, 86597 words/s, in_qsize 5, out_qsize 0\n",
      "2019-12-13 21:38:41,957 : INFO : EPOCH 2 - PROGRESS: at 25.71% examples, 87464 words/s, in_qsize 5, out_qsize 0\n",
      "2019-12-13 21:38:43,137 : INFO : EPOCH 2 - PROGRESS: at 31.66% examples, 87414 words/s, in_qsize 5, out_qsize 0\n",
      "2019-12-13 21:38:44,322 : INFO : EPOCH 2 - PROGRESS: at 37.27% examples, 87263 words/s, in_qsize 5, out_qsize 0\n",
      "2019-12-13 21:38:45,505 : INFO : EPOCH 2 - PROGRESS: at 43.22% examples, 87047 words/s, in_qsize 6, out_qsize 0\n",
      "2019-12-13 21:38:46,584 : INFO : EPOCH 2 - PROGRESS: at 49.11% examples, 87889 words/s, in_qsize 5, out_qsize 0\n",
      "2019-12-13 21:38:47,606 : INFO : EPOCH 2 - PROGRESS: at 54.79% examples, 88282 words/s, in_qsize 5, out_qsize 0\n",
      "2019-12-13 21:38:48,642 : INFO : EPOCH 2 - PROGRESS: at 60.39% examples, 88451 words/s, in_qsize 6, out_qsize 0\n",
      "2019-12-13 21:38:49,696 : INFO : EPOCH 2 - PROGRESS: at 66.46% examples, 88394 words/s, in_qsize 5, out_qsize 0\n",
      "2019-12-13 21:38:50,769 : INFO : EPOCH 2 - PROGRESS: at 73.19% examples, 88338 words/s, in_qsize 5, out_qsize 0\n",
      "2019-12-13 21:38:51,788 : INFO : EPOCH 2 - PROGRESS: at 80.39% examples, 88097 words/s, in_qsize 6, out_qsize 0\n",
      "2019-12-13 21:38:52,824 : INFO : EPOCH 2 - PROGRESS: at 88.34% examples, 88205 words/s, in_qsize 5, out_qsize 0\n",
      "2019-12-13 21:38:54,019 : INFO : EPOCH 2 - PROGRESS: at 92.99% examples, 88304 words/s, in_qsize 5, out_qsize 0\n",
      "2019-12-13 21:38:55,189 : INFO : EPOCH 2 - PROGRESS: at 97.60% examples, 88511 words/s, in_qsize 6, out_qsize 0\n",
      "2019-12-13 21:38:55,482 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-12-13 21:38:55,526 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-12-13 21:38:55,573 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-12-13 21:38:55,574 : INFO : EPOCH - 2 : training on 1957985 raw words (1722689 effective words) took 19.3s, 89220 effective words/s\n",
      "2019-12-13 21:38:56,702 : INFO : EPOCH 3 - PROGRESS: at 4.40% examples, 78795 words/s, in_qsize 5, out_qsize 0\n",
      "2019-12-13 21:38:57,853 : INFO : EPOCH 3 - PROGRESS: at 9.67% examples, 84213 words/s, in_qsize 5, out_qsize 0\n",
      "2019-12-13 21:38:58,951 : INFO : EPOCH 3 - PROGRESS: at 14.98% examples, 86791 words/s, in_qsize 5, out_qsize 0\n",
      "2019-12-13 21:39:00,085 : INFO : EPOCH 3 - PROGRESS: at 20.13% examples, 87377 words/s, in_qsize 5, out_qsize 0\n",
      "2019-12-13 21:39:01,234 : INFO : EPOCH 3 - PROGRESS: at 25.71% examples, 87968 words/s, in_qsize 5, out_qsize 0\n",
      "2019-12-13 21:39:02,242 : INFO : EPOCH 3 - PROGRESS: at 31.09% examples, 88817 words/s, in_qsize 5, out_qsize 0\n",
      "2019-12-13 21:39:03,250 : INFO : EPOCH 3 - PROGRESS: at 35.86% examples, 88267 words/s, in_qsize 6, out_qsize 0\n",
      "2019-12-13 21:39:04,276 : INFO : EPOCH 3 - PROGRESS: at 41.33% examples, 88549 words/s, in_qsize 6, out_qsize 0\n",
      "2019-12-13 21:39:05,287 : INFO : EPOCH 3 - PROGRESS: at 46.73% examples, 88991 words/s, in_qsize 5, out_qsize 0\n",
      "2019-12-13 21:39:06,307 : INFO : EPOCH 3 - PROGRESS: at 51.66% examples, 88481 words/s, in_qsize 5, out_qsize 0\n",
      "2019-12-13 21:39:07,340 : INFO : EPOCH 3 - PROGRESS: at 57.24% examples, 88656 words/s, in_qsize 5, out_qsize 0\n",
      "2019-12-13 21:39:08,342 : INFO : EPOCH 3 - PROGRESS: at 62.60% examples, 88294 words/s, in_qsize 6, out_qsize 0\n",
      "2019-12-13 21:39:09,393 : INFO : EPOCH 3 - PROGRESS: at 68.66% examples, 88392 words/s, in_qsize 5, out_qsize 0\n",
      "2019-12-13 21:39:10,545 : INFO : EPOCH 3 - PROGRESS: at 76.53% examples, 88462 words/s, in_qsize 6, out_qsize 0\n",
      "2019-12-13 21:39:11,652 : INFO : EPOCH 3 - PROGRESS: at 85.32% examples, 88722 words/s, in_qsize 6, out_qsize 0\n",
      "2019-12-13 21:39:12,830 : INFO : EPOCH 3 - PROGRESS: at 91.49% examples, 88770 words/s, in_qsize 6, out_qsize 0\n",
      "2019-12-13 21:39:13,986 : INFO : EPOCH 3 - PROGRESS: at 96.03% examples, 89021 words/s, in_qsize 5, out_qsize 0\n",
      "2019-12-13 21:39:14,630 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-12-13 21:39:14,692 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-12-13 21:39:14,843 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-12-13 21:39:14,844 : INFO : EPOCH - 3 : training on 1957985 raw words (1722374 effective words) took 19.3s, 89391 effective words/s\n",
      "2019-12-13 21:39:16,003 : INFO : EPOCH 4 - PROGRESS: at 4.40% examples, 76697 words/s, in_qsize 6, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-13 21:39:17,132 : INFO : EPOCH 4 - PROGRESS: at 9.67% examples, 83900 words/s, in_qsize 6, out_qsize 0\n",
      "2019-12-13 21:39:18,257 : INFO : EPOCH 4 - PROGRESS: at 14.98% examples, 85895 words/s, in_qsize 5, out_qsize 0\n",
      "2019-12-13 21:39:19,369 : INFO : EPOCH 4 - PROGRESS: at 20.13% examples, 87146 words/s, in_qsize 5, out_qsize 0\n",
      "2019-12-13 21:39:20,453 : INFO : EPOCH 4 - PROGRESS: at 25.71% examples, 88799 words/s, in_qsize 6, out_qsize 0\n",
      "2019-12-13 21:39:21,494 : INFO : EPOCH 4 - PROGRESS: at 31.09% examples, 89082 words/s, in_qsize 6, out_qsize 0\n",
      "2019-12-13 21:39:22,494 : INFO : EPOCH 4 - PROGRESS: at 35.86% examples, 88594 words/s, in_qsize 5, out_qsize 0\n",
      "2019-12-13 21:39:23,551 : INFO : EPOCH 4 - PROGRESS: at 40.88% examples, 87579 words/s, in_qsize 5, out_qsize 0\n",
      "2019-12-13 21:39:24,584 : INFO : EPOCH 4 - PROGRESS: at 46.21% examples, 87921 words/s, in_qsize 5, out_qsize 0\n",
      "2019-12-13 21:39:25,665 : INFO : EPOCH 4 - PROGRESS: at 52.18% examples, 88555 words/s, in_qsize 5, out_qsize 0\n",
      "2019-12-13 21:39:26,684 : INFO : EPOCH 4 - PROGRESS: at 57.24% examples, 88105 words/s, in_qsize 5, out_qsize 0\n",
      "2019-12-13 21:39:27,703 : INFO : EPOCH 4 - PROGRESS: at 63.17% examples, 88333 words/s, in_qsize 5, out_qsize 0\n",
      "2019-12-13 21:39:28,890 : INFO : EPOCH 4 - PROGRESS: at 69.90% examples, 88184 words/s, in_qsize 5, out_qsize 0\n",
      "2019-12-13 21:39:30,045 : INFO : EPOCH 4 - PROGRESS: at 77.92% examples, 88259 words/s, in_qsize 6, out_qsize 0\n",
      "2019-12-13 21:39:31,154 : INFO : EPOCH 4 - PROGRESS: at 86.77% examples, 88512 words/s, in_qsize 5, out_qsize 0\n",
      "2019-12-13 21:39:32,347 : INFO : EPOCH 4 - PROGRESS: at 92.26% examples, 88560 words/s, in_qsize 5, out_qsize 0\n",
      "2019-12-13 21:39:33,487 : INFO : EPOCH 4 - PROGRESS: at 96.82% examples, 88881 words/s, in_qsize 5, out_qsize 0\n",
      "2019-12-13 21:39:33,971 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-12-13 21:39:34,052 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-12-13 21:39:34,144 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-12-13 21:39:34,145 : INFO : EPOCH - 4 : training on 1957985 raw words (1722399 effective words) took 19.3s, 89255 effective words/s\n",
      "2019-12-13 21:39:35,309 : INFO : EPOCH 5 - PROGRESS: at 4.40% examples, 76330 words/s, in_qsize 5, out_qsize 0\n",
      "2019-12-13 21:39:36,418 : INFO : EPOCH 5 - PROGRESS: at 9.67% examples, 84423 words/s, in_qsize 6, out_qsize 0\n",
      "2019-12-13 21:39:37,539 : INFO : EPOCH 5 - PROGRESS: at 14.98% examples, 86367 words/s, in_qsize 5, out_qsize 0\n",
      "2019-12-13 21:39:38,723 : INFO : EPOCH 5 - PROGRESS: at 20.13% examples, 86105 words/s, in_qsize 6, out_qsize 0\n",
      "2019-12-13 21:39:39,751 : INFO : EPOCH 5 - PROGRESS: at 25.22% examples, 87257 words/s, in_qsize 6, out_qsize 0\n",
      "2019-12-13 21:39:40,826 : INFO : EPOCH 5 - PROGRESS: at 30.55% examples, 87355 words/s, in_qsize 5, out_qsize 0\n",
      "2019-12-13 21:39:41,909 : INFO : EPOCH 5 - PROGRESS: at 35.86% examples, 87271 words/s, in_qsize 5, out_qsize 0\n",
      "2019-12-13 21:39:43,079 : INFO : EPOCH 5 - PROGRESS: at 41.76% examples, 87191 words/s, in_qsize 5, out_qsize 0\n",
      "2019-12-13 21:39:44,196 : INFO : EPOCH 5 - PROGRESS: at 47.66% examples, 87694 words/s, in_qsize 5, out_qsize 0\n",
      "2019-12-13 21:39:45,378 : INFO : EPOCH 5 - PROGRESS: at 53.70% examples, 87578 words/s, in_qsize 5, out_qsize 0\n",
      "2019-12-13 21:39:46,507 : INFO : EPOCH 5 - PROGRESS: at 59.87% examples, 87860 words/s, in_qsize 5, out_qsize 0\n",
      "2019-12-13 21:39:47,595 : INFO : EPOCH 5 - PROGRESS: at 66.46% examples, 88252 words/s, in_qsize 6, out_qsize 0\n",
      "2019-12-13 21:39:48,727 : INFO : EPOCH 5 - PROGRESS: at 73.88% examples, 88437 words/s, in_qsize 6, out_qsize 0\n",
      "2019-12-13 21:39:49,839 : INFO : EPOCH 5 - PROGRESS: at 82.52% examples, 88708 words/s, in_qsize 5, out_qsize 0\n",
      "2019-12-13 21:39:50,999 : INFO : EPOCH 5 - PROGRESS: at 90.06% examples, 88762 words/s, in_qsize 5, out_qsize 0\n",
      "2019-12-13 21:39:52,019 : INFO : EPOCH 5 - PROGRESS: at 94.15% examples, 89185 words/s, in_qsize 5, out_qsize 0\n",
      "2019-12-13 21:39:53,136 : INFO : EPOCH 5 - PROGRESS: at 98.02% examples, 88653 words/s, in_qsize 5, out_qsize 0\n",
      "2019-12-13 21:39:53,280 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-12-13 21:39:53,457 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-12-13 21:39:53,470 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-12-13 21:39:53,471 : INFO : EPOCH - 5 : training on 1957985 raw words (1722268 effective words) took 19.3s, 89127 effective words/s\n",
      "2019-12-13 21:39:53,471 : INFO : training on a 9789925 raw words (8612189 effective words) took 96.6s, 89108 effective words/s\n",
      "2019-12-13 21:39:53,572 : INFO : storing 38017x100 projection weights into C:\\Users\\Big data\\Desktop\\class\\funcardproject\\word2vec_model\\news\\測試100win20min_count3cbow1.bin\n"
     ]
    }
   ],
   "source": [
    "# 測試\n",
    "sentences = word2vec.LineSentence(r\"C:\\Users\\Big data\\Desktop\\class\\funcardproject\\data\\文章\\一整大篇_乾淨.txt\")\n",
    "model = word2vec.Word2Vec(sentences,size=100,window=20,min_count=3,sg = 1)\n",
    "BIN =  r'C:\\Users\\Big data\\Desktop\\class\\funcardproject\\word2vec_model\\news\\測試'+str(100)+'win'+str(20)+'min_count'+str(3)+'cbow'+str(1)+'.bin'\n",
    "model.wv.save_word2vec_format(BIN, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-12 16:33:29,734 : INFO : collecting all words and their counts\n",
      "2019-12-12 16:33:29,735 : WARNING : Each 'sentences' item should be a list of words (usually unicode strings). First item here is instead plain <class 'str'>.\n",
      "2019-12-12 16:33:29,736 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2019-12-12 16:33:29,736 : INFO : collected 35 word types from a corpus of 66 raw words and 66 sentences\n",
      "2019-12-12 16:33:29,737 : INFO : Loading a fresh vocabulary\n",
      "2019-12-12 16:33:29,737 : INFO : effective_min_count=0 retains 35 unique words (100% of original 35, drops 0)\n",
      "2019-12-12 16:33:29,738 : INFO : effective_min_count=0 leaves 66 word corpus (100% of original 66, drops 0)\n",
      "2019-12-12 16:33:29,739 : INFO : deleting the raw counts dictionary of 35 items\n",
      "2019-12-12 16:33:29,741 : INFO : sample=0.001 downsamples 35 most-common words\n",
      "2019-12-12 16:33:29,741 : INFO : downsampling leaves estimated 13 word corpus (20.9% of prior 66)\n",
      "2019-12-12 16:33:29,742 : INFO : estimated required memory for 35 words and 200 dimensions: 73500 bytes\n",
      "2019-12-12 16:33:29,742 : INFO : resetting layer weights\n",
      "2019-12-12 16:33:29,746 : INFO : training model with 100 workers on 35 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=5 window=100\n",
      "2019-12-12 16:33:29,795 : INFO : worker thread finished; awaiting finish of 99 more threads\n",
      "2019-12-12 16:33:29,796 : INFO : worker thread finished; awaiting finish of 98 more threads\n",
      "2019-12-12 16:33:29,796 : INFO : worker thread finished; awaiting finish of 97 more threads\n",
      "2019-12-12 16:33:29,797 : INFO : worker thread finished; awaiting finish of 96 more threads\n",
      "2019-12-12 16:33:29,797 : INFO : worker thread finished; awaiting finish of 95 more threads\n",
      "2019-12-12 16:33:29,798 : INFO : worker thread finished; awaiting finish of 94 more threads\n",
      "2019-12-12 16:33:29,798 : INFO : worker thread finished; awaiting finish of 93 more threads\n",
      "2019-12-12 16:33:29,799 : INFO : worker thread finished; awaiting finish of 92 more threads\n",
      "2019-12-12 16:33:29,799 : INFO : worker thread finished; awaiting finish of 91 more threads\n",
      "2019-12-12 16:33:29,800 : INFO : worker thread finished; awaiting finish of 90 more threads\n",
      "2019-12-12 16:33:29,801 : INFO : worker thread finished; awaiting finish of 89 more threads\n",
      "2019-12-12 16:33:29,801 : INFO : worker thread finished; awaiting finish of 88 more threads\n",
      "2019-12-12 16:33:29,802 : INFO : worker thread finished; awaiting finish of 87 more threads\n",
      "2019-12-12 16:33:29,802 : INFO : worker thread finished; awaiting finish of 86 more threads\n",
      "2019-12-12 16:33:29,803 : INFO : worker thread finished; awaiting finish of 85 more threads\n",
      "2019-12-12 16:33:29,803 : INFO : worker thread finished; awaiting finish of 84 more threads\n",
      "2019-12-12 16:33:29,804 : INFO : worker thread finished; awaiting finish of 83 more threads\n",
      "2019-12-12 16:33:29,805 : INFO : worker thread finished; awaiting finish of 82 more threads\n",
      "2019-12-12 16:33:29,805 : INFO : worker thread finished; awaiting finish of 81 more threads\n",
      "2019-12-12 16:33:29,806 : INFO : worker thread finished; awaiting finish of 80 more threads\n",
      "2019-12-12 16:33:29,807 : INFO : worker thread finished; awaiting finish of 79 more threads\n",
      "2019-12-12 16:33:29,807 : INFO : worker thread finished; awaiting finish of 78 more threads\n",
      "2019-12-12 16:33:29,808 : INFO : worker thread finished; awaiting finish of 77 more threads\n",
      "2019-12-12 16:33:29,808 : INFO : worker thread finished; awaiting finish of 76 more threads\n",
      "2019-12-12 16:33:29,809 : INFO : worker thread finished; awaiting finish of 75 more threads\n",
      "2019-12-12 16:33:29,809 : INFO : worker thread finished; awaiting finish of 74 more threads\n",
      "2019-12-12 16:33:29,810 : INFO : worker thread finished; awaiting finish of 73 more threads\n",
      "2019-12-12 16:33:29,810 : INFO : worker thread finished; awaiting finish of 72 more threads\n",
      "2019-12-12 16:33:29,811 : INFO : worker thread finished; awaiting finish of 71 more threads\n",
      "2019-12-12 16:33:29,812 : INFO : worker thread finished; awaiting finish of 70 more threads\n",
      "2019-12-12 16:33:29,812 : INFO : worker thread finished; awaiting finish of 69 more threads\n",
      "2019-12-12 16:33:29,812 : INFO : worker thread finished; awaiting finish of 68 more threads\n",
      "2019-12-12 16:33:29,815 : INFO : worker thread finished; awaiting finish of 67 more threads\n",
      "2019-12-12 16:33:29,816 : INFO : worker thread finished; awaiting finish of 66 more threads\n",
      "2019-12-12 16:33:29,816 : INFO : worker thread finished; awaiting finish of 65 more threads\n",
      "2019-12-12 16:33:29,817 : INFO : worker thread finished; awaiting finish of 64 more threads\n",
      "2019-12-12 16:33:29,818 : INFO : worker thread finished; awaiting finish of 63 more threads\n",
      "2019-12-12 16:33:29,819 : INFO : worker thread finished; awaiting finish of 62 more threads\n",
      "2019-12-12 16:33:29,819 : INFO : worker thread finished; awaiting finish of 61 more threads\n",
      "2019-12-12 16:33:29,820 : INFO : worker thread finished; awaiting finish of 60 more threads\n",
      "2019-12-12 16:33:29,820 : INFO : worker thread finished; awaiting finish of 59 more threads\n",
      "2019-12-12 16:33:29,821 : INFO : worker thread finished; awaiting finish of 58 more threads\n",
      "2019-12-12 16:33:29,821 : INFO : worker thread finished; awaiting finish of 57 more threads\n",
      "2019-12-12 16:33:29,822 : INFO : worker thread finished; awaiting finish of 56 more threads\n",
      "2019-12-12 16:33:29,823 : INFO : worker thread finished; awaiting finish of 55 more threads\n",
      "2019-12-12 16:33:29,824 : INFO : worker thread finished; awaiting finish of 54 more threads\n",
      "2019-12-12 16:33:29,824 : INFO : worker thread finished; awaiting finish of 53 more threads\n",
      "2019-12-12 16:33:29,825 : INFO : worker thread finished; awaiting finish of 52 more threads\n",
      "2019-12-12 16:33:29,826 : INFO : worker thread finished; awaiting finish of 51 more threads\n",
      "2019-12-12 16:33:29,826 : INFO : worker thread finished; awaiting finish of 50 more threads\n",
      "2019-12-12 16:33:29,827 : INFO : worker thread finished; awaiting finish of 49 more threads\n",
      "2019-12-12 16:33:29,828 : INFO : worker thread finished; awaiting finish of 48 more threads\n",
      "2019-12-12 16:33:29,828 : INFO : worker thread finished; awaiting finish of 47 more threads\n",
      "2019-12-12 16:33:29,828 : INFO : worker thread finished; awaiting finish of 46 more threads\n",
      "2019-12-12 16:33:29,829 : INFO : worker thread finished; awaiting finish of 45 more threads\n",
      "2019-12-12 16:33:29,829 : INFO : worker thread finished; awaiting finish of 44 more threads\n",
      "2019-12-12 16:33:29,830 : INFO : worker thread finished; awaiting finish of 43 more threads\n",
      "2019-12-12 16:33:29,830 : INFO : worker thread finished; awaiting finish of 42 more threads\n",
      "2019-12-12 16:33:29,831 : INFO : worker thread finished; awaiting finish of 41 more threads\n",
      "2019-12-12 16:33:29,831 : INFO : worker thread finished; awaiting finish of 40 more threads\n",
      "2019-12-12 16:33:29,832 : INFO : worker thread finished; awaiting finish of 39 more threads\n",
      "2019-12-12 16:33:29,832 : INFO : worker thread finished; awaiting finish of 38 more threads\n",
      "2019-12-12 16:33:29,833 : INFO : worker thread finished; awaiting finish of 37 more threads\n",
      "2019-12-12 16:33:29,833 : INFO : worker thread finished; awaiting finish of 36 more threads\n",
      "2019-12-12 16:33:29,834 : INFO : worker thread finished; awaiting finish of 35 more threads\n",
      "2019-12-12 16:33:29,834 : INFO : worker thread finished; awaiting finish of 34 more threads\n",
      "2019-12-12 16:33:29,835 : INFO : worker thread finished; awaiting finish of 33 more threads\n",
      "2019-12-12 16:33:29,835 : INFO : worker thread finished; awaiting finish of 32 more threads\n",
      "2019-12-12 16:33:29,836 : INFO : worker thread finished; awaiting finish of 31 more threads\n",
      "2019-12-12 16:33:29,837 : INFO : worker thread finished; awaiting finish of 30 more threads\n",
      "2019-12-12 16:33:29,837 : INFO : worker thread finished; awaiting finish of 29 more threads\n",
      "2019-12-12 16:33:29,838 : INFO : worker thread finished; awaiting finish of 28 more threads\n",
      "2019-12-12 16:33:29,838 : INFO : worker thread finished; awaiting finish of 27 more threads\n",
      "2019-12-12 16:33:29,839 : INFO : worker thread finished; awaiting finish of 26 more threads\n",
      "2019-12-12 16:33:29,840 : INFO : worker thread finished; awaiting finish of 25 more threads\n",
      "2019-12-12 16:33:29,840 : INFO : worker thread finished; awaiting finish of 24 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-12 16:33:29,841 : INFO : worker thread finished; awaiting finish of 23 more threads\n",
      "2019-12-12 16:33:29,841 : INFO : worker thread finished; awaiting finish of 22 more threads\n",
      "2019-12-12 16:33:29,842 : INFO : worker thread finished; awaiting finish of 21 more threads\n",
      "2019-12-12 16:33:29,842 : INFO : worker thread finished; awaiting finish of 20 more threads\n",
      "2019-12-12 16:33:29,843 : INFO : worker thread finished; awaiting finish of 19 more threads\n",
      "2019-12-12 16:33:29,844 : INFO : worker thread finished; awaiting finish of 18 more threads\n",
      "2019-12-12 16:33:29,844 : INFO : worker thread finished; awaiting finish of 17 more threads\n",
      "2019-12-12 16:33:29,845 : INFO : worker thread finished; awaiting finish of 16 more threads\n",
      "2019-12-12 16:33:29,845 : INFO : worker thread finished; awaiting finish of 15 more threads\n",
      "2019-12-12 16:33:29,846 : INFO : worker thread finished; awaiting finish of 14 more threads\n",
      "2019-12-12 16:33:29,846 : INFO : worker thread finished; awaiting finish of 13 more threads\n",
      "2019-12-12 16:33:29,847 : INFO : worker thread finished; awaiting finish of 12 more threads\n",
      "2019-12-12 16:33:29,847 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2019-12-12 16:33:29,848 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2019-12-12 16:33:29,848 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-12-12 16:33:29,849 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-12-12 16:33:29,849 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-12-12 16:33:29,849 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-12-12 16:33:29,850 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-12-12 16:33:29,850 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-12-12 16:33:29,851 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-12-12 16:33:29,851 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-12-12 16:33:29,852 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-12-12 16:33:29,852 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-12-12 16:33:29,853 : INFO : EPOCH - 1 : training on 66 raw words (15 effective words) took 0.1s, 238 effective words/s\n",
      "2019-12-12 16:33:29,900 : INFO : worker thread finished; awaiting finish of 99 more threads\n",
      "2019-12-12 16:33:29,901 : INFO : worker thread finished; awaiting finish of 98 more threads\n",
      "2019-12-12 16:33:29,902 : INFO : worker thread finished; awaiting finish of 97 more threads\n",
      "2019-12-12 16:33:29,902 : INFO : worker thread finished; awaiting finish of 96 more threads\n",
      "2019-12-12 16:33:29,903 : INFO : worker thread finished; awaiting finish of 95 more threads\n",
      "2019-12-12 16:33:29,903 : INFO : worker thread finished; awaiting finish of 94 more threads\n",
      "2019-12-12 16:33:29,904 : INFO : worker thread finished; awaiting finish of 93 more threads\n",
      "2019-12-12 16:33:29,904 : INFO : worker thread finished; awaiting finish of 92 more threads\n",
      "2019-12-12 16:33:29,905 : INFO : worker thread finished; awaiting finish of 91 more threads\n",
      "2019-12-12 16:33:29,905 : INFO : worker thread finished; awaiting finish of 90 more threads\n",
      "2019-12-12 16:33:29,906 : INFO : worker thread finished; awaiting finish of 89 more threads\n",
      "2019-12-12 16:33:29,907 : INFO : worker thread finished; awaiting finish of 88 more threads\n",
      "2019-12-12 16:33:29,907 : INFO : worker thread finished; awaiting finish of 87 more threads\n",
      "2019-12-12 16:33:29,908 : INFO : worker thread finished; awaiting finish of 86 more threads\n",
      "2019-12-12 16:33:29,908 : INFO : worker thread finished; awaiting finish of 85 more threads\n",
      "2019-12-12 16:33:29,909 : INFO : worker thread finished; awaiting finish of 84 more threads\n",
      "2019-12-12 16:33:29,909 : INFO : worker thread finished; awaiting finish of 83 more threads\n",
      "2019-12-12 16:33:29,910 : INFO : worker thread finished; awaiting finish of 82 more threads\n",
      "2019-12-12 16:33:29,910 : INFO : worker thread finished; awaiting finish of 81 more threads\n",
      "2019-12-12 16:33:29,911 : INFO : worker thread finished; awaiting finish of 80 more threads\n",
      "2019-12-12 16:33:29,911 : INFO : worker thread finished; awaiting finish of 79 more threads\n",
      "2019-12-12 16:33:29,912 : INFO : worker thread finished; awaiting finish of 78 more threads\n",
      "2019-12-12 16:33:29,912 : INFO : worker thread finished; awaiting finish of 77 more threads\n",
      "2019-12-12 16:33:29,913 : INFO : worker thread finished; awaiting finish of 76 more threads\n",
      "2019-12-12 16:33:29,913 : INFO : worker thread finished; awaiting finish of 75 more threads\n",
      "2019-12-12 16:33:29,914 : INFO : worker thread finished; awaiting finish of 74 more threads\n",
      "2019-12-12 16:33:29,914 : INFO : worker thread finished; awaiting finish of 73 more threads\n",
      "2019-12-12 16:33:29,915 : INFO : worker thread finished; awaiting finish of 72 more threads\n",
      "2019-12-12 16:33:29,915 : INFO : worker thread finished; awaiting finish of 71 more threads\n",
      "2019-12-12 16:33:29,916 : INFO : worker thread finished; awaiting finish of 70 more threads\n",
      "2019-12-12 16:33:29,916 : INFO : worker thread finished; awaiting finish of 69 more threads\n",
      "2019-12-12 16:33:29,917 : INFO : worker thread finished; awaiting finish of 68 more threads\n",
      "2019-12-12 16:33:29,917 : INFO : worker thread finished; awaiting finish of 67 more threads\n",
      "2019-12-12 16:33:29,917 : INFO : worker thread finished; awaiting finish of 66 more threads\n",
      "2019-12-12 16:33:29,918 : INFO : worker thread finished; awaiting finish of 65 more threads\n",
      "2019-12-12 16:33:29,918 : INFO : worker thread finished; awaiting finish of 64 more threads\n",
      "2019-12-12 16:33:29,919 : INFO : worker thread finished; awaiting finish of 63 more threads\n",
      "2019-12-12 16:33:29,919 : INFO : worker thread finished; awaiting finish of 62 more threads\n",
      "2019-12-12 16:33:29,919 : INFO : worker thread finished; awaiting finish of 61 more threads\n",
      "2019-12-12 16:33:29,920 : INFO : worker thread finished; awaiting finish of 60 more threads\n",
      "2019-12-12 16:33:29,920 : INFO : worker thread finished; awaiting finish of 59 more threads\n",
      "2019-12-12 16:33:29,921 : INFO : worker thread finished; awaiting finish of 58 more threads\n",
      "2019-12-12 16:33:29,921 : INFO : worker thread finished; awaiting finish of 57 more threads\n",
      "2019-12-12 16:33:29,922 : INFO : worker thread finished; awaiting finish of 56 more threads\n",
      "2019-12-12 16:33:29,922 : INFO : worker thread finished; awaiting finish of 55 more threads\n",
      "2019-12-12 16:33:29,923 : INFO : worker thread finished; awaiting finish of 54 more threads\n",
      "2019-12-12 16:33:29,924 : INFO : worker thread finished; awaiting finish of 53 more threads\n",
      "2019-12-12 16:33:29,925 : INFO : worker thread finished; awaiting finish of 52 more threads\n",
      "2019-12-12 16:33:29,926 : INFO : worker thread finished; awaiting finish of 51 more threads\n",
      "2019-12-12 16:33:29,926 : INFO : worker thread finished; awaiting finish of 50 more threads\n",
      "2019-12-12 16:33:29,927 : INFO : worker thread finished; awaiting finish of 49 more threads\n",
      "2019-12-12 16:33:29,928 : INFO : worker thread finished; awaiting finish of 48 more threads\n",
      "2019-12-12 16:33:29,928 : INFO : worker thread finished; awaiting finish of 47 more threads\n",
      "2019-12-12 16:33:29,929 : INFO : worker thread finished; awaiting finish of 46 more threads\n",
      "2019-12-12 16:33:29,929 : INFO : worker thread finished; awaiting finish of 45 more threads\n",
      "2019-12-12 16:33:29,930 : INFO : worker thread finished; awaiting finish of 44 more threads\n",
      "2019-12-12 16:33:29,930 : INFO : worker thread finished; awaiting finish of 43 more threads\n",
      "2019-12-12 16:33:29,931 : INFO : worker thread finished; awaiting finish of 42 more threads\n",
      "2019-12-12 16:33:29,931 : INFO : worker thread finished; awaiting finish of 41 more threads\n",
      "2019-12-12 16:33:29,932 : INFO : worker thread finished; awaiting finish of 40 more threads\n",
      "2019-12-12 16:33:29,932 : INFO : worker thread finished; awaiting finish of 39 more threads\n",
      "2019-12-12 16:33:29,933 : INFO : worker thread finished; awaiting finish of 38 more threads\n",
      "2019-12-12 16:33:29,933 : INFO : worker thread finished; awaiting finish of 37 more threads\n",
      "2019-12-12 16:33:29,934 : INFO : worker thread finished; awaiting finish of 36 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-12 16:33:29,934 : INFO : worker thread finished; awaiting finish of 35 more threads\n",
      "2019-12-12 16:33:29,934 : INFO : worker thread finished; awaiting finish of 34 more threads\n",
      "2019-12-12 16:33:29,935 : INFO : worker thread finished; awaiting finish of 33 more threads\n",
      "2019-12-12 16:33:29,935 : INFO : worker thread finished; awaiting finish of 32 more threads\n",
      "2019-12-12 16:33:29,936 : INFO : worker thread finished; awaiting finish of 31 more threads\n",
      "2019-12-12 16:33:29,936 : INFO : worker thread finished; awaiting finish of 30 more threads\n",
      "2019-12-12 16:33:29,936 : INFO : worker thread finished; awaiting finish of 29 more threads\n",
      "2019-12-12 16:33:29,937 : INFO : worker thread finished; awaiting finish of 28 more threads\n",
      "2019-12-12 16:33:29,937 : INFO : worker thread finished; awaiting finish of 27 more threads\n",
      "2019-12-12 16:33:29,937 : INFO : worker thread finished; awaiting finish of 26 more threads\n",
      "2019-12-12 16:33:29,938 : INFO : worker thread finished; awaiting finish of 25 more threads\n",
      "2019-12-12 16:33:29,938 : INFO : worker thread finished; awaiting finish of 24 more threads\n",
      "2019-12-12 16:33:29,939 : INFO : worker thread finished; awaiting finish of 23 more threads\n",
      "2019-12-12 16:33:29,939 : INFO : worker thread finished; awaiting finish of 22 more threads\n",
      "2019-12-12 16:33:29,940 : INFO : worker thread finished; awaiting finish of 21 more threads\n",
      "2019-12-12 16:33:29,940 : INFO : worker thread finished; awaiting finish of 20 more threads\n",
      "2019-12-12 16:33:29,941 : INFO : worker thread finished; awaiting finish of 19 more threads\n",
      "2019-12-12 16:33:29,941 : INFO : worker thread finished; awaiting finish of 18 more threads\n",
      "2019-12-12 16:33:29,942 : INFO : worker thread finished; awaiting finish of 17 more threads\n",
      "2019-12-12 16:33:29,942 : INFO : worker thread finished; awaiting finish of 16 more threads\n",
      "2019-12-12 16:33:29,943 : INFO : worker thread finished; awaiting finish of 15 more threads\n",
      "2019-12-12 16:33:29,943 : INFO : worker thread finished; awaiting finish of 14 more threads\n",
      "2019-12-12 16:33:29,944 : INFO : worker thread finished; awaiting finish of 13 more threads\n",
      "2019-12-12 16:33:29,944 : INFO : worker thread finished; awaiting finish of 12 more threads\n",
      "2019-12-12 16:33:29,945 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2019-12-12 16:33:29,945 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2019-12-12 16:33:29,945 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-12-12 16:33:29,946 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-12-12 16:33:29,946 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-12-12 16:33:29,947 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-12-12 16:33:29,947 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-12-12 16:33:29,948 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-12-12 16:33:29,948 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-12-12 16:33:29,948 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-12-12 16:33:29,949 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-12-12 16:33:29,949 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-12-12 16:33:29,950 : INFO : EPOCH - 2 : training on 66 raw words (14 effective words) took 0.1s, 257 effective words/s\n",
      "2019-12-12 16:33:30,002 : INFO : worker thread finished; awaiting finish of 99 more threads\n",
      "2019-12-12 16:33:30,004 : INFO : worker thread finished; awaiting finish of 98 more threads\n",
      "2019-12-12 16:33:30,005 : INFO : worker thread finished; awaiting finish of 97 more threads\n",
      "2019-12-12 16:33:30,005 : INFO : worker thread finished; awaiting finish of 96 more threads\n",
      "2019-12-12 16:33:30,006 : INFO : worker thread finished; awaiting finish of 95 more threads\n",
      "2019-12-12 16:33:30,007 : INFO : worker thread finished; awaiting finish of 94 more threads\n",
      "2019-12-12 16:33:30,008 : INFO : worker thread finished; awaiting finish of 93 more threads\n",
      "2019-12-12 16:33:30,008 : INFO : worker thread finished; awaiting finish of 92 more threads\n",
      "2019-12-12 16:33:30,009 : INFO : worker thread finished; awaiting finish of 91 more threads\n",
      "2019-12-12 16:33:30,010 : INFO : worker thread finished; awaiting finish of 90 more threads\n",
      "2019-12-12 16:33:30,010 : INFO : worker thread finished; awaiting finish of 89 more threads\n",
      "2019-12-12 16:33:30,011 : INFO : worker thread finished; awaiting finish of 88 more threads\n",
      "2019-12-12 16:33:30,011 : INFO : worker thread finished; awaiting finish of 87 more threads\n",
      "2019-12-12 16:33:30,012 : INFO : worker thread finished; awaiting finish of 86 more threads\n",
      "2019-12-12 16:33:30,012 : INFO : worker thread finished; awaiting finish of 85 more threads\n",
      "2019-12-12 16:33:30,013 : INFO : worker thread finished; awaiting finish of 84 more threads\n",
      "2019-12-12 16:33:30,013 : INFO : worker thread finished; awaiting finish of 83 more threads\n",
      "2019-12-12 16:33:30,014 : INFO : worker thread finished; awaiting finish of 82 more threads\n",
      "2019-12-12 16:33:30,014 : INFO : worker thread finished; awaiting finish of 81 more threads\n",
      "2019-12-12 16:33:30,014 : INFO : worker thread finished; awaiting finish of 80 more threads\n",
      "2019-12-12 16:33:30,015 : INFO : worker thread finished; awaiting finish of 79 more threads\n",
      "2019-12-12 16:33:30,015 : INFO : worker thread finished; awaiting finish of 78 more threads\n",
      "2019-12-12 16:33:30,015 : INFO : worker thread finished; awaiting finish of 77 more threads\n",
      "2019-12-12 16:33:30,016 : INFO : worker thread finished; awaiting finish of 76 more threads\n",
      "2019-12-12 16:33:30,016 : INFO : worker thread finished; awaiting finish of 75 more threads\n",
      "2019-12-12 16:33:30,017 : INFO : worker thread finished; awaiting finish of 74 more threads\n",
      "2019-12-12 16:33:30,017 : INFO : worker thread finished; awaiting finish of 73 more threads\n",
      "2019-12-12 16:33:30,017 : INFO : worker thread finished; awaiting finish of 72 more threads\n",
      "2019-12-12 16:33:30,018 : INFO : worker thread finished; awaiting finish of 71 more threads\n",
      "2019-12-12 16:33:30,018 : INFO : worker thread finished; awaiting finish of 70 more threads\n",
      "2019-12-12 16:33:30,018 : INFO : worker thread finished; awaiting finish of 69 more threads\n",
      "2019-12-12 16:33:30,019 : INFO : worker thread finished; awaiting finish of 68 more threads\n",
      "2019-12-12 16:33:30,019 : INFO : worker thread finished; awaiting finish of 67 more threads\n",
      "2019-12-12 16:33:30,020 : INFO : worker thread finished; awaiting finish of 66 more threads\n",
      "2019-12-12 16:33:30,020 : INFO : worker thread finished; awaiting finish of 65 more threads\n",
      "2019-12-12 16:33:30,021 : INFO : worker thread finished; awaiting finish of 64 more threads\n",
      "2019-12-12 16:33:30,021 : INFO : worker thread finished; awaiting finish of 63 more threads\n",
      "2019-12-12 16:33:30,022 : INFO : worker thread finished; awaiting finish of 62 more threads\n",
      "2019-12-12 16:33:30,022 : INFO : worker thread finished; awaiting finish of 61 more threads\n",
      "2019-12-12 16:33:30,023 : INFO : worker thread finished; awaiting finish of 60 more threads\n",
      "2019-12-12 16:33:30,024 : INFO : worker thread finished; awaiting finish of 59 more threads\n",
      "2019-12-12 16:33:30,024 : INFO : worker thread finished; awaiting finish of 58 more threads\n",
      "2019-12-12 16:33:30,025 : INFO : worker thread finished; awaiting finish of 57 more threads\n",
      "2019-12-12 16:33:30,025 : INFO : worker thread finished; awaiting finish of 56 more threads\n",
      "2019-12-12 16:33:30,026 : INFO : worker thread finished; awaiting finish of 55 more threads\n",
      "2019-12-12 16:33:30,026 : INFO : worker thread finished; awaiting finish of 54 more threads\n",
      "2019-12-12 16:33:30,027 : INFO : worker thread finished; awaiting finish of 53 more threads\n",
      "2019-12-12 16:33:30,027 : INFO : worker thread finished; awaiting finish of 52 more threads\n",
      "2019-12-12 16:33:30,028 : INFO : worker thread finished; awaiting finish of 51 more threads\n",
      "2019-12-12 16:33:30,028 : INFO : worker thread finished; awaiting finish of 50 more threads\n",
      "2019-12-12 16:33:30,029 : INFO : worker thread finished; awaiting finish of 49 more threads\n",
      "2019-12-12 16:33:30,029 : INFO : worker thread finished; awaiting finish of 48 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-12 16:33:30,029 : INFO : worker thread finished; awaiting finish of 47 more threads\n",
      "2019-12-12 16:33:30,030 : INFO : worker thread finished; awaiting finish of 46 more threads\n",
      "2019-12-12 16:33:30,030 : INFO : worker thread finished; awaiting finish of 45 more threads\n",
      "2019-12-12 16:33:30,031 : INFO : worker thread finished; awaiting finish of 44 more threads\n",
      "2019-12-12 16:33:30,031 : INFO : worker thread finished; awaiting finish of 43 more threads\n",
      "2019-12-12 16:33:30,032 : INFO : worker thread finished; awaiting finish of 42 more threads\n",
      "2019-12-12 16:33:30,033 : INFO : worker thread finished; awaiting finish of 41 more threads\n",
      "2019-12-12 16:33:30,033 : INFO : worker thread finished; awaiting finish of 40 more threads\n",
      "2019-12-12 16:33:30,034 : INFO : worker thread finished; awaiting finish of 39 more threads\n",
      "2019-12-12 16:33:30,034 : INFO : worker thread finished; awaiting finish of 38 more threads\n",
      "2019-12-12 16:33:30,035 : INFO : worker thread finished; awaiting finish of 37 more threads\n",
      "2019-12-12 16:33:30,035 : INFO : worker thread finished; awaiting finish of 36 more threads\n",
      "2019-12-12 16:33:30,036 : INFO : worker thread finished; awaiting finish of 35 more threads\n",
      "2019-12-12 16:33:30,036 : INFO : worker thread finished; awaiting finish of 34 more threads\n",
      "2019-12-12 16:33:30,037 : INFO : worker thread finished; awaiting finish of 33 more threads\n",
      "2019-12-12 16:33:30,037 : INFO : worker thread finished; awaiting finish of 32 more threads\n",
      "2019-12-12 16:33:30,038 : INFO : worker thread finished; awaiting finish of 31 more threads\n",
      "2019-12-12 16:33:30,038 : INFO : worker thread finished; awaiting finish of 30 more threads\n",
      "2019-12-12 16:33:30,039 : INFO : worker thread finished; awaiting finish of 29 more threads\n",
      "2019-12-12 16:33:30,039 : INFO : worker thread finished; awaiting finish of 28 more threads\n",
      "2019-12-12 16:33:30,040 : INFO : worker thread finished; awaiting finish of 27 more threads\n",
      "2019-12-12 16:33:30,041 : INFO : worker thread finished; awaiting finish of 26 more threads\n",
      "2019-12-12 16:33:30,041 : INFO : worker thread finished; awaiting finish of 25 more threads\n",
      "2019-12-12 16:33:30,042 : INFO : worker thread finished; awaiting finish of 24 more threads\n",
      "2019-12-12 16:33:30,042 : INFO : worker thread finished; awaiting finish of 23 more threads\n",
      "2019-12-12 16:33:30,043 : INFO : worker thread finished; awaiting finish of 22 more threads\n",
      "2019-12-12 16:33:30,043 : INFO : worker thread finished; awaiting finish of 21 more threads\n",
      "2019-12-12 16:33:30,044 : INFO : worker thread finished; awaiting finish of 20 more threads\n",
      "2019-12-12 16:33:30,044 : INFO : worker thread finished; awaiting finish of 19 more threads\n",
      "2019-12-12 16:33:30,045 : INFO : worker thread finished; awaiting finish of 18 more threads\n",
      "2019-12-12 16:33:30,045 : INFO : worker thread finished; awaiting finish of 17 more threads\n",
      "2019-12-12 16:33:30,046 : INFO : worker thread finished; awaiting finish of 16 more threads\n",
      "2019-12-12 16:33:30,046 : INFO : worker thread finished; awaiting finish of 15 more threads\n",
      "2019-12-12 16:33:30,047 : INFO : worker thread finished; awaiting finish of 14 more threads\n",
      "2019-12-12 16:33:30,048 : INFO : worker thread finished; awaiting finish of 13 more threads\n",
      "2019-12-12 16:33:30,048 : INFO : worker thread finished; awaiting finish of 12 more threads\n",
      "2019-12-12 16:33:30,049 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2019-12-12 16:33:30,049 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2019-12-12 16:33:30,050 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-12-12 16:33:30,050 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-12-12 16:33:30,050 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-12-12 16:33:30,051 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-12-12 16:33:30,051 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-12-12 16:33:30,052 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-12-12 16:33:30,052 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-12-12 16:33:30,052 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-12-12 16:33:30,053 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-12-12 16:33:30,053 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-12-12 16:33:30,054 : INFO : EPOCH - 3 : training on 66 raw words (18 effective words) took 0.1s, 321 effective words/s\n",
      "2019-12-12 16:33:30,104 : INFO : worker thread finished; awaiting finish of 99 more threads\n",
      "2019-12-12 16:33:30,105 : INFO : worker thread finished; awaiting finish of 98 more threads\n",
      "2019-12-12 16:33:30,106 : INFO : worker thread finished; awaiting finish of 97 more threads\n",
      "2019-12-12 16:33:30,106 : INFO : worker thread finished; awaiting finish of 96 more threads\n",
      "2019-12-12 16:33:30,106 : INFO : worker thread finished; awaiting finish of 95 more threads\n",
      "2019-12-12 16:33:30,107 : INFO : worker thread finished; awaiting finish of 94 more threads\n",
      "2019-12-12 16:33:30,108 : INFO : worker thread finished; awaiting finish of 93 more threads\n",
      "2019-12-12 16:33:30,108 : INFO : worker thread finished; awaiting finish of 92 more threads\n",
      "2019-12-12 16:33:30,109 : INFO : worker thread finished; awaiting finish of 91 more threads\n",
      "2019-12-12 16:33:30,109 : INFO : worker thread finished; awaiting finish of 90 more threads\n",
      "2019-12-12 16:33:30,110 : INFO : worker thread finished; awaiting finish of 89 more threads\n",
      "2019-12-12 16:33:30,110 : INFO : worker thread finished; awaiting finish of 88 more threads\n",
      "2019-12-12 16:33:30,111 : INFO : worker thread finished; awaiting finish of 87 more threads\n",
      "2019-12-12 16:33:30,111 : INFO : worker thread finished; awaiting finish of 86 more threads\n",
      "2019-12-12 16:33:30,112 : INFO : worker thread finished; awaiting finish of 85 more threads\n",
      "2019-12-12 16:33:30,112 : INFO : worker thread finished; awaiting finish of 84 more threads\n",
      "2019-12-12 16:33:30,113 : INFO : worker thread finished; awaiting finish of 83 more threads\n",
      "2019-12-12 16:33:30,113 : INFO : worker thread finished; awaiting finish of 82 more threads\n",
      "2019-12-12 16:33:30,114 : INFO : worker thread finished; awaiting finish of 81 more threads\n",
      "2019-12-12 16:33:30,114 : INFO : worker thread finished; awaiting finish of 80 more threads\n",
      "2019-12-12 16:33:30,115 : INFO : worker thread finished; awaiting finish of 79 more threads\n",
      "2019-12-12 16:33:30,115 : INFO : worker thread finished; awaiting finish of 78 more threads\n",
      "2019-12-12 16:33:30,116 : INFO : worker thread finished; awaiting finish of 77 more threads\n",
      "2019-12-12 16:33:30,117 : INFO : worker thread finished; awaiting finish of 76 more threads\n",
      "2019-12-12 16:33:30,117 : INFO : worker thread finished; awaiting finish of 75 more threads\n",
      "2019-12-12 16:33:30,118 : INFO : worker thread finished; awaiting finish of 74 more threads\n",
      "2019-12-12 16:33:30,118 : INFO : worker thread finished; awaiting finish of 73 more threads\n",
      "2019-12-12 16:33:30,119 : INFO : worker thread finished; awaiting finish of 72 more threads\n",
      "2019-12-12 16:33:30,119 : INFO : worker thread finished; awaiting finish of 71 more threads\n",
      "2019-12-12 16:33:30,120 : INFO : worker thread finished; awaiting finish of 70 more threads\n",
      "2019-12-12 16:33:30,120 : INFO : worker thread finished; awaiting finish of 69 more threads\n",
      "2019-12-12 16:33:30,121 : INFO : worker thread finished; awaiting finish of 68 more threads\n",
      "2019-12-12 16:33:30,121 : INFO : worker thread finished; awaiting finish of 67 more threads\n",
      "2019-12-12 16:33:30,122 : INFO : worker thread finished; awaiting finish of 66 more threads\n",
      "2019-12-12 16:33:30,122 : INFO : worker thread finished; awaiting finish of 65 more threads\n",
      "2019-12-12 16:33:30,123 : INFO : worker thread finished; awaiting finish of 64 more threads\n",
      "2019-12-12 16:33:30,123 : INFO : worker thread finished; awaiting finish of 63 more threads\n",
      "2019-12-12 16:33:30,124 : INFO : worker thread finished; awaiting finish of 62 more threads\n",
      "2019-12-12 16:33:30,125 : INFO : worker thread finished; awaiting finish of 61 more threads\n",
      "2019-12-12 16:33:30,126 : INFO : worker thread finished; awaiting finish of 60 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-12 16:33:30,126 : INFO : worker thread finished; awaiting finish of 59 more threads\n",
      "2019-12-12 16:33:30,127 : INFO : worker thread finished; awaiting finish of 58 more threads\n",
      "2019-12-12 16:33:30,127 : INFO : worker thread finished; awaiting finish of 57 more threads\n",
      "2019-12-12 16:33:30,128 : INFO : worker thread finished; awaiting finish of 56 more threads\n",
      "2019-12-12 16:33:30,128 : INFO : worker thread finished; awaiting finish of 55 more threads\n",
      "2019-12-12 16:33:30,129 : INFO : worker thread finished; awaiting finish of 54 more threads\n",
      "2019-12-12 16:33:30,130 : INFO : worker thread finished; awaiting finish of 53 more threads\n",
      "2019-12-12 16:33:30,130 : INFO : worker thread finished; awaiting finish of 52 more threads\n",
      "2019-12-12 16:33:30,131 : INFO : worker thread finished; awaiting finish of 51 more threads\n",
      "2019-12-12 16:33:30,132 : INFO : worker thread finished; awaiting finish of 50 more threads\n",
      "2019-12-12 16:33:30,132 : INFO : worker thread finished; awaiting finish of 49 more threads\n",
      "2019-12-12 16:33:30,133 : INFO : worker thread finished; awaiting finish of 48 more threads\n",
      "2019-12-12 16:33:30,133 : INFO : worker thread finished; awaiting finish of 47 more threads\n",
      "2019-12-12 16:33:30,134 : INFO : worker thread finished; awaiting finish of 46 more threads\n",
      "2019-12-12 16:33:30,134 : INFO : worker thread finished; awaiting finish of 45 more threads\n",
      "2019-12-12 16:33:30,135 : INFO : worker thread finished; awaiting finish of 44 more threads\n",
      "2019-12-12 16:33:30,135 : INFO : worker thread finished; awaiting finish of 43 more threads\n",
      "2019-12-12 16:33:30,135 : INFO : worker thread finished; awaiting finish of 42 more threads\n",
      "2019-12-12 16:33:30,136 : INFO : worker thread finished; awaiting finish of 41 more threads\n",
      "2019-12-12 16:33:30,136 : INFO : worker thread finished; awaiting finish of 40 more threads\n",
      "2019-12-12 16:33:30,137 : INFO : worker thread finished; awaiting finish of 39 more threads\n",
      "2019-12-12 16:33:30,137 : INFO : worker thread finished; awaiting finish of 38 more threads\n",
      "2019-12-12 16:33:30,138 : INFO : worker thread finished; awaiting finish of 37 more threads\n",
      "2019-12-12 16:33:30,138 : INFO : worker thread finished; awaiting finish of 36 more threads\n",
      "2019-12-12 16:33:30,139 : INFO : worker thread finished; awaiting finish of 35 more threads\n",
      "2019-12-12 16:33:30,139 : INFO : worker thread finished; awaiting finish of 34 more threads\n",
      "2019-12-12 16:33:30,139 : INFO : worker thread finished; awaiting finish of 33 more threads\n",
      "2019-12-12 16:33:30,140 : INFO : worker thread finished; awaiting finish of 32 more threads\n",
      "2019-12-12 16:33:30,140 : INFO : worker thread finished; awaiting finish of 31 more threads\n",
      "2019-12-12 16:33:30,141 : INFO : worker thread finished; awaiting finish of 30 more threads\n",
      "2019-12-12 16:33:30,142 : INFO : worker thread finished; awaiting finish of 29 more threads\n",
      "2019-12-12 16:33:30,142 : INFO : worker thread finished; awaiting finish of 28 more threads\n",
      "2019-12-12 16:33:30,143 : INFO : worker thread finished; awaiting finish of 27 more threads\n",
      "2019-12-12 16:33:30,143 : INFO : worker thread finished; awaiting finish of 26 more threads\n",
      "2019-12-12 16:33:30,144 : INFO : worker thread finished; awaiting finish of 25 more threads\n",
      "2019-12-12 16:33:30,144 : INFO : worker thread finished; awaiting finish of 24 more threads\n",
      "2019-12-12 16:33:30,145 : INFO : worker thread finished; awaiting finish of 23 more threads\n",
      "2019-12-12 16:33:30,145 : INFO : worker thread finished; awaiting finish of 22 more threads\n",
      "2019-12-12 16:33:30,146 : INFO : worker thread finished; awaiting finish of 21 more threads\n",
      "2019-12-12 16:33:30,146 : INFO : worker thread finished; awaiting finish of 20 more threads\n",
      "2019-12-12 16:33:30,147 : INFO : worker thread finished; awaiting finish of 19 more threads\n",
      "2019-12-12 16:33:30,147 : INFO : worker thread finished; awaiting finish of 18 more threads\n",
      "2019-12-12 16:33:30,148 : INFO : worker thread finished; awaiting finish of 17 more threads\n",
      "2019-12-12 16:33:30,148 : INFO : worker thread finished; awaiting finish of 16 more threads\n",
      "2019-12-12 16:33:30,148 : INFO : worker thread finished; awaiting finish of 15 more threads\n",
      "2019-12-12 16:33:30,149 : INFO : worker thread finished; awaiting finish of 14 more threads\n",
      "2019-12-12 16:33:30,149 : INFO : worker thread finished; awaiting finish of 13 more threads\n",
      "2019-12-12 16:33:30,150 : INFO : worker thread finished; awaiting finish of 12 more threads\n",
      "2019-12-12 16:33:30,150 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2019-12-12 16:33:30,151 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2019-12-12 16:33:30,151 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-12-12 16:33:30,152 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-12-12 16:33:30,152 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-12-12 16:33:30,153 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-12-12 16:33:30,153 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-12-12 16:33:30,153 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-12-12 16:33:30,154 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-12-12 16:33:30,154 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-12-12 16:33:30,155 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-12-12 16:33:30,155 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-12-12 16:33:30,155 : INFO : EPOCH - 4 : training on 66 raw words (22 effective words) took 0.1s, 388 effective words/s\n",
      "2019-12-12 16:33:30,204 : INFO : worker thread finished; awaiting finish of 99 more threads\n",
      "2019-12-12 16:33:30,205 : INFO : worker thread finished; awaiting finish of 98 more threads\n",
      "2019-12-12 16:33:30,206 : INFO : worker thread finished; awaiting finish of 97 more threads\n",
      "2019-12-12 16:33:30,206 : INFO : worker thread finished; awaiting finish of 96 more threads\n",
      "2019-12-12 16:33:30,207 : INFO : worker thread finished; awaiting finish of 95 more threads\n",
      "2019-12-12 16:33:30,208 : INFO : worker thread finished; awaiting finish of 94 more threads\n",
      "2019-12-12 16:33:30,208 : INFO : worker thread finished; awaiting finish of 93 more threads\n",
      "2019-12-12 16:33:30,209 : INFO : worker thread finished; awaiting finish of 92 more threads\n",
      "2019-12-12 16:33:30,209 : INFO : worker thread finished; awaiting finish of 91 more threads\n",
      "2019-12-12 16:33:30,210 : INFO : worker thread finished; awaiting finish of 90 more threads\n",
      "2019-12-12 16:33:30,210 : INFO : worker thread finished; awaiting finish of 89 more threads\n",
      "2019-12-12 16:33:30,210 : INFO : worker thread finished; awaiting finish of 88 more threads\n",
      "2019-12-12 16:33:30,211 : INFO : worker thread finished; awaiting finish of 87 more threads\n",
      "2019-12-12 16:33:30,211 : INFO : worker thread finished; awaiting finish of 86 more threads\n",
      "2019-12-12 16:33:30,212 : INFO : worker thread finished; awaiting finish of 85 more threads\n",
      "2019-12-12 16:33:30,212 : INFO : worker thread finished; awaiting finish of 84 more threads\n",
      "2019-12-12 16:33:30,213 : INFO : worker thread finished; awaiting finish of 83 more threads\n",
      "2019-12-12 16:33:30,213 : INFO : worker thread finished; awaiting finish of 82 more threads\n",
      "2019-12-12 16:33:30,214 : INFO : worker thread finished; awaiting finish of 81 more threads\n",
      "2019-12-12 16:33:30,214 : INFO : worker thread finished; awaiting finish of 80 more threads\n",
      "2019-12-12 16:33:30,215 : INFO : worker thread finished; awaiting finish of 79 more threads\n",
      "2019-12-12 16:33:30,215 : INFO : worker thread finished; awaiting finish of 78 more threads\n",
      "2019-12-12 16:33:30,215 : INFO : worker thread finished; awaiting finish of 77 more threads\n",
      "2019-12-12 16:33:30,216 : INFO : worker thread finished; awaiting finish of 76 more threads\n",
      "2019-12-12 16:33:30,216 : INFO : worker thread finished; awaiting finish of 75 more threads\n",
      "2019-12-12 16:33:30,217 : INFO : worker thread finished; awaiting finish of 74 more threads\n",
      "2019-12-12 16:33:30,217 : INFO : worker thread finished; awaiting finish of 73 more threads\n",
      "2019-12-12 16:33:30,218 : INFO : worker thread finished; awaiting finish of 72 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-12 16:33:30,218 : INFO : worker thread finished; awaiting finish of 71 more threads\n",
      "2019-12-12 16:33:30,219 : INFO : worker thread finished; awaiting finish of 70 more threads\n",
      "2019-12-12 16:33:30,219 : INFO : worker thread finished; awaiting finish of 69 more threads\n",
      "2019-12-12 16:33:30,219 : INFO : worker thread finished; awaiting finish of 68 more threads\n",
      "2019-12-12 16:33:30,220 : INFO : worker thread finished; awaiting finish of 67 more threads\n",
      "2019-12-12 16:33:30,220 : INFO : worker thread finished; awaiting finish of 66 more threads\n",
      "2019-12-12 16:33:30,220 : INFO : worker thread finished; awaiting finish of 65 more threads\n",
      "2019-12-12 16:33:30,221 : INFO : worker thread finished; awaiting finish of 64 more threads\n",
      "2019-12-12 16:33:30,221 : INFO : worker thread finished; awaiting finish of 63 more threads\n",
      "2019-12-12 16:33:30,221 : INFO : worker thread finished; awaiting finish of 62 more threads\n",
      "2019-12-12 16:33:30,222 : INFO : worker thread finished; awaiting finish of 61 more threads\n",
      "2019-12-12 16:33:30,223 : INFO : worker thread finished; awaiting finish of 60 more threads\n",
      "2019-12-12 16:33:30,224 : INFO : worker thread finished; awaiting finish of 59 more threads\n",
      "2019-12-12 16:33:30,224 : INFO : worker thread finished; awaiting finish of 58 more threads\n",
      "2019-12-12 16:33:30,225 : INFO : worker thread finished; awaiting finish of 57 more threads\n",
      "2019-12-12 16:33:30,225 : INFO : worker thread finished; awaiting finish of 56 more threads\n",
      "2019-12-12 16:33:30,225 : INFO : worker thread finished; awaiting finish of 55 more threads\n",
      "2019-12-12 16:33:30,226 : INFO : worker thread finished; awaiting finish of 54 more threads\n",
      "2019-12-12 16:33:30,226 : INFO : worker thread finished; awaiting finish of 53 more threads\n",
      "2019-12-12 16:33:30,227 : INFO : worker thread finished; awaiting finish of 52 more threads\n",
      "2019-12-12 16:33:30,227 : INFO : worker thread finished; awaiting finish of 51 more threads\n",
      "2019-12-12 16:33:30,228 : INFO : worker thread finished; awaiting finish of 50 more threads\n",
      "2019-12-12 16:33:30,228 : INFO : worker thread finished; awaiting finish of 49 more threads\n",
      "2019-12-12 16:33:30,229 : INFO : worker thread finished; awaiting finish of 48 more threads\n",
      "2019-12-12 16:33:30,230 : INFO : worker thread finished; awaiting finish of 47 more threads\n",
      "2019-12-12 16:33:30,230 : INFO : worker thread finished; awaiting finish of 46 more threads\n",
      "2019-12-12 16:33:30,230 : INFO : worker thread finished; awaiting finish of 45 more threads\n",
      "2019-12-12 16:33:30,231 : INFO : worker thread finished; awaiting finish of 44 more threads\n",
      "2019-12-12 16:33:30,231 : INFO : worker thread finished; awaiting finish of 43 more threads\n",
      "2019-12-12 16:33:30,232 : INFO : worker thread finished; awaiting finish of 42 more threads\n",
      "2019-12-12 16:33:30,232 : INFO : worker thread finished; awaiting finish of 41 more threads\n",
      "2019-12-12 16:33:30,232 : INFO : worker thread finished; awaiting finish of 40 more threads\n",
      "2019-12-12 16:33:30,233 : INFO : worker thread finished; awaiting finish of 39 more threads\n",
      "2019-12-12 16:33:30,234 : INFO : worker thread finished; awaiting finish of 38 more threads\n",
      "2019-12-12 16:33:30,234 : INFO : worker thread finished; awaiting finish of 37 more threads\n",
      "2019-12-12 16:33:30,234 : INFO : worker thread finished; awaiting finish of 36 more threads\n",
      "2019-12-12 16:33:30,235 : INFO : worker thread finished; awaiting finish of 35 more threads\n",
      "2019-12-12 16:33:30,238 : INFO : worker thread finished; awaiting finish of 34 more threads\n",
      "2019-12-12 16:33:30,238 : INFO : worker thread finished; awaiting finish of 33 more threads\n",
      "2019-12-12 16:33:30,239 : INFO : worker thread finished; awaiting finish of 32 more threads\n",
      "2019-12-12 16:33:30,239 : INFO : worker thread finished; awaiting finish of 31 more threads\n",
      "2019-12-12 16:33:30,240 : INFO : worker thread finished; awaiting finish of 30 more threads\n",
      "2019-12-12 16:33:30,240 : INFO : worker thread finished; awaiting finish of 29 more threads\n",
      "2019-12-12 16:33:30,241 : INFO : worker thread finished; awaiting finish of 28 more threads\n",
      "2019-12-12 16:33:30,241 : INFO : worker thread finished; awaiting finish of 27 more threads\n",
      "2019-12-12 16:33:30,242 : INFO : worker thread finished; awaiting finish of 26 more threads\n",
      "2019-12-12 16:33:30,242 : INFO : worker thread finished; awaiting finish of 25 more threads\n",
      "2019-12-12 16:33:30,242 : INFO : worker thread finished; awaiting finish of 24 more threads\n",
      "2019-12-12 16:33:30,243 : INFO : worker thread finished; awaiting finish of 23 more threads\n",
      "2019-12-12 16:33:30,243 : INFO : worker thread finished; awaiting finish of 22 more threads\n",
      "2019-12-12 16:33:30,244 : INFO : worker thread finished; awaiting finish of 21 more threads\n",
      "2019-12-12 16:33:30,244 : INFO : worker thread finished; awaiting finish of 20 more threads\n",
      "2019-12-12 16:33:30,245 : INFO : worker thread finished; awaiting finish of 19 more threads\n",
      "2019-12-12 16:33:30,245 : INFO : worker thread finished; awaiting finish of 18 more threads\n",
      "2019-12-12 16:33:30,245 : INFO : worker thread finished; awaiting finish of 17 more threads\n",
      "2019-12-12 16:33:30,246 : INFO : worker thread finished; awaiting finish of 16 more threads\n",
      "2019-12-12 16:33:30,246 : INFO : worker thread finished; awaiting finish of 15 more threads\n",
      "2019-12-12 16:33:30,247 : INFO : worker thread finished; awaiting finish of 14 more threads\n",
      "2019-12-12 16:33:30,247 : INFO : worker thread finished; awaiting finish of 13 more threads\n",
      "2019-12-12 16:33:30,248 : INFO : worker thread finished; awaiting finish of 12 more threads\n",
      "2019-12-12 16:33:30,248 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2019-12-12 16:33:30,249 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2019-12-12 16:33:30,249 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-12-12 16:33:30,250 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-12-12 16:33:30,250 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-12-12 16:33:30,251 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-12-12 16:33:30,251 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-12-12 16:33:30,252 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-12-12 16:33:30,252 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-12-12 16:33:30,252 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-12-12 16:33:30,253 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-12-12 16:33:30,253 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-12-12 16:33:30,254 : INFO : EPOCH - 5 : training on 66 raw words (12 effective words) took 0.1s, 217 effective words/s\n",
      "2019-12-12 16:33:30,254 : INFO : training on a 330 raw words (81 effective words) took 0.5s, 159 effective words/s\n",
      "2019-12-12 16:33:30,255 : WARNING : under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "2019-12-12 16:33:30,255 : INFO : saving Word2Vec object under C:\\Users\\Big data\\Desktop\\class\\funcardproject\\word2vec\\word2vec.model, separately None\n",
      "2019-12-12 16:33:30,256 : INFO : not storing attribute vectors_norm\n",
      "2019-12-12 16:33:30,257 : INFO : not storing attribute cum_table\n",
      "2019-12-12 16:33:30,259 : INFO : saved C:\\Users\\Big data\\Desktop\\class\\funcardproject\\word2vec\\word2vec.model\n"
     ]
    }
   ],
   "source": [
    "model = Word2Vec(r\"C:\\Users\\Big data\\Desktop\\class\\funcardproject\\data\\文章\\一整大篇_乾淨.txt\", size=200, window=100, min_count=0, workers=100)\n",
    "model.save(r'C:\\Users\\Big data\\Desktop\\class\\funcardproject\\word2vec\\word2vec.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\Big data\\\\Desktop\\\\class\\\\funcardproject\\\\word2vec\\\\(合併重要詞信賴區間)penaltysize150win15cbow0.bin'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-596f5bb3b1ca>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mword_vectors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKeyedVectors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_word2vec_format\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr\"C:\\Users\\Big data\\Desktop\\class\\funcardproject\\word2vec\\(合併重要詞信賴區間)penaltysize150win15cbow0.bin\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbinary\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"'旅遊'前10名相似:\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mword_vectors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'日本'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'中國'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'加油'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtopn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\gensim\\models\\keyedvectors.py\u001b[0m in \u001b[0;36mload_word2vec_format\u001b[1;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype)\u001b[0m\n\u001b[0;32m   1496\u001b[0m         return _load_word2vec_format(\n\u001b[0;32m   1497\u001b[0m             \u001b[0mcls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfvocab\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfvocab\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbinary\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbinary\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0municode_errors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0municode_errors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1498\u001b[1;33m             limit=limit, datatype=datatype)\n\u001b[0m\u001b[0;32m   1499\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1500\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_keras_embedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_embeddings\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\gensim\\models\\utils_any2vec.py\u001b[0m in \u001b[0;36m_load_word2vec_format\u001b[1;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype)\u001b[0m\n\u001b[0;32m    340\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"loading projection weights from %s\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 342\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfin\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    343\u001b[0m         \u001b[0mheader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_unicode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfin\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m         \u001b[0mvocab_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvector_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mheader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# throws for invalid file format\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\smart_open\\smart_open_lib.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(uri, mode, buffering, encoding, errors, newline, closefd, opener, ignore_ext, transport_params)\u001b[0m\n\u001b[0;32m    306\u001b[0m         \u001b[0mbuffering\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbuffering\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    307\u001b[0m         \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 308\u001b[1;33m         \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    309\u001b[0m     )\n\u001b[0;32m    310\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\smart_open\\smart_open_lib.py\u001b[0m in \u001b[0;36m_shortcut_open\u001b[1;34m(uri, mode, ignore_ext, buffering, encoding, errors)\u001b[0m\n\u001b[0;32m    515\u001b[0m     \u001b[1;31m#\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    516\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPY3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 517\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_builtin_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparsed_uri\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muri_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffering\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbuffering\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mopen_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    518\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mopen_kwargs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    519\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_builtin_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparsed_uri\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muri_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffering\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbuffering\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\Big data\\\\Desktop\\\\class\\\\funcardproject\\\\word2vec\\\\(合併重要詞信賴區間)penaltysize150win15cbow0.bin'"
     ]
    }
   ],
   "source": [
    "# 使用訓練好的model\n",
    "import warnings\n",
    "warnings.filterwarnings(action = 'ignore', category = UserWarning, module = 'gensim')\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "\n",
    "\n",
    "word_vectors = KeyedVectors.load_word2vec_format(r\"C:\\Users\\Big data\\Desktop\\class\\funcardproject\\word2vec\\(合併重要詞信賴區間)penaltysize150win15cbow0.bin\", binary = True)\n",
    "print(\"'旅遊'前10名相似:\")    \n",
    "res = word_vectors.wv.most_similar(['日本','中國','加油'], topn = 20)\n",
    "for item in res:\n",
    "    print(item[0] + \",\" + str(item[1]))\n",
    "print(\"\\n'爸爸','媽媽'之間相似度:\")\n",
    "res = word_vectors.similarity('爸爸', '媽媽')\n",
    "print(res)\n",
    "print(\"\\n'爸爸'之於'老公',如'媽媽'之於'老婆':\")\n",
    "res = word_vectors.most_similar(positive = ['爸爸', '老公'], negative = ['媽媽'], topn = 5)\n",
    "for item in res:\n",
    "    print(item[0] + \",\" + str(item[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'word_vectors' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-d310fb690dec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mword_vectors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msimilarity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"回饋\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"現金\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'word_vectors' is not defined"
     ]
    }
   ],
   "source": [
    "a = word_vectors.similarity(\"回饋\", \"現金\")\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-12 16:39:31,005 : INFO : loading projection weights from C:\\Users\\Big data\\Desktop\\class\\funcardproject\\word2vec\\(合併重要詞信賴區間)penaltysize100win15cbow0.bin\n",
      "2019-12-12 16:39:31,860 : INFO : loaded (56224, 100) matrix from C:\\Users\\Big data\\Desktop\\class\\funcardproject\\word2vec\\(合併重要詞信賴區間)penaltysize100win15cbow0.bin\n"
     ]
    }
   ],
   "source": [
    "# 載入bin檔\n",
    "wv_from_bin = KeyedVectors.load_word2vec_format(datapath(r'C:\\Users\\Big data\\Desktop\\class\\funcardproject\\word2vec\\(合併重要詞信賴區間)penaltysize100win15cbow0.bin'), binary=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "#隨意輸入文字\n",
    "input_words=[\"請問有沒有適合旅遊加油現金回饋的卡,?\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['請', '問有', '沒有', '適合', '旅遊', '加油', '現金回饋', '的', '卡']"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#轉DataFrame\n",
    "input_words=pd.DataFrame(input_words,columns=['content'])\n",
    "#斷詞\n",
    "df1=斷詞(input_words)\n",
    "#清乾淨\n",
    "news = 整理(input_words)\n",
    "# 吐出來\n",
    "output_words = input_words['seg'][0]\n",
    "#用空格切開\n",
    "output_words=output_words.split()\n",
    "output_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('可先', 0.8530063033103943),\n",
       " ('943', 0.8477160930633545),\n",
       " ('優惠才', 0.8412401676177979),\n",
       " ('服務人員', 0.8354141116142273),\n",
       " ('繳學費', 0.829584002494812),\n",
       " ('賠本', 0.8292111158370972),\n",
       " ('碰券', 0.8273600339889526),\n",
       " ('要用', 0.8255729675292969),\n",
       " ('李光爵', 0.8252677917480469),\n",
       " ('特定', 0.823772668838501)]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#找最相似的詞\n",
    "res = wv_from_bin.most_similar(output_words,topn = 100)\n",
    "res[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.48889843 0.03019534]\n"
     ]
    }
   ],
   "source": [
    "# 找兩個詞的相似度\n",
    "res = wv_from_bin.similarity(['日本','加油'],'東京')\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "distance() missing 1 required positional argument: 'w2'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-110-cf1a2a4c3806>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwv_from_bin\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_words\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: distance() missing 1 required positional argument: 'w2'"
     ]
    }
   ],
   "source": [
    "res = wv_from_bin.distance(output_words[0])\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<gensim.models.keyedvectors.Word2VecKeyedVectors object at 0x0000023A458C85F8>\n"
     ]
    }
   ],
   "source": [
    "print (wv_from_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#以倍率詞作為重要詞\n",
    "important_words =[]\n",
    "with open('D:/pythoncode/民事資料/處死刑純地院濾完(無毒)/原始詞頻.csv','r',encoding = 'utf-8')as f:\n",
    "    rows = f.readlines()\n",
    "    for row in rows:\n",
    "        data = row.split(',')\n",
    "        try:\n",
    "            if (float(data[-1].replace('\\n','')) >= 2 or float(data[-1].replace('\\n','')) <=0.5 ):\n",
    "                if float(data[-1].replace('\\n','')) <=0.5 :\n",
    "                    if float(data[-2].replace('\\n','')) >=  test/368:\n",
    "                        important_words.append(data[0])\n",
    "                else:\n",
    "                    important_words.append(data[0])\n",
    "        except:\n",
    "            important_words.append(data[0])\n",
    "type_list = ['處死刑純地院(經查)整理完詞性斷詞','處無期徒刑純地院(經查)整理完詞性斷詞']\n",
    "size = [25,50,75,100,125,150]\n",
    "cbow = [0,1]\n",
    "for tt in type_list:\n",
    "    for q in cbow:\n",
    "        for p in size:\n",
    "            filename = 'D:/pythoncode/民事資料/處死刑純地院濾完(無毒)/模型/(合併重要詞)penaltysize'+str(p)+'win150cbow'+str(q)+'.bin'\n",
    "            model = gensim.models.KeyedVectors.load_word2vec_format(filename,binary=True)\n",
    "            path = 'D:/pythoncode/民事資料/處死刑純地院濾完(無毒)/否定詞合併其重要詞(否定)/'+tt+'/*/*.txt'\n",
    "            files = glob.glob(path)\n",
    "            for file in files:\n",
    "                with open(file,'r',encoding='UTF8')as f:\n",
    "                    rows = f.readlines()\n",
    "                    final = []\n",
    "                    content = ''\n",
    "                    for row in rows:\n",
    "                        content = content + row\n",
    "                    sentence = content.replace('\\n',' ').split(' ')\n",
    "                    words =[]\n",
    "                    for x in sentence:\n",
    "                        if (x.replace('否定+','') in important_words)or(x in important_words):\n",
    "                            words.append(x) \n",
    "                    for word in words:    \n",
    "                        try:\n",
    "                            final.append(model.get_vector(word))\n",
    "                        except:\n",
    "                            V = 1\n",
    "                    try:\n",
    "                        fms = []\n",
    "                        for x in range(0,p):\n",
    "                            fm = final[0][x]\n",
    "                            for y in range(1,len(final)):\n",
    "                                fm =fm + final[y][x]\n",
    "                            fm = fm/len(final)\n",
    "                            fms.append(fm)\n",
    "                        finalrow = file.split('\\\\')[2].replace(',','、').replace('.txt','')\n",
    "                        for z in fms:\n",
    "                            finalrow = finalrow + ',' +str(z) \n",
    "                        if '處無期徒刑' in tt:\n",
    "                            finalrow = finalrow +','+ '2'+'\\n'\n",
    "                        else:\n",
    "                            finalrow = finalrow +','+ '1'+'\\n'\n",
    "                        f_file = 'D:/pythoncode/民事資料/處死刑純地院濾完(無毒)/向量/(合併重要詞重新'+str(test)+')txtvector'\n",
    "                        finfile = f_file+str(q)+str(p)+'.csv'\n",
    "                        with open (finfile,'a')as fin:\n",
    "                            fin.write(finalrow)\n",
    "                    except:\n",
    "                        print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 斷詞套件\n",
    "def 斷詞(news):\n",
    "    df1=news\n",
    "    df1['seg']=None\n",
    "    df1['word_freq']=None\n",
    "    n=len(news)\n",
    "    alltext=[]\n",
    "    stopset=set()\n",
    "    stop2=['/n','']\n",
    "    with open('C:\\\\Users\\\\Big data\\\\Desktop\\\\字詞貼標\\\\DB104-master\\\\stop.txt','r',encoding='ISO-8859-1') as s:\n",
    "        for line in s:\n",
    "            stopset.add(line.strip('\\n'))\n",
    "    jieba.load_userdict('C:\\\\Users\\\\Big data\\\\Desktop\\\\字詞貼標\\\\DB104-master\\\\userdict.txt')\n",
    "    for i in range(n):\n",
    "        seg=''\n",
    "        wf={}\n",
    "        text= str(df1.loc[i]['content'])\n",
    "        cut=jieba.cut(text,cut_all=False)\n",
    "        for j in cut:\n",
    "            if j not in stopset:\n",
    "                seg +=j+' '\n",
    "                seg = seg.replace(\"\\n\",'')\n",
    "        df1['seg'][i]=seg\n",
    "        for w in seg.split(' '):\n",
    "            if w not in wf:\n",
    "                wf[w]=1\n",
    "            else:\n",
    "                wf[w]+=1\n",
    "        word_list=[(k,wf[k]) for k in wf if k not in stop2 ]\n",
    "        word_list.sort(key=lambda a :a[1],reverse=True)\n",
    "        df1['word_freq'][i]=word_list\n",
    "    return(df1)\n",
    "\n",
    "\n",
    "\n",
    "# 斷詞整理(去除標點符號)\n",
    "def 整理(df1):\n",
    "    datanews = df1[\"seg\"]\n",
    "    # 轉list\n",
    "    train_data = np.array(datanews)#np.ndarray()\n",
    "    datanews=train_data.tolist()#list\n",
    "    df1=''\n",
    "    for datanew in datanews:\n",
    "        df1+=str(datanew)+'\\n'\n",
    "    df1=df1.replace('[','').replace('\\'','').replace('「 ','').replace('」 ','').replace('」 ','').replace('、 ','').replace('： ','')\n",
    "    df1=df1.replace('《 ','').replace('》 ','').replace('） ','').replace('( ','').replace('／ ','').replace('， ','')\n",
    "    df1=df1.replace('╱ ','').replace('！ ','').replace('？ ','').replace('（ ','').replace('。 ','').replace('； ','').replace('… ','')\n",
    "    df1=df1.replace(']','').replace(' :','').replace('\\u3000','').replace('\\n','')\n",
    "    df2=df1\n",
    "    for i in range(len(df2)):\n",
    "        df1=' '.join(df2.split())\n",
    "    return(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
